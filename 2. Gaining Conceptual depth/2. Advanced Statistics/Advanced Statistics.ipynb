{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f08ab35a-5103-4955-8435-77da755cfde1",
   "metadata": {},
   "source": [
    "# `Advanced Statistics Notes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75da83a-4240-4249-a84d-0b4344f543a8",
   "metadata": {},
   "source": [
    "> # `Covariance | Covariance  vs Causation`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205a80cb-f236-4a2e-b58e-659aad329f9e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "# **Covariance**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* **Covariance** measures how **two numerical variables change together**.\n",
    "* If both variables increase/decrease together ‚Üí **positive covariance**.\n",
    "* If one increases while the other decreases ‚Üí **negative covariance**.\n",
    "* If no consistent relationship ‚Üí covariance ‚âà 0.\n",
    "\n",
    "**Formula (for two variables X and Y):**\n",
    "\n",
    "$$\n",
    "\\text{Cov}(X, Y) = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{n-1}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Example**\n",
    "\n",
    "* Suppose study hours (X) and exam scores (Y):\n",
    "\n",
    "  * If more hours ‚Üí higher scores ‚Üí **positive covariance**.\n",
    "* Suppose exercise (X) and body weight (Y):\n",
    "\n",
    "  * If more exercise ‚Üí lower weight ‚Üí **negative covariance**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Limitations**\n",
    "\n",
    "* The **value of covariance is not standardized** ‚Üí hard to compare.\n",
    "* That‚Äôs why we often use **correlation**, which is a scaled version of covariance.\n",
    "\n",
    "---\n",
    "\n",
    "# **Covariance vs Causation**\n",
    "\n",
    "## **Covariance (or Correlation)**\n",
    "\n",
    "* Shows **association** between variables.\n",
    "* Example: Ice cream sales ‚Üë and temperature ‚Üë ‚Üí strong positive covariance.\n",
    "\n",
    "## **Causation**\n",
    "\n",
    "* Implies that **one variable directly affects the other**.\n",
    "* Example: Temperature ‚Üë ‚Üí people buy more ice cream (temperature causes ice cream sales).\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Differences**\n",
    "\n",
    "| Aspect    | Covariance / Correlation                            | Causation                                         |\n",
    "| --------- | --------------------------------------------------- | ------------------------------------------------- |\n",
    "| Meaning   | Shows if variables move together                    | Shows if one variable influences the other        |\n",
    "| Direction | Positive, Negative, or None                         | Cause ‚Üí Effect                                    |\n",
    "| Proof     | From data relationship only                         | Requires controlled experiment or deep reasoning  |\n",
    "| Example   | Shoe size and reading ability may correlate in kids | Age causes both shoe size ‚Üë and reading ability ‚Üë |\n",
    "\n",
    "---\n",
    "\n",
    "## **4. In Machine Learning**\n",
    "\n",
    "* **Covariance/Correlation** ‚Üí used in feature selection, PCA (Principal Component Analysis), detecting multicollinearity.\n",
    "* **Causation** ‚Üí very hard to prove! Needs experiments (A/B testing), causal inference, or domain knowledge.\n",
    "* ML models often exploit **correlations**, but that doesn‚Äôt always mean true causality.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic**:\n",
    "\n",
    "* **Covariance = Moves together?**\n",
    "* **Causation = One makes the other happen.**\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e52ec55-2ac7-4509-93ea-1e778f039ded",
   "metadata": {},
   "source": [
    "> # `Probability Distribution Functions - PDF, PMF & CDF`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e97ca-d2c2-490c-82fc-e3843d67b601",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "# **Probability Distribution Functions**\n",
    "\n",
    "Probability distributions describe **how probabilities are assigned to different outcomes** of a random variable.\n",
    "\n",
    "There are 2 types of random variables:\n",
    "\n",
    "* **Discrete** ‚Üí countable outcomes (e.g., dice roll, number of students).\n",
    "* **Continuous** ‚Üí infinite possible values within a range (e.g., height, weight).\n",
    "\n",
    "---\n",
    "\n",
    "## **1. PMF (Probability Mass Function)**\n",
    "\n",
    "* Used for **discrete random variables**.\n",
    "* Assigns a probability to **each possible outcome**.\n",
    "* Properties:\n",
    "\n",
    "  * $P(X = x) \\geq 0$\n",
    "  * $\\sum P(X = x) = 1$\n",
    "\n",
    "**Example (Dice roll):**\n",
    "\n",
    "* PMF:\n",
    "\n",
    "  $$\n",
    "  P(X=x) = \\frac{1}{6}, \\quad x \\in \\{1,2,3,4,5,6\\}\n",
    "  $$\n",
    "\n",
    "**In ML:** PMFs appear in Naive Bayes (discrete features), categorical variables, language models (word counts).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. PDF (Probability Density Function)**\n",
    "\n",
    "* Used for **continuous random variables**.\n",
    "* Probability is **not assigned to a single point** (since infinite values exist), but to an **interval**.\n",
    "* Area under the curve = probability.\n",
    "* Properties:\n",
    "\n",
    "  * $f(x) \\geq 0$\n",
    "  * $\\int_{-\\infty}^{\\infty} f(x) dx = 1$\n",
    "\n",
    "**Example (Normal distribution):**\n",
    "\n",
    "* Bell curve for heights of people.\n",
    "* Probability someone‚Äôs height is between 160‚Äì170 cm = area under curve between 160 and 170.\n",
    "\n",
    "**In ML:** PDFs appear in density estimation, Gaussian Naive Bayes, anomaly detection, generative models.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. CDF (Cumulative Distribution Function)**\n",
    "\n",
    "* Works for **both discrete and continuous** variables.\n",
    "* Gives the **probability that random variable ‚â§ x**.\n",
    "* Formula:\n",
    "\n",
    "  $$\n",
    "  F(x) = P(X \\leq x)\n",
    "  $$\n",
    "\n",
    "**Example (Dice roll):**\n",
    "\n",
    "* $F(3) = P(X \\leq 3) = \\frac{3}{6} = 0.5$\n",
    "\n",
    "**Example (Height with Normal PDF):**\n",
    "\n",
    "* If CDF(170) = 0.6 ‚Üí 60% of people are ‚â§ 170 cm tall.\n",
    "\n",
    "**In ML:** CDFs are used in hypothesis testing (p-values), probabilistic models, and survival analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## **Quick Comparison**\n",
    "\n",
    "| Function | Variable Type | What it Tells You                                                        |\n",
    "| -------- | ------------- | ------------------------------------------------------------------------ |\n",
    "| **PMF**  | Discrete      | Probability of exact value                                               |\n",
    "| **PDF**  | Continuous    | Probability density at a value (area over an interval gives probability) |\n",
    "| **CDF**  | Both          | Probability variable ‚â§ a value                                           |\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic**\n",
    "\n",
    "* **PMF ‚Üí Point probability** (discrete).\n",
    "* **PDF ‚Üí Density probability** (continuous).\n",
    "* **CDF ‚Üí Cumulative probability** (up to a point).\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967bd8c2-5d7e-415b-9283-b33637787e6a",
   "metadata": {},
   "source": [
    "> # `Kernel Density Estimation (KDE)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cf294b-b387-4ac6-a968-1a8343c4ce6c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* **KDE** is a **non-parametric** way to estimate the probability density function (PDF) of a random variable.\n",
    "* Unlike a histogram (which is blocky), KDE gives a **smooth curve** that represents the underlying distribution of data.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. How it Works**\n",
    "\n",
    "* Imagine placing a **small ‚Äúbump‚Äù (kernel function)** on each data point.\n",
    "* Add up all these bumps ‚Üí get a smooth curve (the density estimate).\n",
    "* The **kernel** is usually Gaussian (bell-shaped), but can be others.\n",
    "* The **bandwidth** controls smoothness:\n",
    "\n",
    "  * Small bandwidth ‚Üí too wiggly (overfits).\n",
    "  * Large bandwidth ‚Üí too flat (underfits).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Example**\n",
    "\n",
    "Suppose we have exam scores: `[50, 55, 60, 70, 80, 85, 90]`.\n",
    "\n",
    "* Histogram ‚Üí shows frequencies in bins.\n",
    "* KDE ‚Üí smooth curve showing how scores are distributed.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Applications in Machine Learning**\n",
    "\n",
    "* **Data Exploration (EDA):** Visualizing feature distributions.\n",
    "* **Outlier Detection:** Peaks vs rare regions.\n",
    "* **Generative Modeling:** Estimating density without assuming a specific distribution.\n",
    "* **Anomaly Detection:** Points with very low KDE density = anomalies.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. KDE vs Histogram**\n",
    "\n",
    "| Aspect     | Histogram                    | KDE                       |\n",
    "| ---------- | ---------------------------- | ------------------------- |\n",
    "| Shape      | Blocky (depends on bin size) | Smooth                    |\n",
    "| Parameters | Bin width                    | Bandwidth                 |\n",
    "| Use Case   | Quick count visualization    | Estimating underlying PDF |\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Quick Analogy**\n",
    "\n",
    "Think of KDE as pouring a drop of **ink (kernel)** at every data point.\n",
    "When all ink drops overlap, they form a **smooth shape** (density curve).\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**:\n",
    "\n",
    "* KDE = Smooth estimate of PDF.\n",
    "* Controlled by **kernel type** and **bandwidth**.\n",
    "* Widely used in ML for **EDA, density estimation, and anomaly detection**.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c35cbf5-c538-44a2-b8e2-2bb29c02badd",
   "metadata": {},
   "source": [
    "> # `Normal Distribution`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2dbbc5-44e4-46fe-a728-98926266713a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* Also called the **Gaussian distribution** (after Carl Friedrich Gauss).\n",
    "* A **continuous probability distribution** shaped like a symmetric \"bell curve.\"\n",
    "* Most natural phenomena (heights, IQ scores, measurement errors) follow it (approximately).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Properties**\n",
    "\n",
    "* **Symmetric** around the mean ($\\mu$).\n",
    "* **Mean = Median = Mode**.\n",
    "* **68-95-99.7 Rule** (Empirical Rule):\n",
    "\n",
    "  * ~68% of data within 1 standard deviation ($\\sigma$).\n",
    "  * ~95% within 2$\\sigma$.\n",
    "  * ~99.7% within 3$\\sigma$.\n",
    "\n",
    "**Probability Density Function (PDF):**\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{ -\\frac{(x-\\mu)^2}{2\\sigma^2} }\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Standard Normal Distribution**\n",
    "\n",
    "* Special case: $\\mu = 0$, $\\sigma = 1$.\n",
    "* Often denoted $Z$.\n",
    "* Used for **Z-scores**:\n",
    "\n",
    "  $$\n",
    "  Z = \\frac{X - \\mu}{\\sigma}\n",
    "  $$\n",
    "* Helps compare different datasets on the same scale.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Applications in Machine Learning**\n",
    "\n",
    "* **Assumption in Models:** Linear regression, logistic regression, Naive Bayes often assume normality (errors or features).\n",
    "* **Feature Scaling:** Z-score normalization uses mean and standard deviation.\n",
    "* **Hypothesis Testing:** Many test statistics (t-test, ANOVA, etc.) rely on normality assumptions.\n",
    "* **Probability & Likelihood:** Gaussian likelihood is used in generative models (e.g., Gaussian Mixture Models).\n",
    "* **Noise Modeling:** Measurement errors often assumed to be Gaussian.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Example**\n",
    "\n",
    "* Suppose students‚Äô heights in a class are approximately normal with:\n",
    "\n",
    "  * $\\mu = 170$ cm, $\\sigma = 10$ cm.\n",
    "  * ~68% of students are between **160 cm and 180 cm**.\n",
    "  * ~95% between **150 cm and 190 cm**.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Visual Intuition**\n",
    "\n",
    "* Bell-shaped curve.\n",
    "* Tallest at mean, tails taper off.\n",
    "* Area under curve = probability.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic**:\n",
    "\n",
    "* **Normal = Natural = Bell curve**.\n",
    "* Think of it as the \"default\" distribution in statistics.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c0c2c0-3972-4efd-a328-107ba2a30ea7",
   "metadata": {},
   "source": [
    "> # `Skewness`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec27b6e7-56d8-449f-a2ba-38d8f9d12cf7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* **Skewness** measures the **asymmetry** of a distribution.\n",
    "* A normal distribution has **skewness = 0** (perfectly symmetric).\n",
    "* If data leans to one side ‚Üí it‚Äôs skewed.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Types of Skewness**\n",
    "\n",
    "### **a) Positive Skew (Right-skewed)**\n",
    "\n",
    "* Tail stretches more to the **right**.\n",
    "* Mean > Median > Mode.\n",
    "* Example: Income distribution (a few very high incomes pull the mean to the right).\n",
    "\n",
    "### **b) Negative Skew (Left-skewed)**\n",
    "\n",
    "* Tail stretches more to the **left**.\n",
    "* Mean < Median < Mode.\n",
    "* Example: Age at retirement (most retire around 60‚Äì65, but some retire much earlier).\n",
    "\n",
    "### **c) Zero Skew (Symmetric)**\n",
    "\n",
    "* Distribution is symmetric.\n",
    "* Mean = Median = Mode.\n",
    "* Example: Heights of adults (approximately).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Formula**\n",
    "\n",
    "For a dataset $X$:\n",
    "\n",
    "$$\n",
    "\\text{Skewness} = \\frac{\\sum (X_i - \\bar{X})^3 / n}{\\sigma^3}\n",
    "$$\n",
    "\n",
    "* Positive value ‚Üí right skew.\n",
    "* Negative value ‚Üí left skew.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. In Machine Learning**\n",
    "\n",
    "* Skewed features can affect algorithms that assume normality (e.g., Linear Regression, Logistic Regression).\n",
    "* Often corrected with **log transform, square root, or Box-Cox transform**.\n",
    "* Important in **outlier detection** (skewness often caused by outliers).\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Visual Intuition**\n",
    "\n",
    "* **Right skew** = tail on the right.\n",
    "* **Left skew** = tail on the left.\n",
    "* Think of the \"tail\" as the direction of skew.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic**:\n",
    "\n",
    "* \"Tail tells the tale.\"\n",
    "* If the **tail is right ‚Üí right skew**.\n",
    "* If the **tail is left ‚Üí left skew**.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad310e5-5fc7-4c97-94da-252536c76f0c",
   "metadata": {},
   "source": [
    "> # `Non-Gaussian Probability Distributions`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85ad8f4-ecaa-40f8-8988-b83ab56bc788",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "###  What are Non-Gaussian Distributions?\n",
    "\n",
    "* A **Gaussian distribution** = the bell curve (symmetric, unimodal, defined by mean & variance).\n",
    "* **Non-Gaussian distributions** are all distributions that **don‚Äôt follow the bell curve**.\n",
    "\n",
    "  * They may be **skewed**, **heavier-tailed**, **multi-peaked**, or **discrete**.\n",
    "\n",
    "---\n",
    "\n",
    "###  Common Non-Gaussian Distributions\n",
    "\n",
    "1. **Uniform Distribution**\n",
    "\n",
    "   * All outcomes equally likely.\n",
    "   * Example: Rolling a fair die (1‚Äì6, each has probability 1/6).\n",
    "\n",
    "2. **Bernoulli Distribution**\n",
    "\n",
    "   * Only two outcomes: success (1) or failure (0).\n",
    "   * Example: Tossing a coin once.\n",
    "\n",
    "3. **Binomial Distribution**\n",
    "\n",
    "   * Number of successes in `n` independent Bernoulli trials.\n",
    "   * Example: Number of heads in 10 coin tosses.\n",
    "\n",
    "4. **Poisson Distribution**\n",
    "\n",
    "   * Counts the number of events in a fixed time/space interval.\n",
    "   * Example: Number of emails received in an hour.\n",
    "\n",
    "5. **Exponential Distribution**\n",
    "\n",
    "   * Models **time between events** in a Poisson process.\n",
    "   * Example: Time between arrivals at a bus stop.\n",
    "\n",
    "6. **Geometric Distribution**\n",
    "\n",
    "   * Number of trials until the first success.\n",
    "   * Example: Tossing a coin until you get heads.\n",
    "\n",
    "7. **t-Distribution (Student‚Äôs t)**\n",
    "\n",
    "   * Similar to normal but with **heavier tails** (more outliers).\n",
    "   * Example: Useful when working with **small sample sizes**.\n",
    "\n",
    "8. **Chi-Square Distribution**\n",
    "\n",
    "   * Distribution of a sum of squared standard normal variables.\n",
    "   * Used in **hypothesis testing** (e.g., independence tests).\n",
    "\n",
    "9. **Exotic Non-Gaussians**\n",
    "\n",
    "   * **Cauchy Distribution** ‚Üí very heavy tails, mean & variance undefined.\n",
    "   * **Beta Distribution** ‚Üí used for probabilities (values between 0 and 1).\n",
    "   * **Gamma Distribution** ‚Üí generalization of exponential.\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Idea\n",
    "\n",
    " Non-Gaussian distributions show up when:\n",
    "\n",
    "* Data is **discrete** (like dice rolls).\n",
    "* Data is **skewed** (like income).\n",
    "* Data has **heavy tails** (like stock returns).\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a9ecbb-4278-402a-8b8b-d7995d2ae80c",
   "metadata": {},
   "source": [
    "> # `Kurtosis`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7934c649-70a4-4a55-96bc-c17948ec3807",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "###  What is Kurtosis?\n",
    "\n",
    "* **Kurtosis** measures the **‚Äútailedness‚Äù** of a probability distribution.\n",
    "* It tells us **how heavy or light the tails** are compared to a normal distribution.\n",
    "* In other words: Do extreme values (outliers) happen more or less often than in a normal bell curve?\n",
    "\n",
    "---\n",
    "\n",
    "###  Types of Kurtosis\n",
    "\n",
    "1. **Mesokurtic (Normal)**\n",
    "\n",
    "   * Same kurtosis as the normal distribution.\n",
    "   * Balanced tails.\n",
    "   * Example: Standard normal curve.\n",
    "\n",
    "2. **Leptokurtic (High Kurtosis > 3)**\n",
    "\n",
    "   * **Heavy tails**, **sharp peak**.\n",
    "   * More extreme values (outliers) likely.\n",
    "   * Example: Stock market returns.\n",
    "\n",
    "3. **Platykurtic (Low Kurtosis < 3)**\n",
    "\n",
    "   * **Light tails**, **flatter peak**.\n",
    "   * Fewer extreme values.\n",
    "   * Example: Uniform distribution.\n",
    "\n",
    "---\n",
    "\n",
    "###  Formula for Sample Kurtosis\n",
    "\n",
    "$$\n",
    "K = \\frac{\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^4}{\\left(\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2\\right)^2}\n",
    "$$\n",
    "\n",
    "* Numerator = 4th moment (sensitive to extreme values).\n",
    "* Denominator = squared variance.\n",
    "\n",
    "Often we use **Excess Kurtosis = K ‚Äì 3** so that:\n",
    "\n",
    "* Normal distribution ‚Üí 0\n",
    "* Leptokurtic ‚Üí positive\n",
    "* Platykurtic ‚Üí negative\n",
    "\n",
    "---\n",
    "\n",
    "###  Intuition\n",
    "\n",
    "* **Skewness** = ‚ÄúIs the curve tilted left or right?‚Äù\n",
    "* **Kurtosis** = ‚ÄúHow fat are the tails and how sharp is the peak?‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b433846f-55dc-40e6-b481-2480bf5525ac",
   "metadata": {},
   "source": [
    "> # `Q‚ÄìQ plot`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d7446-c29e-47bd-8936-e4fb3c6c470a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "###  What is a Q‚ÄìQ Plot?\n",
    "\n",
    "* **Q‚ÄìQ (Quantile‚ÄìQuantile) Plot** compares the **quantiles** of your dataset with the quantiles of a theoretical distribution (like normal).\n",
    "* If your data follows that distribution ‚Üí the points lie **close to a straight line** (usually 45¬∞).\n",
    "\n",
    "---\n",
    "\n",
    "###  How it Works\n",
    "\n",
    "1. Take your dataset and sort it.\n",
    "2. Compute its **quantiles**.\n",
    "3. Compare against the **theoretical quantiles** (e.g., of normal distribution).\n",
    "4. Plot data quantiles (Y-axis) vs theoretical quantiles (X-axis).\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "* **Straight line** ‚Üí data ‚âà theoretical distribution.\n",
    "* **Upward curve at ends** ‚Üí heavier tails than normal (leptokurtic).\n",
    "* **Downward curve at ends** ‚Üí lighter tails (platykurtic).\n",
    "* **S-shape** ‚Üí skewness (left or right tilt).\n",
    "\n",
    "---\n",
    "\n",
    "###  Example in Machine Learning\n",
    "\n",
    "* Before applying models like **Linear Regression** or **Logistic Regression**, we often assume errors are **normally distributed**.\n",
    "* A Q‚ÄìQ plot of residuals can check this assumption quickly.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8f958-6c78-4902-8b2d-9515f5ca4cac",
   "metadata": {},
   "source": [
    "> # `Uniform Distribution`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8481fefe-13a6-43cf-b27a-ef68dcacf9f2",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "###  What is a Uniform Distribution?\n",
    "\n",
    "* A probability distribution where **all outcomes are equally likely**.\n",
    "* Every value within a given range has the **same probability**.\n",
    "* Example: Rolling a fair die ‚Üí each face (1‚Äì6) has probability $\\tfrac{1}{6}$.\n",
    "\n",
    "---\n",
    "\n",
    "###  Types of Uniform Distribution\n",
    "\n",
    "1. **Discrete Uniform Distribution**\n",
    "\n",
    "   * Finite number of values, each equally likely.\n",
    "   * Example: Rolling a die, picking a random card from a deck.\n",
    "\n",
    "2. **Continuous Uniform Distribution**\n",
    "\n",
    "   * Infinite values in an interval $[a, b]$, all equally likely.\n",
    "   * Probability Density Function (PDF):\n",
    "\n",
    "     $$\n",
    "     f(x) = \\frac{1}{b-a}, \\quad a \\leq x \\leq b\n",
    "     $$\n",
    "   * Cumulative Distribution Function (CDF):\n",
    "\n",
    "     $$\n",
    "     F(x) = \\frac{x-a}{b-a}, \\quad a \\leq x \\leq b\n",
    "     $$\n",
    "\n",
    "---\n",
    "\n",
    "### Properties\n",
    "\n",
    "* **Mean**:\n",
    "\n",
    "  $$\n",
    "  \\mu = \\frac{a+b}{2}\n",
    "  $$\n",
    "* **Variance**:\n",
    "\n",
    "  $$\n",
    "  \\sigma^2 = \\frac{(b-a)^2}{12}\n",
    "  $$\n",
    "* Shape: Flat (rectangular).\n",
    "\n",
    "---\n",
    "\n",
    "### In Machine Learning\n",
    "\n",
    "* Used for **random initialization** of weights (before training starts).\n",
    "* Sampling for simulations (Monte Carlo methods).\n",
    "* Data augmentation (random crops, rotations with equal probability).\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8e86e5-666e-4f05-a18b-074cc1a419eb",
   "metadata": {},
   "source": [
    "> # `Log Normal Distribution `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fe6b87-41fc-4b27-afe3-829b994af71f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "### What is a Log-Normal Distribution?\n",
    "\n",
    "* A random variable $X$ is **log-normally distributed** if:\n",
    "\n",
    "  $$\n",
    "  \\ln(X) \\sim N(\\mu, \\sigma^2)\n",
    "  $$\n",
    "\n",
    "  That means the **logarithm of $X$** follows a **normal distribution**.\n",
    "* So while a normal distribution can take **negative values**, a log-normal is **strictly positive**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Probability Density Function (PDF)\n",
    "\n",
    "For $x > 0$:\n",
    "\n",
    "$$\n",
    "f(x; \\mu, \\sigma) = \\frac{1}{x\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "* Skewed to the right (long positive tail).\n",
    "* Shape depends on $\\mu$ and $\\sigma$.\n",
    "\n",
    "---\n",
    "\n",
    "###  Properties\n",
    "\n",
    "* **Mean**:\n",
    "\n",
    "  $$\n",
    "  E[X] = e^{\\mu + \\frac{\\sigma^2}{2}}\n",
    "  $$\n",
    "* **Median**:\n",
    "\n",
    "  $$\n",
    "  \\text{Median} = e^{\\mu}\n",
    "  $$\n",
    "* **Variance**:\n",
    "\n",
    "  $$\n",
    "  Var[X] = \\left(e^{\\sigma^2} - 1\\right) e^{2\\mu + \\sigma^2}\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "###  Examples in Real Life\n",
    "\n",
    "* **Stock prices**: Can‚Äôt be negative, but can grow exponentially.\n",
    "* **Income distribution**: Most people earn around the median, but a few earn extremely high amounts.\n",
    "* **Biological measures**: Reaction times, survival times, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### In Machine Learning\n",
    "\n",
    "* **Modeling skewed data** (e.g., prices, time-to-event data).\n",
    "* **Feature transformation**: Taking $\\ln(x)$ of a skewed feature often makes it more normal-like, which helps models that assume normality (like linear regression).\n",
    "* **Generative models**: Useful for positive-only variables.\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220aa2a-9f98-43f1-b523-19dba4714275",
   "metadata": {},
   "source": [
    "> # `Pareto Distribution`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f2aee-639b-4925-ba0d-84a3ddaa3419",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "###  What is the Pareto Distribution?\n",
    "\n",
    "* A continuous probability distribution often called the **‚Äú80/20 rule‚Äù distribution**.\n",
    "* Named after economist **Vilfredo Pareto**, who observed that **20% of people owned 80% of the land in Italy**.\n",
    "* It describes situations where **a small number of events account for most of the effect**.\n",
    "\n",
    "---\n",
    "\n",
    "###  Probability Density Function (PDF)\n",
    "\n",
    "For $x \\geq x_m$:\n",
    "\n",
    "$$\n",
    "f(x; x_m, \\alpha) = \\frac{\\alpha x_m^\\alpha}{x^{\\alpha+1}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $x_m > 0$ = minimum possible value (scale).\n",
    "* $\\alpha > 0$ = shape parameter.\n",
    "\n",
    "---\n",
    "\n",
    "###  Properties\n",
    "\n",
    "* **Mean** (only if $\\alpha > 1$):\n",
    "\n",
    "  $$\n",
    "  E[X] = \\frac{\\alpha x_m}{\\alpha - 1}\n",
    "  $$\n",
    "* **Variance** (only if $\\alpha > 2$):\n",
    "\n",
    "  $$\n",
    "  Var[X] = \\frac{x_m^2 \\alpha}{(\\alpha - 1)^2 (\\alpha - 2)}\n",
    "  $$\n",
    "* Heavy-tailed: Extreme large values occur more often than in normal or exponential.\n",
    "\n",
    "---\n",
    "\n",
    "###  Applications in Real Life\n",
    "\n",
    "* **Wealth distribution** (small % of population owns most wealth).\n",
    "* **Internet traffic** (few sites get most of the clicks).\n",
    "* **Natural phenomena** (sizes of cities, earthquakes, file sizes).\n",
    "\n",
    "---\n",
    "\n",
    "### In Machine Learning\n",
    "\n",
    "* Understanding **imbalanced data** (e.g., rare events dominate outcomes).\n",
    "* **Feature engineering**: log-transforming Pareto-like features can stabilize models.\n",
    "* **Anomaly detection**: large outliers may be natural if the underlying process is Pareto.\n",
    "\n",
    "---\n",
    "\n",
    "**Compare with Log-Normal**:\n",
    "\n",
    "* Both are skewed with heavy tails.\n",
    "* **Log-normal** ‚Üí arises when multiplying many random factors.\n",
    "* **Pareto** ‚Üí arises when following power-law processes.\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b338378-9538-4272-81ff-ecf37a427177",
   "metadata": {},
   "source": [
    "> # `Transformations `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcfc40b-2c05-4f70-bb79-c16485b535f6",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "# **Data Transformations**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* A **transformation** changes the **scale, shape, or distribution** of data.\n",
    "* Purpose: Improve model performance, reduce skewness, stabilize variance, or make relationships more linear.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Common Types of Transformations**\n",
    "\n",
    "### **a) Logarithmic Transformation**\n",
    "\n",
    "* Formula: $X' = \\log(X)$ (usually natural log).\n",
    "* **Use:** Reduce right skew, compress large values.\n",
    "* **Example:** Income, population, stock prices.\n",
    "\n",
    "---\n",
    "\n",
    "### **b) Square Root Transformation**\n",
    "\n",
    "* Formula: $X' = \\sqrt{X}$\n",
    "* **Use:** Reduce moderate skewness, stabilize variance.\n",
    "* **Example:** Count data like number of defects, number of calls.\n",
    "\n",
    "---\n",
    "\n",
    "### **c) Cube Root Transformation**\n",
    "\n",
    "* Formula: $X' = \\sqrt[3]{X}$\n",
    "* **Use:** Can reduce skewness for both positive and negative values.\n",
    "\n",
    "---\n",
    "\n",
    "### **d) Reciprocal Transformation**\n",
    "\n",
    "* Formula: $X' = 1/X$\n",
    "* **Use:** Invert relationships, reduce influence of large values.\n",
    "\n",
    "---\n",
    "\n",
    "### **e) Box-Cox Transformation**\n",
    "\n",
    "* Formula: $X' = \\frac{X^\\lambda - 1}{\\lambda}$ (for $\\lambda \\neq 0$)\n",
    "* **Use:** Finds the best power transformation to **normalize** data.\n",
    "* **Requirement:** All $X > 0$.\n",
    "\n",
    "---\n",
    "\n",
    "### **f) Yeo-Johnson Transformation**\n",
    "\n",
    "* Similar to Box-Cox but works for **positive and negative values**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Why Transformations are Important in ML**\n",
    "\n",
    "* **Linear models** assume linearity ‚Üí transform skewed features to improve fit.\n",
    "* **Stabilize variance** ‚Üí reduce heteroscedasticity (non-constant variance).\n",
    "* **Reduce effect of outliers** ‚Üí compress extreme values.\n",
    "* **Make distributions more normal** ‚Üí better for algorithms that assume normality (e.g., Naive Bayes, t-tests).\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Visual Example**\n",
    "\n",
    "* Original data: Right-skewed histogram.\n",
    "* After log transformation: More symmetric, easier for models to learn.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic:**\n",
    "\n",
    "* **Log / Sqrt ‚Üí compress big values**\n",
    "* **Reciprocal ‚Üí invert relationships**\n",
    "* **Box-Cox ‚Üí find the best power automatically**\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8586b1-57b7-4634-9af0-99ea2583ba4b",
   "metadata": {},
   "source": [
    "> # `Bernoulli Distribution `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790bbe69-fbb4-41db-b006-49676b3f2dbd",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Bernoulli Distribution**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* The **Bernoulli distribution** is the probability distribution of a **single trial** with only **two possible outcomes**:\n",
    "\n",
    "  * Success ($1$) with probability $p$\n",
    "  * Failure ($0$) with probability $1-p$\n",
    "\n",
    "It‚Äôs like flipping a biased coin once.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Probability Mass Function (PMF)**\n",
    "\n",
    "For outcome $x \\in \\{0, 1\\}$:\n",
    "\n",
    "$$\n",
    "P(X = x) = p^x (1-p)^{1-x}\n",
    "$$\n",
    "\n",
    "* $P(X=1) = p$\n",
    "* $P(X=0) = 1-p$\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Properties**\n",
    "\n",
    "* **Mean (Expected Value):**\n",
    "\n",
    "  $$\n",
    "  E[X] = p\n",
    "  $$\n",
    "* **Variance:**\n",
    "\n",
    "  $$\n",
    "  Var(X) = p(1-p)\n",
    "  $$\n",
    "* **Support:** $X \\in \\{0,1\\}$\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Real-Life Examples**\n",
    "\n",
    "* Tossing a (possibly biased) coin: Heads (1), Tails (0).\n",
    "* A student passing (1) or failing (0) an exam.\n",
    "* Email being spam (1) or not spam (0).\n",
    "\n",
    "---\n",
    "\n",
    "## **5. In Machine Learning**\n",
    "\n",
    "* Basis of **binary classification**.\n",
    "* Logistic regression models $P(Y=1)$, which follows Bernoulli.\n",
    "* Loss function: **Binary Cross-Entropy** is derived from Bernoulli likelihood.\n",
    "* Used in **generative models** (e.g., Bernoulli Naive Bayes).\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Related Distributions**\n",
    "\n",
    "* **Binomial distribution** = sum of several independent Bernoulli trials.\n",
    "* **Geometric distribution** = number of Bernoulli trials until the first success.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a047e9d-1b7d-41ef-9631-8395d64f3831",
   "metadata": {},
   "source": [
    "> # `Binomial Distribution `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd3b5d5-5323-47d2-9fcc-179a13fb0aa7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Binomial Distribution**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* The **binomial distribution** gives the probability of getting exactly $k$ successes in $n$ independent Bernoulli trials, each with probability of success $p$.\n",
    "* Example: Flipping a coin $n$ times and counting heads.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Probability Mass Function (PMF)**\n",
    "\n",
    "For $k = 0,1,2, \\dots, n$:\n",
    "\n",
    "$$\n",
    "P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$ (number of ways to choose $k$ successes)\n",
    "* $p$ = probability of success\n",
    "* $n$ = number of trials\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Properties**\n",
    "\n",
    "* **Mean (Expected Value):**\n",
    "\n",
    "  $$\n",
    "  E[X] = np\n",
    "  $$\n",
    "* **Variance:**\n",
    "\n",
    "  $$\n",
    "  Var(X) = np(1-p)\n",
    "  $$\n",
    "* **Support:** $X \\in \\{0,1,2,\\dots,n\\}$\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Real-Life Examples**\n",
    "\n",
    "* Number of heads in 10 coin flips.\n",
    "* Number of students passing an exam (success/fail).\n",
    "* Number of defective items in a batch of products.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. In Machine Learning**\n",
    "\n",
    "* **Evaluation metrics**: Many are based on binomial proportions (e.g., accuracy = number of correct predictions out of $n$).\n",
    "* **Feature modeling**: If you record ‚Äúnumber of clicks out of trials,‚Äù binomial fits well.\n",
    "* **Hypothesis testing**: Proportions are often modeled with binomial.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Connection with Other Distributions**\n",
    "\n",
    "* **Bernoulli**: Special case of binomial with $n=1$.\n",
    "* **Normal approximation**: For large $n$, binomial ‚âà normal distribution (Central Limit Theorem).\n",
    "* **Poisson approximation**: If $n$ is large and $p$ is small.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d31772-ffc0-486a-9817-f7ae2b2457db",
   "metadata": {},
   "source": [
    "> # `Sampling Distribution `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88715bea-b7f4-4761-b3eb-1774c1e8f3d7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Sampling Distribution**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* A **sampling distribution** is the probability distribution of a statistic (like the mean, variance, or proportion) that is calculated from many random samples of the same population.\n",
    "* In other words:\n",
    "\n",
    "  * Take many samples from a population.\n",
    "  * Compute a statistic (e.g., sample mean $\\bar{X}$) for each.\n",
    "  * Plot the distribution of those statistics ‚Üí that‚Äôs the **sampling distribution**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Why It‚Äôs Important**\n",
    "\n",
    "* It tells us **how much our sample statistic is likely to vary** from sample to sample.\n",
    "* Forms the foundation of:\n",
    "\n",
    "  * **Confidence intervals**\n",
    "  * **Hypothesis testing**\n",
    "  * **Standard errors**\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Example**\n",
    "\n",
    "* Population: Heights of students in a college (true mean $\\mu$ = 170 cm).\n",
    "* Take random samples of size $n=30$.\n",
    "* Compute the mean height for each sample.\n",
    "* Collect many such sample means ‚Üí their distribution is the **sampling distribution of the mean**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Central Limit Theorem (CLT)**\n",
    "\n",
    "* Key fact: As sample size $n$ increases, the sampling distribution of the mean $\\bar{X}$ approaches a **normal distribution**, regardless of the population‚Äôs original distribution.\n",
    "* Mean of sampling distribution:\n",
    "\n",
    "  $$\n",
    "  E[\\bar{X}] = \\mu\n",
    "  $$\n",
    "* Standard error (spread of sample means):\n",
    "\n",
    "  $$\n",
    "  SE = \\frac{\\sigma}{\\sqrt{n}}\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "## **5. In Machine Learning**\n",
    "\n",
    "* **Cross-validation** mimics the idea of sampling distributions (different train/test splits ‚Üí different performance measures).\n",
    "* **Bootstrap methods** use repeated resampling to approximate sampling distributions.\n",
    "* Understanding model stability ‚Üí how much metrics (like accuracy) vary across samples.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic:**\n",
    "\n",
    "* **Population ‚Üí one big truth**\n",
    "* **Sample ‚Üí one estimate**\n",
    "* **Sampling distribution ‚Üí distribution of many estimates**\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41b47b6-0797-4524-b47f-22f404c0a63f",
   "metadata": {},
   "source": [
    "> # `Central Limit Theorem`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60db1b3-109c-4199-ad86-af5143a4a6be",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Central Limit Theorem (CLT)**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "The **CLT states**:\n",
    "When we take **many independent random samples** from a population with mean $\\mu$ and variance $\\sigma^2$, the **sampling distribution of the sample mean** $\\bar{X}$ approaches a **normal distribution**, as the sample size $n$ becomes large.\n",
    "\n",
    "Formally:\n",
    "\n",
    "$$\n",
    "\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\;\\;\\xrightarrow{d}\\;\\; N(0,1) \\quad \\text{as } n \\to \\infty\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Key Points**\n",
    "\n",
    "* Works **regardless of the population‚Äôs original distribution** (normal, uniform, skewed, etc.).\n",
    "* Only requirements:\n",
    "\n",
    "  * Samples must be **independent** and **identically distributed (i.i.d.)**.\n",
    "  * Finite mean ($\\mu$) and variance ($\\sigma^2$).\n",
    "* The approximation improves as $n$ increases (usually $n \\geq 30$ is ‚Äúlarge enough‚Äù).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Implications**\n",
    "\n",
    "* The **mean of the sampling distribution** = population mean $\\mu$.\n",
    "* The **spread of the sampling distribution** = standard error (SE):\n",
    "\n",
    "  $$\n",
    "  SE = \\frac{\\sigma}{\\sqrt{n}}\n",
    "  $$\n",
    "* Lets us use **normal probability theory** (z-scores, confidence intervals, hypothesis tests) even when data isn‚Äôt normal.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Example**\n",
    "\n",
    "* Population: Students‚Äô exam scores, skewed right (not normal).\n",
    "* Take random samples of size $n=40$.\n",
    "* Compute sample means repeatedly.\n",
    "* Distribution of those sample means ‚Üí nearly **bell-shaped (normal)**.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. In Machine Learning**\n",
    "\n",
    "* Justifies why many algorithms assume ‚Äúerrors are normally distributed.‚Äù\n",
    "* Supports **bootstrap resampling** and confidence intervals for model metrics.\n",
    "* Ensures that **loss functions** and **test statistics** (like accuracy differences) behave predictably.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic:**\n",
    "\n",
    "* **CLT = \"Means go Normal\"** (even if data isn‚Äôt).\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0469ea-5163-471f-9615-0e47c9d4c7c1",
   "metadata": {},
   "source": [
    "> # `Confidence Intervals `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857a47df-6517-4e5d-b203-3540cd32d94c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Confidence Intervals (CIs)**\n",
    "\n",
    "## **1. Idea**\n",
    "\n",
    "A **confidence interval** gives a **range of plausible values** for a population parameter (like the mean or proportion) based on sample data.\n",
    "\n",
    "It‚Äôs not a guarantee, but rather a **level of confidence** (say 95%) that the true population parameter lies within that interval.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Formula (for Mean, when œÉ is known)**\n",
    "\n",
    "From CLT, we know the sample mean $\\bar{X}$ follows a normal distribution:\n",
    "\n",
    "$$\n",
    "CI = \\bar{X} \\;\\; \\pm \\;\\; Z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "* $\\bar{X}$ = sample mean\n",
    "* $\\sigma$ = population standard deviation\n",
    "* $n$ = sample size\n",
    "* $Z_{\\alpha/2}$ = critical value from standard normal distribution\n",
    "\n",
    "  * 95% CI ‚Üí $Z = 1.96$\n",
    "  * 99% CI ‚Üí $Z = 2.58$\n",
    "\n",
    "---\n",
    "\n",
    "## **3. When œÉ is Unknown**\n",
    "\n",
    "We use **sample standard deviation (s)** and a **t-distribution**:\n",
    "\n",
    "$$\n",
    "CI = \\bar{X} \\;\\; \\pm \\;\\; t_{\\alpha/2, \\; (n-1)} \\cdot \\frac{s}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Example**\n",
    "\n",
    "* Suppose you measure **average study time** for 100 students: $\\bar{X} = 4.5$ hours, $s = 1.2$.\n",
    "* 95% CI:\n",
    "\n",
    "$$\n",
    "4.5 \\pm 1.96 \\times \\frac{1.2}{\\sqrt{100}}\n",
    "= 4.5 \\pm 0.24\n",
    "= [4.26, 4.74]\n",
    "$$\n",
    "\n",
    "Interpretation: We are 95% confident that the **true mean study time** for all students is between **4.26 and 4.74 hours**.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Misconceptions**\n",
    "\n",
    "* ‚ùå A 95% CI does **not** mean the probability is 95% that the mean is in the interval.\n",
    "* ‚úÖ It means: if we repeat the experiment many times, **95% of the intervals built this way will contain the true mean**.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Uses in ML/DS**\n",
    "\n",
    "* Estimate **model performance** (e.g., 95% CI for accuracy).\n",
    "* Assess uncertainty in **parameter estimates**.\n",
    "* Compare two models‚Äô results with overlap or separation of their intervals.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic:**\n",
    "**CI = Estimate ¬± Margin of Error**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c36239c-1d8e-455d-9f41-5d6e0157aa04",
   "metadata": {},
   "source": [
    "> # `What is Hypothesis Testing?`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b97e1a-a843-4026-a724-818683fd8963",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  What is Hypothesis Testing?\n",
    "\n",
    "**Definition:**\n",
    "Hypothesis testing is a **statistical method** used to make decisions or draw conclusions about a **population parameter** based on data from a **sample**.\n",
    "\n",
    "It answers:\n",
    " *‚ÄúIs this observed effect real, or could it just be due to random chance?‚Äù*\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Ideas**\n",
    "\n",
    "* **Hypothesis** = an assumption or claim.\n",
    "* We test this claim using sample data.\n",
    "* There are always two competing hypotheses:\n",
    "\n",
    "  * **Null Hypothesis (H‚ÇÄ):** \"No effect\" or \"status quo\" (e.g., mean = 50).\n",
    "  * **Alternative Hypothesis (H‚ÇÅ or H‚Çê):** What you want to check/prove (e.g., mean > 50).\n",
    "\n",
    "---\n",
    "\n",
    "## **Example in Real Life**\n",
    "\n",
    "* A medicine company claims a new drug lowers blood pressure by 10 points on average.\n",
    "* You collect a sample of patients and test whether the average reduction is really 10 or not.\n",
    "* If data strongly contradicts H‚ÇÄ, you reject it and accept H‚ÇÅ.\n",
    "\n",
    "---\n",
    "\n",
    "## **Why It Matters in Machine Learning**\n",
    "\n",
    "* To test whether a **feature is significant**.\n",
    "* To compare two models‚Äô accuracies (e.g., Model A vs Model B).\n",
    "* In **A/B testing** for model updates or user interface changes.\n",
    "\n",
    "---\n",
    "\n",
    " **In one line:**\n",
    "Hypothesis testing is a **decision-making tool** that uses data to check if an assumption about the population is likely true or not.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b1fa9-bfc5-4d01-ae84-a3ca3438fa41",
   "metadata": {},
   "source": [
    "> # `Null Hypothesis (H‚ÇÄ) and Alternative Hypothesis (H‚ÇÅ / H‚Çê) `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2305b4b0-80ac-4750-9d97-50a1e83d47cd",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "\n",
    "#  Null Hypothesis (H‚ÇÄ)\n",
    "\n",
    "* The **default assumption** ‚Äî \"nothing new is happening.\"\n",
    "* Usually states there is **no effect**, **no difference**, or the value equals a specific number.\n",
    "* Example:\n",
    "\n",
    "  * $H‚ÇÄ: \\mu = 50$ ‚Üí The population mean is 50.\n",
    "  * In machine learning: \"Model A and Model B have the same accuracy.\"\n",
    "\n",
    "---\n",
    "\n",
    "# Alternative Hypothesis (H‚ÇÅ / H‚Çê)\n",
    "\n",
    "* The **opposite claim** to $H‚ÇÄ$.\n",
    "* Represents what the researcher or analyst is trying to prove.\n",
    "* Example:\n",
    "\n",
    "  * $H‚ÇÅ: \\mu > 50$ ‚Üí The population mean is greater than 50.\n",
    "  * In ML: \"Model A has higher accuracy than Model B.\"\n",
    "\n",
    "---\n",
    "\n",
    "# Types of Alternative Hypotheses\n",
    "\n",
    "1. **Two-tailed (‚â†)**\n",
    "\n",
    "   * $H‚ÇÅ: \\mu \\neq 50$\n",
    "   * Tests if the mean is *different* (either higher or lower).\n",
    "\n",
    "2. **Right-tailed (>)**\n",
    "\n",
    "   * $H‚ÇÅ: \\mu > 50$\n",
    "   * Tests if the mean is *greater*.\n",
    "\n",
    "3. **Left-tailed (<)**\n",
    "\n",
    "   * $H‚ÇÅ: \\mu < 50$\n",
    "   * Tests if the mean is *less*.\n",
    "\n",
    "---\n",
    "\n",
    "# Analogy (Simple)\n",
    "\n",
    "* Think of a **courtroom trial**:\n",
    "\n",
    "  * $H‚ÇÄ$: The person is innocent (default assumption).\n",
    "  * $H‚ÇÅ$: The person is guilty (claim to be tested).\n",
    "  * Evidence (data) decides whether we reject $H‚ÇÄ$.\n",
    "\n",
    "---\n",
    "\n",
    "**In one line:**\n",
    "\n",
    "* **H‚ÇÄ:** No effect / status quo.\n",
    "* **H‚ÇÅ:** There is an effect / change.\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb477d2-aaf9-4651-88f6-305fd2143fc9",
   "metadata": {},
   "source": [
    "> # `Steps Involved in a Hypothesis Test`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a001364a-8147-4f71-bd74-0c0702001dfa",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Steps Involved in a Hypothesis Test**\n",
    "\n",
    "### **Step 1: State the Hypotheses**\n",
    "\n",
    "* Formulate **Null Hypothesis (H‚ÇÄ)** and **Alternative Hypothesis (H‚ÇÅ)**.\n",
    "* Example:\n",
    "\n",
    "  * $H‚ÇÄ: \\mu = 50$ (mean = 50)\n",
    "  * $H‚ÇÅ: \\mu > 50$ (mean is greater than 50)\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Choose the Significance Level (Œ±)**\n",
    "\n",
    "* Common choices: **0.05 (5%)** or **0.01 (1%)**.\n",
    "* This is the probability of making a **Type I error** (rejecting H‚ÇÄ when it‚Äôs true).\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Select the Test Statistic**\n",
    "\n",
    "* Depends on data type, distribution, and sample size:\n",
    "\n",
    "  * **Z-test** ‚Üí large samples, known population œÉ.\n",
    "  * **t-test** ‚Üí small samples, œÉ unknown.\n",
    "  * **Chi-square test** ‚Üí categorical data.\n",
    "  * **ANOVA** ‚Üí comparing more than two group means.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Compute the Test Statistic from Sample Data**\n",
    "\n",
    "* Formula:\n",
    "\n",
    "  $$\n",
    "  Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\n",
    "  $$\n",
    "\n",
    "  (for mean with known œÉ).\n",
    "\n",
    "* You‚Äôll calculate either:\n",
    "\n",
    "  * A **test statistic** (Z, t, œá¬≤, F, etc.)\n",
    "  * Or a **p-value** (probability of observing data this extreme if H‚ÇÄ is true).\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 5: Define the Decision Rule**\n",
    "\n",
    "* Compare test statistic with **critical value** from the distribution table, OR use the **p-value method**:\n",
    "\n",
    "  * If **p ‚â§ Œ±** ‚Üí Reject H‚ÇÄ.\n",
    "  * If **p > Œ±** ‚Üí Fail to reject H‚ÇÄ.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 6: Make a Decision and Interpret**\n",
    "\n",
    "* Reject H‚ÇÄ ‚Üí Evidence supports the alternative hypothesis.\n",
    "* Fail to reject H‚ÇÄ ‚Üí No strong evidence against H‚ÇÄ.\n",
    "\n",
    "---\n",
    "\n",
    "#  Quick Example\n",
    "\n",
    "A sample of 36 phones has mean battery = 9.5 hours, œÉ = 1.8.\n",
    "Company claims mean = 10. Test at Œ± = 0.05.\n",
    "\n",
    "1. $H‚ÇÄ: \\mu = 10,\\; H‚ÇÅ: \\mu \\neq 10$.\n",
    "2. Œ± = 0.05.\n",
    "3. Z-test.\n",
    "4. $Z = \\frac{9.5 - 10}{1.8/\\sqrt{36}} = -1.67$.\n",
    "5. Critical Z = ¬±1.96.\n",
    "6. Since -1.67 is inside the range, **Fail to reject H‚ÇÄ** ‚Üí no significant difference.\n",
    "\n",
    "---\n",
    "\n",
    "**Mnemonic:**\n",
    "**‚ÄúHypothesis ‚Üí Alpha ‚Üí Test ‚Üí Compute ‚Üí Compare ‚Üí Conclude.‚Äù**\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286949e7-64cd-4374-8937-c12ec1175c5d",
   "metadata": {},
   "source": [
    "> # `performing a Z-test`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7248d6e-294a-4186-92dc-ec86f25af024",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Z-Test**\n",
    "\n",
    "## **1. When to Use Z-Test**\n",
    "\n",
    "* Population standard deviation (œÉ) is known.\n",
    "* Sample size is large (**n ‚â• 30**) ‚Üí CLT applies.\n",
    "* Data is approximately normally distributed.\n",
    "\n",
    "Common uses:\n",
    "\n",
    "* Test a population **mean**.\n",
    "* Test a population **proportion**.\n",
    "* Compare **two population means** (large n).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Formula for Z-Test (One Sample Mean)**\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\bar{X} - \\mu_0}{\\sigma / \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\bar{X}$ = sample mean\n",
    "* $\\mu_0$ = hypothesized population mean (from H‚ÇÄ)\n",
    "* $\\sigma$ = population standard deviation\n",
    "* $n$ = sample size\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Steps**\n",
    "\n",
    "1. **State Hypotheses**\n",
    "   Example: A company claims battery life = 10 hours.\n",
    "\n",
    "   * $H‚ÇÄ: \\mu = 10$\n",
    "   * $H‚ÇÅ: \\mu \\neq 10$ (two-tailed)\n",
    "\n",
    "2. **Set Œ± (significance level)**\n",
    "\n",
    "   * Example: Œ± = 0.05 ‚Üí critical Z = ¬±1.96.\n",
    "\n",
    "3. **Calculate Test Statistic**\n",
    "   Suppose:\n",
    "\n",
    "   * $\\bar{X} = 9.5$, œÉ = 1.8, n = 36.\n",
    "\n",
    "   $$\n",
    "   Z = \\frac{9.5 - 10}{1.8/\\sqrt{36}} \n",
    "   = \\frac{-0.5}{0.3} \n",
    "   = -1.67\n",
    "   $$\n",
    "\n",
    "4. **Decision Rule**\n",
    "\n",
    "   * If $|Z| > 1.96$, reject H‚ÇÄ.\n",
    "   * Here, $|-1.67| < 1.96$.\n",
    "\n",
    "5. **Conclusion**\n",
    "\n",
    "   * Fail to reject H‚ÇÄ ‚Üí no significant evidence battery life is different from 10 hours.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Z-Test for Proportion (bonus)**\n",
    "\n",
    "If testing population proportion $p$:\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\hat{p} - p_0}{\\sqrt{p_0 (1 - p_0) / n}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**In short:** Z-test compares your sample mean (or proportion) with the hypothesized population value, using the standard error to scale differences.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d3d466-2fa7-412e-a1b0-91def861dd01",
   "metadata": {},
   "source": [
    "> # `Rejection Region Approach`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae549107-8ed8-4771-ba00-4a90f9cffb6d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "# Rejection Region Approach\n",
    "\n",
    "## **1. Idea**\n",
    "\n",
    "* Instead of calculating a p-value, we decide by comparing the **test statistic** (Z, t, œá¬≤, etc.) to a **critical value**.\n",
    "* The **rejection region** is the set of values for which we reject $H‚ÇÄ$.\n",
    "* It depends on:\n",
    "\n",
    "  * The **significance level (Œ±)**.\n",
    "  * Whether the test is **one-tailed** or **two-tailed**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Steps**\n",
    "\n",
    "1. **State Hypotheses**\n",
    "   Example: $H‚ÇÄ: \\mu = 50,\\; H‚ÇÅ: \\mu > 50$.\n",
    "\n",
    "2. **Choose Œ± (say 0.05)**.\n",
    "\n",
    "3. **Determine the Critical Value(s)**\n",
    "\n",
    "   * Look up the Z or t distribution.\n",
    "   * For a **one-tailed test** (Œ± = 0.05): critical Z = 1.645.\n",
    "   * For a **two-tailed test** (Œ± = 0.05): critical Z = ¬±1.96.\n",
    "\n",
    "4. **Compute the Test Statistic**\n",
    "\n",
    "   * Formula:\n",
    "\n",
    "     $$\n",
    "     Z = \\frac{\\bar{X} - \\mu_0}{\\sigma / \\sqrt{n}}\n",
    "     $$\n",
    "\n",
    "5. **Decision Rule**\n",
    "\n",
    "   * If the test statistic **falls in the rejection region**, reject $H‚ÇÄ$.\n",
    "   * If not, fail to reject $H‚ÇÄ$.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Example (Two-Tailed Z-Test)**\n",
    "\n",
    "Claim: Population mean = 100.\n",
    "Sample: $\\bar{X} = 104,\\; \\sigma = 12,\\; n = 36$.\n",
    "Test at Œ± = 0.05.\n",
    "\n",
    "1. $H‚ÇÄ: \\mu = 100,\\; H‚ÇÅ: \\mu \\neq 100$.\n",
    "2. Œ± = 0.05 ‚Üí critical Z = ¬±1.96.\n",
    "3. Compute:\n",
    "\n",
    "   $$\n",
    "   Z = \\frac{104 - 100}{12/\\sqrt{36}} \n",
    "   = \\frac{4}{2} \n",
    "   = 2.0\n",
    "   $$\n",
    "4. Decision: Since $Z = 2.0 > 1.96$, reject $H‚ÇÄ$.\n",
    "5. Conclusion: Mean is significantly different from 100.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Visualization (Mental Picture)**\n",
    "\n",
    "* Imagine the normal bell curve.\n",
    "* Shade Œ± = 0.05 at the tails ‚Üí these are the **rejection regions**.\n",
    "* If your Z lands inside the shaded area, reject $H‚ÇÄ$.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Difference from p-value method:**\n",
    "\n",
    "* **Rejection region:** Compare test statistic to critical value.\n",
    "* **p-value method:** Compare p-value to Œ±.\n",
    "* Both give the same conclusion, just different perspectives.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203586b7-4451-4f52-9c1a-cca6f45c5359",
   "metadata": {},
   "source": [
    "> # `Type 1 Vs Type 2 Errors`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b65d1a1-2f3a-43e3-b1bc-3e06219a7474",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "# **Type I vs Type II Errors**\n",
    "\n",
    "## **1. The Setup**\n",
    "\n",
    "In hypothesis testing, we make a decision about the **null hypothesis (H‚ÇÄ)**:\n",
    "\n",
    "* **Reject H‚ÇÄ**\n",
    "* **Fail to reject H‚ÇÄ**\n",
    "\n",
    "But mistakes can happen depending on the **truth in the population**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. The Two Types of Errors**\n",
    "\n",
    "###  **Type I Error (Œ±)**\n",
    "\n",
    "* **Definition:** Rejecting $H‚ÇÄ$ when it is actually true.\n",
    "* Analogy: Convicting an innocent person.\n",
    "* Probability of Type I Error = **Œ±** (the significance level).\n",
    "* Example: Claiming a new drug works when in fact it doesn‚Äôt.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Type II Error (Œ≤)**\n",
    "\n",
    "* **Definition:** Failing to reject $H‚ÇÄ$ when it is actually false.\n",
    "* Analogy: Letting a guilty person go free.\n",
    "* Probability of Type II Error = **Œ≤**.\n",
    "* Example: Missing the fact that a new drug actually works (concluding it doesn‚Äôt).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Power of a Test**\n",
    "\n",
    "* **Power = 1 ‚Äì Œ≤**\n",
    "* Probability of correctly rejecting a false $H‚ÇÄ$.\n",
    "* A powerful test = low chance of Type II Error.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Summary Table**\n",
    "\n",
    "| Reality ‚Üì / Decision ‚Üí | Fail to Reject H‚ÇÄ | Reject H‚ÇÄ      |\n",
    "| ---------------------- | ----------------- | -------------- |\n",
    "| H‚ÇÄ True                | ‚úÖ Correct         | ‚ùå Type I Error |\n",
    "| H‚ÇÄ False               | ‚ùå Type II Error   | ‚úÖ Correct      |\n",
    "\n",
    "---\n",
    "\n",
    "## **5. In Machine Learning**\n",
    "\n",
    "* **Type I Error (False Positive):** Model predicts spam when the email is not spam.\n",
    "* **Type II Error (False Negative):** Model misses spam (predicts not spam when it is spam).\n",
    "* Choosing Œ± balances the trade-off between the two.\n",
    "\n",
    "---\n",
    "\n",
    "**Mnemonic:**\n",
    "\n",
    "* **Type I = False Alarm** (crying wolf when there is no wolf).\n",
    "* **Type II = Missed Detection** (not crying wolf when there is one).\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aec6e3-cb74-4790-a24f-770388133b98",
   "metadata": {},
   "source": [
    "> # `One Sided vs 2 sided tests`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6893b81-b788-45ba-a5e1-47ad365d6f73",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **One-Sided vs Two-Sided Tests**\n",
    "\n",
    "## **1. Two-Sided (Two-Tailed) Test**\n",
    "\n",
    "* **Hypotheses:**\n",
    "\n",
    "  * $H_0: \\mu = \\mu_0$\n",
    "  * $H_1: \\mu \\neq \\mu_0$\n",
    "* We test for **any difference** (greater or smaller).\n",
    "* Rejection regions: both **tails** of the distribution.\n",
    "* Example: A company claims average battery life = 10 hrs. You want to test if it‚Äôs **different from 10** (could be less OR more).\n",
    "\n",
    "Critical Z values (Œ± = 0.05): ¬±1.96.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. One-Sided (One-Tailed) Test**\n",
    "\n",
    "* **Hypotheses:**\n",
    "\n",
    "  * Right-tailed:\n",
    "\n",
    "    * $H_0: \\mu \\leq \\mu_0$\n",
    "    * $H_1: \\mu > \\mu_0$\n",
    "  * Left-tailed:\n",
    "\n",
    "    * $H_0: \\mu \\geq \\mu_0$\n",
    "    * $H_1: \\mu < \\mu_0$\n",
    "* Tests for a **specific direction** (greater than OR less than, not both).\n",
    "* Rejection region: only **one tail**.\n",
    "* Example: Testing if a new medicine **increases survival rate** compared to standard. You only care if it‚Äôs better, not worse.\n",
    "\n",
    "Critical Z value (Œ± = 0.05): 1.645 (right tail) or ‚Äì1.645 (left tail).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Key Differences**\n",
    "\n",
    "| Feature                                  | One-Sided Test                          | Two-Sided Test     |\n",
    "| ---------------------------------------- | --------------------------------------- | ------------------ |\n",
    "| Direction                                | Specific (>, <)                         | Any difference (‚â†) |\n",
    "| Rejection region                         | One tail                                | Both tails         |\n",
    "| Power (for true effect in one direction) | More powerful                           | Less powerful      |\n",
    "| Risk                                     | Might miss effect in opposite direction | More conservative  |\n",
    "\n",
    "---\n",
    "\n",
    "## **4. In Machine Learning**\n",
    "\n",
    "* One-sided: Testing if **model A‚Äôs accuracy > model B‚Äôs accuracy**.\n",
    "* Two-sided: Testing if **model A‚Äôs accuracy ‚â† model B‚Äôs accuracy** (could be better OR worse).\n",
    "\n",
    "---\n",
    "\n",
    "**Rule of thumb:**\n",
    "\n",
    "* Use **two-sided** unless you have a strong prior reason to expect an effect only in one direction.\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f1f4f-fa4a-4ce6-b03c-6cf21e5894cc",
   "metadata": {},
   "source": [
    "> # `Statistical Power`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c071324a-81a2-4369-8b9e-d52a87f08289",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "###  What is Statistical Power?\n",
    "\n",
    "* **Definition:** The probability of correctly rejecting the null hypothesis (**H‚ÇÄ**) when the alternative hypothesis (**H‚ÇÅ**) is true.\n",
    "* In short: it tells us **how good a test is at detecting a real effect**.\n",
    "\n",
    "Formula (conceptually):\n",
    "\n",
    "$$\n",
    "\\text{Power} = 1 - \\beta\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* **Œ≤ (Type II Error):** Probability of failing to reject H‚ÇÄ when H‚ÇÅ is actually true.\n",
    "* So, **higher power = lower risk of missing a real effect**.\n",
    "\n",
    "---\n",
    "\n",
    "###  Why is Power Important?\n",
    "\n",
    "* A test with **low power** might miss real effects ‚Üí false negatives.\n",
    "* Researchers usually aim for **80% power** (0.8) ‚Üí means if the effect is real, we‚Äôll catch it 8 times out of 10.\n",
    "\n",
    "---\n",
    "\n",
    "###  Factors Affecting Statistical Power\n",
    "\n",
    "1. **Sample Size (n):** Larger samples = higher power.\n",
    "2. **Effect Size:** Bigger effect = easier to detect ‚Üí higher power.\n",
    "3. **Significance Level (Œ±):** Larger Œ± (e.g., 0.10 instead of 0.05) increases power but also increases chance of Type I error.\n",
    "4. **Variability (œÉ¬≤):** Less noise = higher power.\n",
    "\n",
    "---\n",
    "\n",
    "###  Simple Example\n",
    "\n",
    "Suppose we want to test if a new medicine lowers blood pressure:\n",
    "\n",
    "* **H‚ÇÄ:** No difference (medicine = placebo).\n",
    "\n",
    "* **H‚ÇÅ:** Medicine lowers BP.\n",
    "\n",
    "* If the medicine truly works, a **powerful test** will detect it.\n",
    "\n",
    "* A **low-power test** might miss it and wrongly conclude the medicine doesn‚Äôt work.\n",
    "\n",
    "---\n",
    "\n",
    "**Memory Trick:**\n",
    "\n",
    "* **Type I error (Œ±):** False alarm.\n",
    "* **Type II error (Œ≤):** Missed detection.\n",
    "* **Power = 1 - Œ≤:** Ability to catch the signal when it‚Äôs really there.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6e1a85-328b-4965-9b91-be23b66e127b",
   "metadata": {},
   "source": [
    "> # `P-Value`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a03708-fcf9-4c9a-9e39-d7e360337ea5",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **P-Value**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "The **p-value** is the **probability of observing the sample data (or something more extreme) assuming the null hypothesis $H_0$ is true**.\n",
    "\n",
    "In simple words:\n",
    "\n",
    "* It measures how **compatible your data** is with the null hypothesis.\n",
    "* Smaller p-value ‚Üí less compatible ‚Üí stronger evidence against $H_0$.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Interpreting the P-Value**\n",
    "\n",
    "* **p ‚â§ Œ±:** Reject $H_0$ (data is unlikely under H‚ÇÄ)\n",
    "* **p > Œ±:** Fail to reject $H_0$ (data is consistent with H‚ÇÄ)\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Relationship to Significance Level**\n",
    "\n",
    "* Œ± = significance level (common: 0.05, 0.01)\n",
    "* p-value is **compared to Œ±**:\n",
    "\n",
    "  * If **p < 0.05**, result is statistically significant.\n",
    "  * If **p ‚â• 0.05**, result is not significant.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Example**\n",
    "\n",
    "A sample of 36 phones has mean battery = 9.5, population mean = 10, œÉ = 1.8.\n",
    "\n",
    "* Compute Z = -1.67 (from previous Z-test example).\n",
    "* **Two-tailed p-value**:\n",
    "\n",
    "$$\n",
    "p = 2 \\cdot P(Z \\le -1.67) \\approx 2 \\cdot 0.0475 = 0.095\n",
    "$$\n",
    "\n",
    "* Compare to Œ± = 0.05 ‚Üí **p > 0.05**, fail to reject $H_0$.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Misconceptions**\n",
    "\n",
    "* ‚ùå P-value is **not** the probability that $H_0$ is true.\n",
    "* ‚ùå P-value is **not** the probability that results happened by chance.\n",
    "* ‚úÖ It‚Äôs the probability of seeing data as extreme (or more extreme) if H‚ÇÄ is true.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. In Machine Learning**\n",
    "\n",
    "* Test if a feature **significantly correlates with target**.\n",
    "* Compare **model performance metrics** between two models.\n",
    "* Evaluate **A/B testing** results for algorithm changes.\n",
    "\n",
    "---\n",
    "\n",
    "**Mnemonic:**\n",
    "**‚Äúp-value = How surprising is my data if H‚ÇÄ were true?‚Äù**\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b9282f-ea56-40f6-82a9-9d1582c0f39e",
   "metadata": {},
   "source": [
    "> # `How to interpret P-values`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb26459-71a5-4664-9e6d-a5e9d4a1b363",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Interpreting P-Values**\n",
    "\n",
    "## **1. Compare P-Value to Significance Level (Œ±)**\n",
    "\n",
    "* **Step 1:** Choose a significance level Œ± (common choices: 0.05 or 0.01).\n",
    "* **Step 2:** Look at your p-value.\n",
    "\n",
    "  * **p ‚â§ Œ± ‚Üí Reject H‚ÇÄ** (evidence suggests an effect exists)\n",
    "  * **p > Œ± ‚Üí Fail to reject H‚ÇÄ** (insufficient evidence to claim an effect)\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Understanding the Magnitude**\n",
    "\n",
    "* **Very small p-value (e.g., < 0.01)** ‚Üí Strong evidence **against H‚ÇÄ**.\n",
    "* **Moderate p-value (e.g., 0.01 ‚Äì 0.05)** ‚Üí Moderate evidence **against H‚ÇÄ**.\n",
    "* **Large p-value (e.g., > 0.05)** ‚Üí Weak or no evidence **against H‚ÇÄ**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Examples**\n",
    "\n",
    "| P-value | Interpretation                              |\n",
    "| ------- | ------------------------------------------- |\n",
    "| 0.001   | Very strong evidence against H‚ÇÄ ‚Üí reject H‚ÇÄ |\n",
    "| 0.03    | Strong evidence against H‚ÇÄ ‚Üí reject H‚ÇÄ      |\n",
    "| 0.07    | Weak evidence ‚Üí fail to reject H‚ÇÄ           |\n",
    "| 0.5     | No evidence ‚Üí fail to reject H‚ÇÄ             |\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Common Misinterpretations**\n",
    "\n",
    "* ‚ùå A p-value is **not** the probability that H‚ÇÄ is true.\n",
    "* ‚ùå A p-value is **not** the probability that your data happened by chance.\n",
    "* ‚úÖ Correct view: **P-value = probability of observing your data (or more extreme) if H‚ÇÄ were true.**\n",
    "\n",
    "---\n",
    "\n",
    "## **5. P-Values in Machine Learning**\n",
    "\n",
    "* Determine whether a **feature is statistically significant** for prediction.\n",
    "* Test whether **model improvements** are meaningful.\n",
    "* Evaluate **A/B tests** for algorithm changes in production.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick tip:**\n",
    "\n",
    "* **Small p-value ‚Üí reject H‚ÇÄ** ‚Üí effect likely exists.\n",
    "* **Large p-value ‚Üí fail to reject H‚ÇÄ** ‚Üí effect not supported.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79093dc1-13d4-4180-b6e0-adedeb571809",
   "metadata": {},
   "source": [
    "> # `Types of Hypothesis Tests`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35f93c-0053-4bb0-b088-61963ae7046b",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Types of Hypothesis Tests**\n",
    "\n",
    "## **1. Z-Test**\n",
    "\n",
    "* **Purpose:** Test a population mean (or proportion) when **œÉ is known** or **large sample size (n ‚â• 30)**.\n",
    "* **Types:**\n",
    "\n",
    "  * **One-sample Z-test** ‚Üí Compare sample mean to population mean.\n",
    "  * **Two-sample Z-test** ‚Üí Compare means of two independent samples.\n",
    "  * **Proportion Z-test** ‚Üí Test population proportion.\n",
    "* **Example:** Is the average battery life of phones = 10 hours?\n",
    "\n",
    "---\n",
    "\n",
    "## **2. T-Test**\n",
    "\n",
    "* **Purpose:** Test means when **population œÉ unknown** and/or **small sample size (n < 30)**.\n",
    "* **Types:**\n",
    "\n",
    "  1. **One-sample t-test** ‚Üí Compare sample mean to hypothesized mean.\n",
    "  2. **Independent two-sample t-test** ‚Üí Compare means of two independent groups.\n",
    "  3. **Paired t-test** ‚Üí Compare means of **related samples** (before-after studies).\n",
    "* **Example:** Does a new teaching method increase student scores compared to old method?\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Chi-Square Test (œá¬≤)**\n",
    "\n",
    "* **Purpose:** Test relationships between **categorical variables**.\n",
    "* **Types:**\n",
    "\n",
    "  1. **Chi-square goodness-of-fit** ‚Üí Does observed data fit a specific distribution?\n",
    "  2. **Chi-square test of independence** ‚Üí Are two categorical variables independent?\n",
    "* **Example:** Is gender independent of preference for a product?\n",
    "\n",
    "---\n",
    "\n",
    "## **4. ANOVA (Analysis of Variance)**\n",
    "\n",
    "* **Purpose:** Compare **means of 3 or more groups**.\n",
    "* **One-way ANOVA:** One factor, multiple groups.\n",
    "* **Two-way ANOVA:** Two factors.\n",
    "* **Example:** Do exam scores differ across three teaching methods?\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Non-Parametric Tests**\n",
    "\n",
    "* Used when **data doesn‚Äôt meet normality assumptions**.\n",
    "* Examples:\n",
    "\n",
    "  * **Mann-Whitney U Test** ‚Üí Compare two independent samples.\n",
    "  * **Wilcoxon Signed-Rank Test** ‚Üí Paired samples.\n",
    "  * **Kruskal-Wallis Test** ‚Üí Compare more than two groups.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Other Specialized Tests**\n",
    "\n",
    "* **F-Test:** Compare variances of two populations.\n",
    "* **Proportion Test:** Compare population proportions (one-sample or two-sample).\n",
    "* **Correlation Tests:** Test if correlation ‚â† 0 (e.g., Pearson correlation).\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Summary:**\n",
    "\n",
    "| Test Type      | Data Type             | Purpose                              |\n",
    "| -------------- | --------------------- | ------------------------------------ |\n",
    "| Z-test         | Continuous            | Known œÉ, test mean or proportion     |\n",
    "| T-test         | Continuous            | Unknown œÉ, small sample              |\n",
    "| Chi-square     | Categorical           | Test independence or goodness-of-fit |\n",
    "| ANOVA          | Continuous            | Compare 3+ group means               |\n",
    "| Non-parametric | Continuous or Ordinal | Data doesn‚Äôt fit normality           |\n",
    "\n",
    "---\n",
    "\n",
    "**ML Connection:**\n",
    "\n",
    "* **T-tests & ANOVA:** Compare model metrics across groups.\n",
    "* **Chi-square:** Feature selection for categorical variables.\n",
    "* **Non-parametric tests:** Useful when data is skewed or ordinal.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c947e742-a1e7-42e2-a689-1a6d66274521",
   "metadata": {},
   "source": [
    "> # `Z-Test`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f01a21-3f9f-4dfe-891e-0541b0e11725",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Z-Test**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "A **Z-test** is a statistical test used to determine if there is a **significant difference** between a sample mean (or proportion) and a population mean (or proportion), **when the population standard deviation (œÉ) is known** or the sample size is large (n ‚â• 30).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Types of Z-Tests**\n",
    "\n",
    "1. **One-Sample Z-Test**\n",
    "\n",
    "   * Compare a **sample mean** to a **known population mean**.\n",
    "   * Example: Is the average battery life of 36 phones different from 10 hours?\n",
    "\n",
    "2. **Two-Sample Z-Test**\n",
    "\n",
    "   * Compare the means of **two independent samples**.\n",
    "   * Example: Compare average exam scores of students in Class A vs Class B.\n",
    "\n",
    "3. **Z-Test for Proportions**\n",
    "\n",
    "   * Compare a sample proportion with a population proportion or compare **two proportions**.\n",
    "   * Example: Is the proportion of students passing a test different from 0.8?\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Formula**\n",
    "\n",
    "### **One-Sample Z-Test (Mean)**\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\bar{X} - \\mu_0}{\\sigma / \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\bar{X}$ = sample mean\n",
    "* $\\mu_0$ = population mean (H‚ÇÄ)\n",
    "* œÉ = population standard deviation\n",
    "* n = sample size\n",
    "\n",
    "---\n",
    "\n",
    "### **Two-Sample Z-Test (Mean)**\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Z-Test for Proportion**\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\hat{p} - p_0}{\\sqrt{p_0(1-p_0)/n}}\n",
    "$$\n",
    "\n",
    "* $\\hat{p}$ = sample proportion\n",
    "* $p_0$ = population proportion\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Steps to Perform Z-Test**\n",
    "\n",
    "1. **State Hypotheses**\n",
    "\n",
    "   * Example: H‚ÇÄ: Œº = 10, H‚ÇÅ: Œº ‚â† 10\n",
    "\n",
    "2. **Choose Œ± (significance level)**\n",
    "\n",
    "   * Usually 0.05 ‚Üí Z critical = ¬±1.96 for two-tailed test\n",
    "\n",
    "3. **Compute Z statistic** using formula\n",
    "\n",
    "4. **Decision Rule**\n",
    "\n",
    "   * If |Z| > Z critical ‚Üí reject H‚ÇÄ\n",
    "   * If |Z| ‚â§ Z critical ‚Üí fail to reject H‚ÇÄ\n",
    "\n",
    "5. **Conclusion**\n",
    "\n",
    "   * Interpret in context of the problem\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Example (One-Sample Z-Test)**\n",
    "\n",
    "* Sample: n = 36 phones, mean battery life = 9.5 hrs\n",
    "* Population mean: Œº‚ÇÄ = 10 hrs, œÉ = 1.8\n",
    "\n",
    "$$\n",
    "Z = \\frac{9.5 - 10}{1.8 / \\sqrt{36}} = \\frac{-0.5}{0.3} = -1.67\n",
    "$$\n",
    "\n",
    "* Critical Z = ¬±1.96 (Œ± = 0.05, two-tailed)\n",
    "* |‚Äì1.67| < 1.96 ‚Üí **Fail to reject H‚ÇÄ**\n",
    "* Conclusion: No significant difference in battery life.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. When to Use Z-Test**\n",
    "\n",
    "* Large sample size (n ‚â• 30)\n",
    "* Known population œÉ\n",
    "* Data roughly normally distributed\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Machine Learning Connection**\n",
    "\n",
    "* Compare model accuracies to a benchmark.\n",
    "* Compare conversion rates in A/B tests.\n",
    "* Feature significance testing for continuous variables.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Memory Trick:**\n",
    "**Z-Test = ‚ÄúHow many standard errors away is my sample mean from the population mean?‚Äù**\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d71833-32db-4d48-b736-4f0b58d4d224",
   "metadata": {},
   "source": [
    "> # `T-Test`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1882171e-14a2-4e11-87f0-01a0c7f3d62e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **T-Test**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "A **t-test** is a statistical test used to compare **means** when:\n",
    "\n",
    "* The **population standard deviation (œÉ) is unknown**\n",
    "* The **sample size is small (n < 30)**\n",
    "\n",
    "It uses the **t-distribution**, which is similar to the normal distribution but has **fatter tails** to account for more variability in small samples.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Types of T-Tests**\n",
    "\n",
    "### **a) One-Sample T-Test**\n",
    "\n",
    "* Compare a **sample mean** to a **known or hypothesized population mean**.\n",
    "* Example: Does the average test score of 15 students differ from 75?\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\bar{X}$ = sample mean\n",
    "* $s$ = sample standard deviation\n",
    "* n = sample size\n",
    "* $\\mu_0$ = hypothesized population mean\n",
    "\n",
    "---\n",
    "\n",
    "### **b) Independent Two-Sample T-Test**\n",
    "\n",
    "* Compare **means of two independent groups**.\n",
    "* Example: Compare exam scores of Class A vs Class B.\n",
    "\n",
    "**Formula (assuming equal variances):**\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n",
    "$$\n",
    "\n",
    "Where $s_p$ = pooled standard deviation:\n",
    "\n",
    "$$\n",
    "s_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **c) Paired Sample T-Test**\n",
    "\n",
    "* Compare **means of two related samples** (before-after, matched pairs).\n",
    "* Example: Student scores **before and after** a new teaching method.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{d}}{s_d / \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\bar{d}$ = mean of differences\n",
    "* $s_d$ = standard deviation of differences\n",
    "* n = number of pairs\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Steps to Perform a T-Test**\n",
    "\n",
    "1. **State Hypotheses**\n",
    "\n",
    "   * Example: H‚ÇÄ: Œº = 75, H‚ÇÅ: Œº ‚â† 75\n",
    "\n",
    "2. **Choose Œ± (significance level)**, usually 0.05\n",
    "\n",
    "3. **Compute t statistic** using the formula\n",
    "\n",
    "4. **Compare with Critical t value** (from t-table, depends on df = n‚Äì1) or use **p-value**\n",
    "\n",
    "5. **Decision**\n",
    "\n",
    "   * |t| > t critical ‚Üí reject H‚ÇÄ\n",
    "   * |t| ‚â§ t critical ‚Üí fail to reject H‚ÇÄ\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Example (One-Sample T-Test)**\n",
    "\n",
    "* Sample: n = 10 students, mean = 78, sample sd = 5\n",
    "* Population mean: Œº‚ÇÄ = 75\n",
    "\n",
    "$$\n",
    "t = \\frac{78 - 75}{5 / \\sqrt{10}} = \\frac{3}{1.58} \\approx 1.90\n",
    "$$\n",
    "\n",
    "* df = 10‚Äì1 = 9\n",
    "* Œ± = 0.05 ‚Üí two-tailed t critical ‚âà ¬±2.262\n",
    "* |1.90| < 2.262 ‚Üí **Fail to reject H‚ÇÄ**\n",
    "\n",
    "---\n",
    "\n",
    "## **5. When to Use T-Test**\n",
    "\n",
    "* **Unknown œÉ**\n",
    "* **Small sample (n < 30)**\n",
    "* Data roughly **normally distributed**\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Machine Learning Applications**\n",
    "\n",
    "* Compare **model performance metrics** for small datasets.\n",
    "* Test whether a **feature significantly affects target**.\n",
    "* Compare **before-after effect of algorithm changes**.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Memory Trick:**\n",
    "\n",
    "* **Z-test:** œÉ known or large n\n",
    "* **T-test:** œÉ unknown, small n\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abedd13f-7c00-4a22-a3f0-d5f80a323563",
   "metadata": {},
   "source": [
    "> # `Chi-square Test`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f88d093-d6b0-49e9-b93e-034db926e3ad",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Chi-Square (œá¬≤) Test**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "The **Chi-Square test** is a **non-parametric statistical test** used to examine whether there is a significant association between **categorical variables** or whether an observed frequency distribution matches an expected distribution.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Types of Chi-Square Tests**\n",
    "\n",
    "### **a) Chi-Square Goodness-of-Fit Test**\n",
    "\n",
    "* **Purpose:** Test if a **single categorical variable** follows a specific distribution.\n",
    "* **Example:** Are dice rolls uniform across 1‚Äì6?\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $O_i$ = observed frequency\n",
    "* $E_i$ = expected frequency\n",
    "\n",
    "---\n",
    "\n",
    "### **b) Chi-Square Test of Independence**\n",
    "\n",
    "* **Purpose:** Test if **two categorical variables are independent**.\n",
    "* **Example:** Is gender independent of choosing a computer course?\n",
    "\n",
    "**Formula (same as above):**\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $O_{ij}$ = observed frequency in cell i,j\n",
    "* $E_{ij} = \\frac{(\\text{row total} \\cdot \\text{column total})}{\\text{grand total}}$\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Steps to Perform Chi-Square Test**\n",
    "\n",
    "1. **State Hypotheses**\n",
    "\n",
    "   * Goodness-of-fit: H‚ÇÄ = observed frequencies match expected\n",
    "   * Independence: H‚ÇÄ = variables are independent\n",
    "\n",
    "2. **Set significance level Œ±** (common: 0.05)\n",
    "\n",
    "3. **Calculate œá¬≤ statistic** using observed and expected frequencies\n",
    "\n",
    "4. **Find critical œá¬≤ value** from œá¬≤ table with appropriate **degrees of freedom (df)**:\n",
    "\n",
    "   * Goodness-of-fit: df = number of categories ‚Äì 1\n",
    "   * Independence: df = (rows‚Äì1) √ó (columns‚Äì1)\n",
    "\n",
    "5. **Decision**\n",
    "\n",
    "   * œá¬≤ > œá¬≤ critical ‚Üí reject H‚ÇÄ\n",
    "   * œá¬≤ ‚â§ œá¬≤ critical ‚Üí fail to reject H‚ÇÄ\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Example (Test of Independence)**\n",
    "\n",
    "Survey of 100 students:\n",
    "\n",
    "* **Gender:** Male/Female\n",
    "* **Course Preference:** Data Science / AI\n",
    "\n",
    "|        | DS | AI | Total |\n",
    "| ------ | -- | -- | ----- |\n",
    "| Male   | 20 | 30 | 50    |\n",
    "| Female | 25 | 25 | 50    |\n",
    "| Total  | 45 | 55 | 100   |\n",
    "\n",
    "**Expected frequencies:**\n",
    "\n",
    "* Male & DS = (50 √ó 45)/100 = 22.5\n",
    "* Male & AI = (50 √ó 55)/100 = 27.5\n",
    "* Female & DS = 22.5, Female & AI = 27.5\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\frac{(20-22.5)^2}{22.5} + \\frac{(30-27.5)^2}{27.5} + \\frac{(25-22.5)^2}{22.5} + \\frac{(25-27.5)^2}{27.5} \\approx 1.36\n",
    "$$\n",
    "\n",
    "* df = (2‚Äì1) √ó (2‚Äì1) = 1\n",
    "* œá¬≤ critical at Œ± = 0.05 ‚Üí 3.841\n",
    "* 1.36 < 3.841 ‚Üí **Fail to reject H‚ÇÄ** ‚Üí Gender and course preference are independent\n",
    "\n",
    "---\n",
    "\n",
    "## **5. When to Use**\n",
    "\n",
    "* Data is **categorical**\n",
    "* Observations are **independent**\n",
    "* Expected frequency in each cell ‚â• 5 (rule of thumb)\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Machine Learning Applications**\n",
    "\n",
    "* Feature selection: test if categorical features are **dependent on target**\n",
    "* Market research: test if user preferences differ by demographics\n",
    "* A/B testing for categorical outcomes\n",
    "\n",
    "---\n",
    "\n",
    "**Mnemonic:**\n",
    "\n",
    "* **Goodness-of-fit ‚Üí single variable**\n",
    "* **Independence ‚Üí two variables**\n",
    "* œá¬≤ measures **difference between observed & expected frequencies**\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec06f9e-4a51-42fc-8abc-138a8b36a222",
   "metadata": {},
   "source": [
    "> # `ANOVA (Analysis of Variance)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3e58a0-8321-4993-be40-e8aa5b25314e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "# **ANOVA (Analysis of Variance)**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "ANOVA is a statistical test used to determine if there are **significant differences between the means of 3 or more groups**.\n",
    "\n",
    "* Instead of doing multiple t-tests (which increases error risk), ANOVA compares all group means **in one test**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Idea Behind ANOVA**\n",
    "\n",
    "It looks at **variability** in data:\n",
    "\n",
    "* **Between-group variability**: how much the group means differ from each other.\n",
    "* **Within-group variability**: how much individuals differ within each group.\n",
    "\n",
    "**If between > within ‚Üí groups are significantly different.**\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Hypotheses**\n",
    "\n",
    "* **Null hypothesis (H‚ÇÄ):** All group means are equal.\n",
    "* **Alternative hypothesis (H‚ÇÅ):** At least one mean is different.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Types of ANOVA**\n",
    "\n",
    "1. **One-way ANOVA**\n",
    "\n",
    "   * One factor (independent variable), 3+ groups.\n",
    "   * Example: Do exam scores differ across three teaching methods?\n",
    "\n",
    "2. **Two-way ANOVA**\n",
    "\n",
    "   * Two factors (e.g., teaching method **and** gender).\n",
    "   * Tests main effects + interaction effects.\n",
    "\n",
    "3. **Repeated Measures ANOVA**\n",
    "\n",
    "   * Same subjects measured under different conditions.\n",
    "   * Example: Blood pressure measured before, during, and after treatment.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Test Statistic (F-ratio)**\n",
    "\n",
    "$$\n",
    "F = \\frac{\\text{Between-group variance}}{\\text{Within-group variance}}\n",
    "$$\n",
    "\n",
    "* If **F is large**, groups differ significantly.\n",
    "* Compare with **F-critical** value from F-distribution (df between, df within).\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Steps in One-Way ANOVA**\n",
    "\n",
    "1. **State hypotheses** (H‚ÇÄ: Œº‚ÇÅ = Œº‚ÇÇ = Œº‚ÇÉ ‚Ä¶).\n",
    "2. **Set significance level (Œ± = 0.05)**.\n",
    "3. **Calculate F-statistic** (ANOVA table).\n",
    "4. **Compare F with critical F** or check **p-value**.\n",
    "\n",
    "   * If p < Œ± ‚Üí reject H‚ÇÄ.\n",
    "5. If significant ‚Üí do **post-hoc tests** (like Tukey‚Äôs HSD) to see **which groups differ**.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Example (One-Way ANOVA)**\n",
    "\n",
    "Suppose exam scores of students taught by 3 methods:\n",
    "\n",
    "* Method A: [85, 90, 88]\n",
    "* Method B: [78, 74, 80]\n",
    "* Method C: [92, 95, 91]\n",
    "\n",
    "ANOVA compares:\n",
    "\n",
    "* Between-group variance (differences in averages).\n",
    "* Within-group variance (spread inside each method).\n",
    "\n",
    "If F = 12.5 and p < 0.05 ‚Üí reject H‚ÇÄ ‚Üí teaching methods differ.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Applications in Machine Learning**\n",
    "\n",
    "* Model comparison: Compare accuracy across 3+ ML models.\n",
    "* Feature testing: Compare outcomes across multiple categories of a feature.\n",
    "* A/B/n testing: Test if multiple experimental groups differ significantly.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Limitations**\n",
    "\n",
    "* Assumes **normality** and **equal variances** across groups.\n",
    "* If violated ‚Üí use **non-parametric alternatives** (Kruskal-Wallis test).\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic:**\n",
    "\n",
    "* **T-test** = compare 2 means\n",
    "* **ANOVA** = compare 3+ means\n",
    "* **F-test** inside ANOVA tells us if differences are real\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
