{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f08ab35a-5103-4955-8435-77da755cfde1",
   "metadata": {},
   "source": [
    "# `Advanced Statistics Notes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75da83a-4240-4249-a84d-0b4344f543a8",
   "metadata": {},
   "source": [
    "> # `Covariance | Covariance  vs Causation`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205a80cb-f236-4a2e-b58e-659aad329f9e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "# **Covariance**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* **Covariance** measures how **two numerical variables change together**.\n",
    "* If both variables increase/decrease together → **positive covariance**.\n",
    "* If one increases while the other decreases → **negative covariance**.\n",
    "* If no consistent relationship → covariance ≈ 0.\n",
    "\n",
    "**Formula (for two variables X and Y):**\n",
    "\n",
    "$$\n",
    "\\text{Cov}(X, Y) = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{n-1}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Example**\n",
    "\n",
    "* Suppose study hours (X) and exam scores (Y):\n",
    "\n",
    "  * If more hours → higher scores → **positive covariance**.\n",
    "* Suppose exercise (X) and body weight (Y):\n",
    "\n",
    "  * If more exercise → lower weight → **negative covariance**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Limitations**\n",
    "\n",
    "* The **value of covariance is not standardized** → hard to compare.\n",
    "* That’s why we often use **correlation**, which is a scaled version of covariance.\n",
    "\n",
    "---\n",
    "\n",
    "# **Covariance vs Causation**\n",
    "\n",
    "## **Covariance (or Correlation)**\n",
    "\n",
    "* Shows **association** between variables.\n",
    "* Example: Ice cream sales ↑ and temperature ↑ → strong positive covariance.\n",
    "\n",
    "## **Causation**\n",
    "\n",
    "* Implies that **one variable directly affects the other**.\n",
    "* Example: Temperature ↑ → people buy more ice cream (temperature causes ice cream sales).\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Differences**\n",
    "\n",
    "| Aspect    | Covariance / Correlation                            | Causation                                         |\n",
    "| --------- | --------------------------------------------------- | ------------------------------------------------- |\n",
    "| Meaning   | Shows if variables move together                    | Shows if one variable influences the other        |\n",
    "| Direction | Positive, Negative, or None                         | Cause → Effect                                    |\n",
    "| Proof     | From data relationship only                         | Requires controlled experiment or deep reasoning  |\n",
    "| Example   | Shoe size and reading ability may correlate in kids | Age causes both shoe size ↑ and reading ability ↑ |\n",
    "\n",
    "---\n",
    "\n",
    "## **4. In Machine Learning**\n",
    "\n",
    "* **Covariance/Correlation** → used in feature selection, PCA (Principal Component Analysis), detecting multicollinearity.\n",
    "* **Causation** → very hard to prove! Needs experiments (A/B testing), causal inference, or domain knowledge.\n",
    "* ML models often exploit **correlations**, but that doesn’t always mean true causality.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic**:\n",
    "\n",
    "* **Covariance = Moves together?**\n",
    "* **Causation = One makes the other happen.**\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e52ec55-2ac7-4509-93ea-1e778f039ded",
   "metadata": {},
   "source": [
    "> # `Probability Distribution Functions - PDF, PMF & CDF`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e97ca-d2c2-490c-82fc-e3843d67b601",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "# **Probability Distribution Functions**\n",
    "\n",
    "Probability distributions describe **how probabilities are assigned to different outcomes** of a random variable.\n",
    "\n",
    "There are 2 types of random variables:\n",
    "\n",
    "* **Discrete** → countable outcomes (e.g., dice roll, number of students).\n",
    "* **Continuous** → infinite possible values within a range (e.g., height, weight).\n",
    "\n",
    "---\n",
    "\n",
    "## **1. PMF (Probability Mass Function)**\n",
    "\n",
    "* Used for **discrete random variables**.\n",
    "* Assigns a probability to **each possible outcome**.\n",
    "* Properties:\n",
    "\n",
    "  * $P(X = x) \\geq 0$\n",
    "  * $\\sum P(X = x) = 1$\n",
    "\n",
    "**Example (Dice roll):**\n",
    "\n",
    "* PMF:\n",
    "\n",
    "  $$\n",
    "  P(X=x) = \\frac{1}{6}, \\quad x \\in \\{1,2,3,4,5,6\\}\n",
    "  $$\n",
    "\n",
    "**In ML:** PMFs appear in Naive Bayes (discrete features), categorical variables, language models (word counts).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. PDF (Probability Density Function)**\n",
    "\n",
    "* Used for **continuous random variables**.\n",
    "* Probability is **not assigned to a single point** (since infinite values exist), but to an **interval**.\n",
    "* Area under the curve = probability.\n",
    "* Properties:\n",
    "\n",
    "  * $f(x) \\geq 0$\n",
    "  * $\\int_{-\\infty}^{\\infty} f(x) dx = 1$\n",
    "\n",
    "**Example (Normal distribution):**\n",
    "\n",
    "* Bell curve for heights of people.\n",
    "* Probability someone’s height is between 160–170 cm = area under curve between 160 and 170.\n",
    "\n",
    "**In ML:** PDFs appear in density estimation, Gaussian Naive Bayes, anomaly detection, generative models.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. CDF (Cumulative Distribution Function)**\n",
    "\n",
    "* Works for **both discrete and continuous** variables.\n",
    "* Gives the **probability that random variable ≤ x**.\n",
    "* Formula:\n",
    "\n",
    "  $$\n",
    "  F(x) = P(X \\leq x)\n",
    "  $$\n",
    "\n",
    "**Example (Dice roll):**\n",
    "\n",
    "* $F(3) = P(X \\leq 3) = \\frac{3}{6} = 0.5$\n",
    "\n",
    "**Example (Height with Normal PDF):**\n",
    "\n",
    "* If CDF(170) = 0.6 → 60% of people are ≤ 170 cm tall.\n",
    "\n",
    "**In ML:** CDFs are used in hypothesis testing (p-values), probabilistic models, and survival analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## **Quick Comparison**\n",
    "\n",
    "| Function | Variable Type | What it Tells You                                                        |\n",
    "| -------- | ------------- | ------------------------------------------------------------------------ |\n",
    "| **PMF**  | Discrete      | Probability of exact value                                               |\n",
    "| **PDF**  | Continuous    | Probability density at a value (area over an interval gives probability) |\n",
    "| **CDF**  | Both          | Probability variable ≤ a value                                           |\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic**\n",
    "\n",
    "* **PMF → Point probability** (discrete).\n",
    "* **PDF → Density probability** (continuous).\n",
    "* **CDF → Cumulative probability** (up to a point).\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967bd8c2-5d7e-415b-9283-b33637787e6a",
   "metadata": {},
   "source": [
    "> # `Kernel Density Estimation (KDE)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cf294b-b387-4ac6-a968-1a8343c4ce6c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* **KDE** is a **non-parametric** way to estimate the probability density function (PDF) of a random variable.\n",
    "* Unlike a histogram (which is blocky), KDE gives a **smooth curve** that represents the underlying distribution of data.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. How it Works**\n",
    "\n",
    "* Imagine placing a **small “bump” (kernel function)** on each data point.\n",
    "* Add up all these bumps → get a smooth curve (the density estimate).\n",
    "* The **kernel** is usually Gaussian (bell-shaped), but can be others.\n",
    "* The **bandwidth** controls smoothness:\n",
    "\n",
    "  * Small bandwidth → too wiggly (overfits).\n",
    "  * Large bandwidth → too flat (underfits).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Example**\n",
    "\n",
    "Suppose we have exam scores: `[50, 55, 60, 70, 80, 85, 90]`.\n",
    "\n",
    "* Histogram → shows frequencies in bins.\n",
    "* KDE → smooth curve showing how scores are distributed.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Applications in Machine Learning**\n",
    "\n",
    "* **Data Exploration (EDA):** Visualizing feature distributions.\n",
    "* **Outlier Detection:** Peaks vs rare regions.\n",
    "* **Generative Modeling:** Estimating density without assuming a specific distribution.\n",
    "* **Anomaly Detection:** Points with very low KDE density = anomalies.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. KDE vs Histogram**\n",
    "\n",
    "| Aspect     | Histogram                    | KDE                       |\n",
    "| ---------- | ---------------------------- | ------------------------- |\n",
    "| Shape      | Blocky (depends on bin size) | Smooth                    |\n",
    "| Parameters | Bin width                    | Bandwidth                 |\n",
    "| Use Case   | Quick count visualization    | Estimating underlying PDF |\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Quick Analogy**\n",
    "\n",
    "Think of KDE as pouring a drop of **ink (kernel)** at every data point.\n",
    "When all ink drops overlap, they form a **smooth shape** (density curve).\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**:\n",
    "\n",
    "* KDE = Smooth estimate of PDF.\n",
    "* Controlled by **kernel type** and **bandwidth**.\n",
    "* Widely used in ML for **EDA, density estimation, and anomaly detection**.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c35cbf5-c538-44a2-b8e2-2bb29c02badd",
   "metadata": {},
   "source": [
    "> # `Normal Distribution`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2dbbc5-44e4-46fe-a728-98926266713a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* Also called the **Gaussian distribution** (after Carl Friedrich Gauss).\n",
    "* A **continuous probability distribution** shaped like a symmetric \"bell curve.\"\n",
    "* Most natural phenomena (heights, IQ scores, measurement errors) follow it (approximately).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Properties**\n",
    "\n",
    "* **Symmetric** around the mean ($\\mu$).\n",
    "* **Mean = Median = Mode**.\n",
    "* **68-95-99.7 Rule** (Empirical Rule):\n",
    "\n",
    "  * ~68% of data within 1 standard deviation ($\\sigma$).\n",
    "  * ~95% within 2$\\sigma$.\n",
    "  * ~99.7% within 3$\\sigma$.\n",
    "\n",
    "**Probability Density Function (PDF):**\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{ -\\frac{(x-\\mu)^2}{2\\sigma^2} }\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Standard Normal Distribution**\n",
    "\n",
    "* Special case: $\\mu = 0$, $\\sigma = 1$.\n",
    "* Often denoted $Z$.\n",
    "* Used for **Z-scores**:\n",
    "\n",
    "  $$\n",
    "  Z = \\frac{X - \\mu}{\\sigma}\n",
    "  $$\n",
    "* Helps compare different datasets on the same scale.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Applications in Machine Learning**\n",
    "\n",
    "* **Assumption in Models:** Linear regression, logistic regression, Naive Bayes often assume normality (errors or features).\n",
    "* **Feature Scaling:** Z-score normalization uses mean and standard deviation.\n",
    "* **Hypothesis Testing:** Many test statistics (t-test, ANOVA, etc.) rely on normality assumptions.\n",
    "* **Probability & Likelihood:** Gaussian likelihood is used in generative models (e.g., Gaussian Mixture Models).\n",
    "* **Noise Modeling:** Measurement errors often assumed to be Gaussian.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Example**\n",
    "\n",
    "* Suppose students’ heights in a class are approximately normal with:\n",
    "\n",
    "  * $\\mu = 170$ cm, $\\sigma = 10$ cm.\n",
    "  * ~68% of students are between **160 cm and 180 cm**.\n",
    "  * ~95% between **150 cm and 190 cm**.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Visual Intuition**\n",
    "\n",
    "* Bell-shaped curve.\n",
    "* Tallest at mean, tails taper off.\n",
    "* Area under curve = probability.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic**:\n",
    "\n",
    "* **Normal = Natural = Bell curve**.\n",
    "* Think of it as the \"default\" distribution in statistics.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c0c2c0-3972-4efd-a328-107ba2a30ea7",
   "metadata": {},
   "source": [
    "> # `Skewness`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec27b6e7-56d8-449f-a2ba-38d8f9d12cf7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* **Skewness** measures the **asymmetry** of a distribution.\n",
    "* A normal distribution has **skewness = 0** (perfectly symmetric).\n",
    "* If data leans to one side → it’s skewed.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Types of Skewness**\n",
    "\n",
    "### **a) Positive Skew (Right-skewed)**\n",
    "\n",
    "* Tail stretches more to the **right**.\n",
    "* Mean > Median > Mode.\n",
    "* Example: Income distribution (a few very high incomes pull the mean to the right).\n",
    "\n",
    "### **b) Negative Skew (Left-skewed)**\n",
    "\n",
    "* Tail stretches more to the **left**.\n",
    "* Mean < Median < Mode.\n",
    "* Example: Age at retirement (most retire around 60–65, but some retire much earlier).\n",
    "\n",
    "### **c) Zero Skew (Symmetric)**\n",
    "\n",
    "* Distribution is symmetric.\n",
    "* Mean = Median = Mode.\n",
    "* Example: Heights of adults (approximately).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Formula**\n",
    "\n",
    "For a dataset $X$:\n",
    "\n",
    "$$\n",
    "\\text{Skewness} = \\frac{\\sum (X_i - \\bar{X})^3 / n}{\\sigma^3}\n",
    "$$\n",
    "\n",
    "* Positive value → right skew.\n",
    "* Negative value → left skew.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. In Machine Learning**\n",
    "\n",
    "* Skewed features can affect algorithms that assume normality (e.g., Linear Regression, Logistic Regression).\n",
    "* Often corrected with **log transform, square root, or Box-Cox transform**.\n",
    "* Important in **outlier detection** (skewness often caused by outliers).\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Visual Intuition**\n",
    "\n",
    "* **Right skew** = tail on the right.\n",
    "* **Left skew** = tail on the left.\n",
    "* Think of the \"tail\" as the direction of skew.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic**:\n",
    "\n",
    "* \"Tail tells the tale.\"\n",
    "* If the **tail is right → right skew**.\n",
    "* If the **tail is left → left skew**.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad310e5-5fc7-4c97-94da-252536c76f0c",
   "metadata": {},
   "source": [
    "> # `Non-Gaussian Probability Distributions`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85ad8f4-ecaa-40f8-8988-b83ab56bc788",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "###  What are Non-Gaussian Distributions?\n",
    "\n",
    "* A **Gaussian distribution** = the bell curve (symmetric, unimodal, defined by mean & variance).\n",
    "* **Non-Gaussian distributions** are all distributions that **don’t follow the bell curve**.\n",
    "\n",
    "  * They may be **skewed**, **heavier-tailed**, **multi-peaked**, or **discrete**.\n",
    "\n",
    "---\n",
    "\n",
    "###  Common Non-Gaussian Distributions\n",
    "\n",
    "1. **Uniform Distribution**\n",
    "\n",
    "   * All outcomes equally likely.\n",
    "   * Example: Rolling a fair die (1–6, each has probability 1/6).\n",
    "\n",
    "2. **Bernoulli Distribution**\n",
    "\n",
    "   * Only two outcomes: success (1) or failure (0).\n",
    "   * Example: Tossing a coin once.\n",
    "\n",
    "3. **Binomial Distribution**\n",
    "\n",
    "   * Number of successes in `n` independent Bernoulli trials.\n",
    "   * Example: Number of heads in 10 coin tosses.\n",
    "\n",
    "4. **Poisson Distribution**\n",
    "\n",
    "   * Counts the number of events in a fixed time/space interval.\n",
    "   * Example: Number of emails received in an hour.\n",
    "\n",
    "5. **Exponential Distribution**\n",
    "\n",
    "   * Models **time between events** in a Poisson process.\n",
    "   * Example: Time between arrivals at a bus stop.\n",
    "\n",
    "6. **Geometric Distribution**\n",
    "\n",
    "   * Number of trials until the first success.\n",
    "   * Example: Tossing a coin until you get heads.\n",
    "\n",
    "7. **t-Distribution (Student’s t)**\n",
    "\n",
    "   * Similar to normal but with **heavier tails** (more outliers).\n",
    "   * Example: Useful when working with **small sample sizes**.\n",
    "\n",
    "8. **Chi-Square Distribution**\n",
    "\n",
    "   * Distribution of a sum of squared standard normal variables.\n",
    "   * Used in **hypothesis testing** (e.g., independence tests).\n",
    "\n",
    "9. **Exotic Non-Gaussians**\n",
    "\n",
    "   * **Cauchy Distribution** → very heavy tails, mean & variance undefined.\n",
    "   * **Beta Distribution** → used for probabilities (values between 0 and 1).\n",
    "   * **Gamma Distribution** → generalization of exponential.\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Idea\n",
    "\n",
    " Non-Gaussian distributions show up when:\n",
    "\n",
    "* Data is **discrete** (like dice rolls).\n",
    "* Data is **skewed** (like income).\n",
    "* Data has **heavy tails** (like stock returns).\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a9ecbb-4278-402a-8b8b-d7995d2ae80c",
   "metadata": {},
   "source": [
    "> # `Kurtosis`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7934c649-70a4-4a55-96bc-c17948ec3807",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "###  What is Kurtosis?\n",
    "\n",
    "* **Kurtosis** measures the **“tailedness”** of a probability distribution.\n",
    "* It tells us **how heavy or light the tails** are compared to a normal distribution.\n",
    "* In other words: Do extreme values (outliers) happen more or less often than in a normal bell curve?\n",
    "\n",
    "---\n",
    "\n",
    "###  Types of Kurtosis\n",
    "\n",
    "1. **Mesokurtic (Normal)**\n",
    "\n",
    "   * Same kurtosis as the normal distribution.\n",
    "   * Balanced tails.\n",
    "   * Example: Standard normal curve.\n",
    "\n",
    "2. **Leptokurtic (High Kurtosis > 3)**\n",
    "\n",
    "   * **Heavy tails**, **sharp peak**.\n",
    "   * More extreme values (outliers) likely.\n",
    "   * Example: Stock market returns.\n",
    "\n",
    "3. **Platykurtic (Low Kurtosis < 3)**\n",
    "\n",
    "   * **Light tails**, **flatter peak**.\n",
    "   * Fewer extreme values.\n",
    "   * Example: Uniform distribution.\n",
    "\n",
    "---\n",
    "\n",
    "###  Formula for Sample Kurtosis\n",
    "\n",
    "$$\n",
    "K = \\frac{\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^4}{\\left(\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2\\right)^2}\n",
    "$$\n",
    "\n",
    "* Numerator = 4th moment (sensitive to extreme values).\n",
    "* Denominator = squared variance.\n",
    "\n",
    "Often we use **Excess Kurtosis = K – 3** so that:\n",
    "\n",
    "* Normal distribution → 0\n",
    "* Leptokurtic → positive\n",
    "* Platykurtic → negative\n",
    "\n",
    "---\n",
    "\n",
    "###  Intuition\n",
    "\n",
    "* **Skewness** = “Is the curve tilted left or right?”\n",
    "* **Kurtosis** = “How fat are the tails and how sharp is the peak?”\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b433846f-55dc-40e6-b481-2480bf5525ac",
   "metadata": {},
   "source": [
    "> # `Q–Q plot`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d7446-c29e-47bd-8936-e4fb3c6c470a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "###  What is a Q–Q Plot?\n",
    "\n",
    "* **Q–Q (Quantile–Quantile) Plot** compares the **quantiles** of your dataset with the quantiles of a theoretical distribution (like normal).\n",
    "* If your data follows that distribution → the points lie **close to a straight line** (usually 45°).\n",
    "\n",
    "---\n",
    "\n",
    "###  How it Works\n",
    "\n",
    "1. Take your dataset and sort it.\n",
    "2. Compute its **quantiles**.\n",
    "3. Compare against the **theoretical quantiles** (e.g., of normal distribution).\n",
    "4. Plot data quantiles (Y-axis) vs theoretical quantiles (X-axis).\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "* **Straight line** → data ≈ theoretical distribution.\n",
    "* **Upward curve at ends** → heavier tails than normal (leptokurtic).\n",
    "* **Downward curve at ends** → lighter tails (platykurtic).\n",
    "* **S-shape** → skewness (left or right tilt).\n",
    "\n",
    "---\n",
    "\n",
    "###  Example in Machine Learning\n",
    "\n",
    "* Before applying models like **Linear Regression** or **Logistic Regression**, we often assume errors are **normally distributed**.\n",
    "* A Q–Q plot of residuals can check this assumption quickly.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8f958-6c78-4902-8b2d-9515f5ca4cac",
   "metadata": {},
   "source": [
    "> # `Uniform Distribution`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8481fefe-13a6-43cf-b27a-ef68dcacf9f2",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "###  What is a Uniform Distribution?\n",
    "\n",
    "* A probability distribution where **all outcomes are equally likely**.\n",
    "* Every value within a given range has the **same probability**.\n",
    "* Example: Rolling a fair die → each face (1–6) has probability $\\tfrac{1}{6}$.\n",
    "\n",
    "---\n",
    "\n",
    "###  Types of Uniform Distribution\n",
    "\n",
    "1. **Discrete Uniform Distribution**\n",
    "\n",
    "   * Finite number of values, each equally likely.\n",
    "   * Example: Rolling a die, picking a random card from a deck.\n",
    "\n",
    "2. **Continuous Uniform Distribution**\n",
    "\n",
    "   * Infinite values in an interval $[a, b]$, all equally likely.\n",
    "   * Probability Density Function (PDF):\n",
    "\n",
    "     $$\n",
    "     f(x) = \\frac{1}{b-a}, \\quad a \\leq x \\leq b\n",
    "     $$\n",
    "   * Cumulative Distribution Function (CDF):\n",
    "\n",
    "     $$\n",
    "     F(x) = \\frac{x-a}{b-a}, \\quad a \\leq x \\leq b\n",
    "     $$\n",
    "\n",
    "---\n",
    "\n",
    "### Properties\n",
    "\n",
    "* **Mean**:\n",
    "\n",
    "  $$\n",
    "  \\mu = \\frac{a+b}{2}\n",
    "  $$\n",
    "* **Variance**:\n",
    "\n",
    "  $$\n",
    "  \\sigma^2 = \\frac{(b-a)^2}{12}\n",
    "  $$\n",
    "* Shape: Flat (rectangular).\n",
    "\n",
    "---\n",
    "\n",
    "### In Machine Learning\n",
    "\n",
    "* Used for **random initialization** of weights (before training starts).\n",
    "* Sampling for simulations (Monte Carlo methods).\n",
    "* Data augmentation (random crops, rotations with equal probability).\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8e86e5-666e-4f05-a18b-074cc1a419eb",
   "metadata": {},
   "source": [
    "> # `Log Normal Distribution `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fe6b87-41fc-4b27-afe3-829b994af71f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "### What is a Log-Normal Distribution?\n",
    "\n",
    "* A random variable $X$ is **log-normally distributed** if:\n",
    "\n",
    "  $$\n",
    "  \\ln(X) \\sim N(\\mu, \\sigma^2)\n",
    "  $$\n",
    "\n",
    "  That means the **logarithm of $X$** follows a **normal distribution**.\n",
    "* So while a normal distribution can take **negative values**, a log-normal is **strictly positive**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Probability Density Function (PDF)\n",
    "\n",
    "For $x > 0$:\n",
    "\n",
    "$$\n",
    "f(x; \\mu, \\sigma) = \\frac{1}{x\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "* Skewed to the right (long positive tail).\n",
    "* Shape depends on $\\mu$ and $\\sigma$.\n",
    "\n",
    "---\n",
    "\n",
    "###  Properties\n",
    "\n",
    "* **Mean**:\n",
    "\n",
    "  $$\n",
    "  E[X] = e^{\\mu + \\frac{\\sigma^2}{2}}\n",
    "  $$\n",
    "* **Median**:\n",
    "\n",
    "  $$\n",
    "  \\text{Median} = e^{\\mu}\n",
    "  $$\n",
    "* **Variance**:\n",
    "\n",
    "  $$\n",
    "  Var[X] = \\left(e^{\\sigma^2} - 1\\right) e^{2\\mu + \\sigma^2}\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "###  Examples in Real Life\n",
    "\n",
    "* **Stock prices**: Can’t be negative, but can grow exponentially.\n",
    "* **Income distribution**: Most people earn around the median, but a few earn extremely high amounts.\n",
    "* **Biological measures**: Reaction times, survival times, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### In Machine Learning\n",
    "\n",
    "* **Modeling skewed data** (e.g., prices, time-to-event data).\n",
    "* **Feature transformation**: Taking $\\ln(x)$ of a skewed feature often makes it more normal-like, which helps models that assume normality (like linear regression).\n",
    "* **Generative models**: Useful for positive-only variables.\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220aa2a-9f98-43f1-b523-19dba4714275",
   "metadata": {},
   "source": [
    "> # `Pareto Distribution`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f2aee-639b-4925-ba0d-84a3ddaa3419",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "###  What is the Pareto Distribution?\n",
    "\n",
    "* A continuous probability distribution often called the **“80/20 rule” distribution**.\n",
    "* Named after economist **Vilfredo Pareto**, who observed that **20% of people owned 80% of the land in Italy**.\n",
    "* It describes situations where **a small number of events account for most of the effect**.\n",
    "\n",
    "---\n",
    "\n",
    "###  Probability Density Function (PDF)\n",
    "\n",
    "For $x \\geq x_m$:\n",
    "\n",
    "$$\n",
    "f(x; x_m, \\alpha) = \\frac{\\alpha x_m^\\alpha}{x^{\\alpha+1}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $x_m > 0$ = minimum possible value (scale).\n",
    "* $\\alpha > 0$ = shape parameter.\n",
    "\n",
    "---\n",
    "\n",
    "###  Properties\n",
    "\n",
    "* **Mean** (only if $\\alpha > 1$):\n",
    "\n",
    "  $$\n",
    "  E[X] = \\frac{\\alpha x_m}{\\alpha - 1}\n",
    "  $$\n",
    "* **Variance** (only if $\\alpha > 2$):\n",
    "\n",
    "  $$\n",
    "  Var[X] = \\frac{x_m^2 \\alpha}{(\\alpha - 1)^2 (\\alpha - 2)}\n",
    "  $$\n",
    "* Heavy-tailed: Extreme large values occur more often than in normal or exponential.\n",
    "\n",
    "---\n",
    "\n",
    "###  Applications in Real Life\n",
    "\n",
    "* **Wealth distribution** (small % of population owns most wealth).\n",
    "* **Internet traffic** (few sites get most of the clicks).\n",
    "* **Natural phenomena** (sizes of cities, earthquakes, file sizes).\n",
    "\n",
    "---\n",
    "\n",
    "### In Machine Learning\n",
    "\n",
    "* Understanding **imbalanced data** (e.g., rare events dominate outcomes).\n",
    "* **Feature engineering**: log-transforming Pareto-like features can stabilize models.\n",
    "* **Anomaly detection**: large outliers may be natural if the underlying process is Pareto.\n",
    "\n",
    "---\n",
    "\n",
    "**Compare with Log-Normal**:\n",
    "\n",
    "* Both are skewed with heavy tails.\n",
    "* **Log-normal** → arises when multiplying many random factors.\n",
    "* **Pareto** → arises when following power-law processes.\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b338378-9538-4272-81ff-ecf37a427177",
   "metadata": {},
   "source": [
    "> # `Transformations `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcfc40b-2c05-4f70-bb79-c16485b535f6",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "# **Data Transformations**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* A **transformation** changes the **scale, shape, or distribution** of data.\n",
    "* Purpose: Improve model performance, reduce skewness, stabilize variance, or make relationships more linear.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Common Types of Transformations**\n",
    "\n",
    "### **a) Logarithmic Transformation**\n",
    "\n",
    "* Formula: $X' = \\log(X)$ (usually natural log).\n",
    "* **Use:** Reduce right skew, compress large values.\n",
    "* **Example:** Income, population, stock prices.\n",
    "\n",
    "---\n",
    "\n",
    "### **b) Square Root Transformation**\n",
    "\n",
    "* Formula: $X' = \\sqrt{X}$\n",
    "* **Use:** Reduce moderate skewness, stabilize variance.\n",
    "* **Example:** Count data like number of defects, number of calls.\n",
    "\n",
    "---\n",
    "\n",
    "### **c) Cube Root Transformation**\n",
    "\n",
    "* Formula: $X' = \\sqrt[3]{X}$\n",
    "* **Use:** Can reduce skewness for both positive and negative values.\n",
    "\n",
    "---\n",
    "\n",
    "### **d) Reciprocal Transformation**\n",
    "\n",
    "* Formula: $X' = 1/X$\n",
    "* **Use:** Invert relationships, reduce influence of large values.\n",
    "\n",
    "---\n",
    "\n",
    "### **e) Box-Cox Transformation**\n",
    "\n",
    "* Formula: $X' = \\frac{X^\\lambda - 1}{\\lambda}$ (for $\\lambda \\neq 0$)\n",
    "* **Use:** Finds the best power transformation to **normalize** data.\n",
    "* **Requirement:** All $X > 0$.\n",
    "\n",
    "---\n",
    "\n",
    "### **f) Yeo-Johnson Transformation**\n",
    "\n",
    "* Similar to Box-Cox but works for **positive and negative values**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Why Transformations are Important in ML**\n",
    "\n",
    "* **Linear models** assume linearity → transform skewed features to improve fit.\n",
    "* **Stabilize variance** → reduce heteroscedasticity (non-constant variance).\n",
    "* **Reduce effect of outliers** → compress extreme values.\n",
    "* **Make distributions more normal** → better for algorithms that assume normality (e.g., Naive Bayes, t-tests).\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Visual Example**\n",
    "\n",
    "* Original data: Right-skewed histogram.\n",
    "* After log transformation: More symmetric, easier for models to learn.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic:**\n",
    "\n",
    "* **Log / Sqrt → compress big values**\n",
    "* **Reciprocal → invert relationships**\n",
    "* **Box-Cox → find the best power automatically**\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8586b1-57b7-4634-9af0-99ea2583ba4b",
   "metadata": {},
   "source": [
    "> # `Bernoulli Distribution `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790bbe69-fbb4-41db-b006-49676b3f2dbd",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Bernoulli Distribution**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* The **Bernoulli distribution** is the probability distribution of a **single trial** with only **two possible outcomes**:\n",
    "\n",
    "  * Success ($1$) with probability $p$\n",
    "  * Failure ($0$) with probability $1-p$\n",
    "\n",
    "It’s like flipping a biased coin once.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Probability Mass Function (PMF)**\n",
    "\n",
    "For outcome $x \\in \\{0, 1\\}$:\n",
    "\n",
    "$$\n",
    "P(X = x) = p^x (1-p)^{1-x}\n",
    "$$\n",
    "\n",
    "* $P(X=1) = p$\n",
    "* $P(X=0) = 1-p$\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Properties**\n",
    "\n",
    "* **Mean (Expected Value):**\n",
    "\n",
    "  $$\n",
    "  E[X] = p\n",
    "  $$\n",
    "* **Variance:**\n",
    "\n",
    "  $$\n",
    "  Var(X) = p(1-p)\n",
    "  $$\n",
    "* **Support:** $X \\in \\{0,1\\}$\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Real-Life Examples**\n",
    "\n",
    "* Tossing a (possibly biased) coin: Heads (1), Tails (0).\n",
    "* A student passing (1) or failing (0) an exam.\n",
    "* Email being spam (1) or not spam (0).\n",
    "\n",
    "---\n",
    "\n",
    "## **5. In Machine Learning**\n",
    "\n",
    "* Basis of **binary classification**.\n",
    "* Logistic regression models $P(Y=1)$, which follows Bernoulli.\n",
    "* Loss function: **Binary Cross-Entropy** is derived from Bernoulli likelihood.\n",
    "* Used in **generative models** (e.g., Bernoulli Naive Bayes).\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Related Distributions**\n",
    "\n",
    "* **Binomial distribution** = sum of several independent Bernoulli trials.\n",
    "* **Geometric distribution** = number of Bernoulli trials until the first success.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a047e9d-1b7d-41ef-9631-8395d64f3831",
   "metadata": {},
   "source": [
    "> # `Binomial Distribution `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd3b5d5-5323-47d2-9fcc-179a13fb0aa7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Binomial Distribution**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* The **binomial distribution** gives the probability of getting exactly $k$ successes in $n$ independent Bernoulli trials, each with probability of success $p$.\n",
    "* Example: Flipping a coin $n$ times and counting heads.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Probability Mass Function (PMF)**\n",
    "\n",
    "For $k = 0,1,2, \\dots, n$:\n",
    "\n",
    "$$\n",
    "P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$ (number of ways to choose $k$ successes)\n",
    "* $p$ = probability of success\n",
    "* $n$ = number of trials\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Properties**\n",
    "\n",
    "* **Mean (Expected Value):**\n",
    "\n",
    "  $$\n",
    "  E[X] = np\n",
    "  $$\n",
    "* **Variance:**\n",
    "\n",
    "  $$\n",
    "  Var(X) = np(1-p)\n",
    "  $$\n",
    "* **Support:** $X \\in \\{0,1,2,\\dots,n\\}$\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Real-Life Examples**\n",
    "\n",
    "* Number of heads in 10 coin flips.\n",
    "* Number of students passing an exam (success/fail).\n",
    "* Number of defective items in a batch of products.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. In Machine Learning**\n",
    "\n",
    "* **Evaluation metrics**: Many are based on binomial proportions (e.g., accuracy = number of correct predictions out of $n$).\n",
    "* **Feature modeling**: If you record “number of clicks out of trials,” binomial fits well.\n",
    "* **Hypothesis testing**: Proportions are often modeled with binomial.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Connection with Other Distributions**\n",
    "\n",
    "* **Bernoulli**: Special case of binomial with $n=1$.\n",
    "* **Normal approximation**: For large $n$, binomial ≈ normal distribution (Central Limit Theorem).\n",
    "* **Poisson approximation**: If $n$ is large and $p$ is small.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d31772-ffc0-486a-9817-f7ae2b2457db",
   "metadata": {},
   "source": [
    "> # `Sampling Distribution `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88715bea-b7f4-4761-b3eb-1774c1e8f3d7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Sampling Distribution**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "* A **sampling distribution** is the probability distribution of a statistic (like the mean, variance, or proportion) that is calculated from many random samples of the same population.\n",
    "* In other words:\n",
    "\n",
    "  * Take many samples from a population.\n",
    "  * Compute a statistic (e.g., sample mean $\\bar{X}$) for each.\n",
    "  * Plot the distribution of those statistics → that’s the **sampling distribution**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Why It’s Important**\n",
    "\n",
    "* It tells us **how much our sample statistic is likely to vary** from sample to sample.\n",
    "* Forms the foundation of:\n",
    "\n",
    "  * **Confidence intervals**\n",
    "  * **Hypothesis testing**\n",
    "  * **Standard errors**\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Example**\n",
    "\n",
    "* Population: Heights of students in a college (true mean $\\mu$ = 170 cm).\n",
    "* Take random samples of size $n=30$.\n",
    "* Compute the mean height for each sample.\n",
    "* Collect many such sample means → their distribution is the **sampling distribution of the mean**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Central Limit Theorem (CLT)**\n",
    "\n",
    "* Key fact: As sample size $n$ increases, the sampling distribution of the mean $\\bar{X}$ approaches a **normal distribution**, regardless of the population’s original distribution.\n",
    "* Mean of sampling distribution:\n",
    "\n",
    "  $$\n",
    "  E[\\bar{X}] = \\mu\n",
    "  $$\n",
    "* Standard error (spread of sample means):\n",
    "\n",
    "  $$\n",
    "  SE = \\frac{\\sigma}{\\sqrt{n}}\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "## **5. In Machine Learning**\n",
    "\n",
    "* **Cross-validation** mimics the idea of sampling distributions (different train/test splits → different performance measures).\n",
    "* **Bootstrap methods** use repeated resampling to approximate sampling distributions.\n",
    "* Understanding model stability → how much metrics (like accuracy) vary across samples.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic:**\n",
    "\n",
    "* **Population → one big truth**\n",
    "* **Sample → one estimate**\n",
    "* **Sampling distribution → distribution of many estimates**\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41b47b6-0797-4524-b47f-22f404c0a63f",
   "metadata": {},
   "source": [
    "> # `Central Limit Theorem`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60db1b3-109c-4199-ad86-af5143a4a6be",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Central Limit Theorem (CLT)**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "The **CLT states**:\n",
    "When we take **many independent random samples** from a population with mean $\\mu$ and variance $\\sigma^2$, the **sampling distribution of the sample mean** $\\bar{X}$ approaches a **normal distribution**, as the sample size $n$ becomes large.\n",
    "\n",
    "Formally:\n",
    "\n",
    "$$\n",
    "\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\;\\;\\xrightarrow{d}\\;\\; N(0,1) \\quad \\text{as } n \\to \\infty\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Key Points**\n",
    "\n",
    "* Works **regardless of the population’s original distribution** (normal, uniform, skewed, etc.).\n",
    "* Only requirements:\n",
    "\n",
    "  * Samples must be **independent** and **identically distributed (i.i.d.)**.\n",
    "  * Finite mean ($\\mu$) and variance ($\\sigma^2$).\n",
    "* The approximation improves as $n$ increases (usually $n \\geq 30$ is “large enough”).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Implications**\n",
    "\n",
    "* The **mean of the sampling distribution** = population mean $\\mu$.\n",
    "* The **spread of the sampling distribution** = standard error (SE):\n",
    "\n",
    "  $$\n",
    "  SE = \\frac{\\sigma}{\\sqrt{n}}\n",
    "  $$\n",
    "* Lets us use **normal probability theory** (z-scores, confidence intervals, hypothesis tests) even when data isn’t normal.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Example**\n",
    "\n",
    "* Population: Students’ exam scores, skewed right (not normal).\n",
    "* Take random samples of size $n=40$.\n",
    "* Compute sample means repeatedly.\n",
    "* Distribution of those sample means → nearly **bell-shaped (normal)**.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. In Machine Learning**\n",
    "\n",
    "* Justifies why many algorithms assume “errors are normally distributed.”\n",
    "* Supports **bootstrap resampling** and confidence intervals for model metrics.\n",
    "* Ensures that **loss functions** and **test statistics** (like accuracy differences) behave predictably.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic:**\n",
    "\n",
    "* **CLT = \"Means go Normal\"** (even if data isn’t).\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0469ea-5163-471f-9615-0e47c9d4c7c1",
   "metadata": {},
   "source": [
    "> # `Confidence Intervals `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857a47df-6517-4e5d-b203-3540cd32d94c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Confidence Intervals (CIs)**\n",
    "\n",
    "## **1. Idea**\n",
    "\n",
    "A **confidence interval** gives a **range of plausible values** for a population parameter (like the mean or proportion) based on sample data.\n",
    "\n",
    "It’s not a guarantee, but rather a **level of confidence** (say 95%) that the true population parameter lies within that interval.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Formula (for Mean, when σ is known)**\n",
    "\n",
    "From CLT, we know the sample mean $\\bar{X}$ follows a normal distribution:\n",
    "\n",
    "$$\n",
    "CI = \\bar{X} \\;\\; \\pm \\;\\; Z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "* $\\bar{X}$ = sample mean\n",
    "* $\\sigma$ = population standard deviation\n",
    "* $n$ = sample size\n",
    "* $Z_{\\alpha/2}$ = critical value from standard normal distribution\n",
    "\n",
    "  * 95% CI → $Z = 1.96$\n",
    "  * 99% CI → $Z = 2.58$\n",
    "\n",
    "---\n",
    "\n",
    "## **3. When σ is Unknown**\n",
    "\n",
    "We use **sample standard deviation (s)** and a **t-distribution**:\n",
    "\n",
    "$$\n",
    "CI = \\bar{X} \\;\\; \\pm \\;\\; t_{\\alpha/2, \\; (n-1)} \\cdot \\frac{s}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Example**\n",
    "\n",
    "* Suppose you measure **average study time** for 100 students: $\\bar{X} = 4.5$ hours, $s = 1.2$.\n",
    "* 95% CI:\n",
    "\n",
    "$$\n",
    "4.5 \\pm 1.96 \\times \\frac{1.2}{\\sqrt{100}}\n",
    "= 4.5 \\pm 0.24\n",
    "= [4.26, 4.74]\n",
    "$$\n",
    "\n",
    "Interpretation: We are 95% confident that the **true mean study time** for all students is between **4.26 and 4.74 hours**.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Misconceptions**\n",
    "\n",
    "* ❌ A 95% CI does **not** mean the probability is 95% that the mean is in the interval.\n",
    "* ✅ It means: if we repeat the experiment many times, **95% of the intervals built this way will contain the true mean**.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Uses in ML/DS**\n",
    "\n",
    "* Estimate **model performance** (e.g., 95% CI for accuracy).\n",
    "* Assess uncertainty in **parameter estimates**.\n",
    "* Compare two models’ results with overlap or separation of their intervals.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic:**\n",
    "**CI = Estimate ± Margin of Error**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c36239c-1d8e-455d-9f41-5d6e0157aa04",
   "metadata": {},
   "source": [
    "> # `What is Hypothesis Testing?`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b97e1a-a843-4026-a724-818683fd8963",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  What is Hypothesis Testing?\n",
    "\n",
    "**Definition:**\n",
    "Hypothesis testing is a **statistical method** used to make decisions or draw conclusions about a **population parameter** based on data from a **sample**.\n",
    "\n",
    "It answers:\n",
    " *“Is this observed effect real, or could it just be due to random chance?”*\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Ideas**\n",
    "\n",
    "* **Hypothesis** = an assumption or claim.\n",
    "* We test this claim using sample data.\n",
    "* There are always two competing hypotheses:\n",
    "\n",
    "  * **Null Hypothesis (H₀):** \"No effect\" or \"status quo\" (e.g., mean = 50).\n",
    "  * **Alternative Hypothesis (H₁ or Hₐ):** What you want to check/prove (e.g., mean > 50).\n",
    "\n",
    "---\n",
    "\n",
    "## **Example in Real Life**\n",
    "\n",
    "* A medicine company claims a new drug lowers blood pressure by 10 points on average.\n",
    "* You collect a sample of patients and test whether the average reduction is really 10 or not.\n",
    "* If data strongly contradicts H₀, you reject it and accept H₁.\n",
    "\n",
    "---\n",
    "\n",
    "## **Why It Matters in Machine Learning**\n",
    "\n",
    "* To test whether a **feature is significant**.\n",
    "* To compare two models’ accuracies (e.g., Model A vs Model B).\n",
    "* In **A/B testing** for model updates or user interface changes.\n",
    "\n",
    "---\n",
    "\n",
    " **In one line:**\n",
    "Hypothesis testing is a **decision-making tool** that uses data to check if an assumption about the population is likely true or not.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b1fa9-bfc5-4d01-ae84-a3ca3438fa41",
   "metadata": {},
   "source": [
    "> # `Null Hypothesis (H₀) and Alternative Hypothesis (H₁ / Hₐ) `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2305b4b0-80ac-4750-9d97-50a1e83d47cd",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "\n",
    "#  Null Hypothesis (H₀)\n",
    "\n",
    "* The **default assumption** — \"nothing new is happening.\"\n",
    "* Usually states there is **no effect**, **no difference**, or the value equals a specific number.\n",
    "* Example:\n",
    "\n",
    "  * $H₀: \\mu = 50$ → The population mean is 50.\n",
    "  * In machine learning: \"Model A and Model B have the same accuracy.\"\n",
    "\n",
    "---\n",
    "\n",
    "# Alternative Hypothesis (H₁ / Hₐ)\n",
    "\n",
    "* The **opposite claim** to $H₀$.\n",
    "* Represents what the researcher or analyst is trying to prove.\n",
    "* Example:\n",
    "\n",
    "  * $H₁: \\mu > 50$ → The population mean is greater than 50.\n",
    "  * In ML: \"Model A has higher accuracy than Model B.\"\n",
    "\n",
    "---\n",
    "\n",
    "# Types of Alternative Hypotheses\n",
    "\n",
    "1. **Two-tailed (≠)**\n",
    "\n",
    "   * $H₁: \\mu \\neq 50$\n",
    "   * Tests if the mean is *different* (either higher or lower).\n",
    "\n",
    "2. **Right-tailed (>)**\n",
    "\n",
    "   * $H₁: \\mu > 50$\n",
    "   * Tests if the mean is *greater*.\n",
    "\n",
    "3. **Left-tailed (<)**\n",
    "\n",
    "   * $H₁: \\mu < 50$\n",
    "   * Tests if the mean is *less*.\n",
    "\n",
    "---\n",
    "\n",
    "# Analogy (Simple)\n",
    "\n",
    "* Think of a **courtroom trial**:\n",
    "\n",
    "  * $H₀$: The person is innocent (default assumption).\n",
    "  * $H₁$: The person is guilty (claim to be tested).\n",
    "  * Evidence (data) decides whether we reject $H₀$.\n",
    "\n",
    "---\n",
    "\n",
    "**In one line:**\n",
    "\n",
    "* **H₀:** No effect / status quo.\n",
    "* **H₁:** There is an effect / change.\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb477d2-aaf9-4651-88f6-305fd2143fc9",
   "metadata": {},
   "source": [
    "> # `Steps Involved in a Hypothesis Test`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a001364a-8147-4f71-bd74-0c0702001dfa",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Steps Involved in a Hypothesis Test**\n",
    "\n",
    "### **Step 1: State the Hypotheses**\n",
    "\n",
    "* Formulate **Null Hypothesis (H₀)** and **Alternative Hypothesis (H₁)**.\n",
    "* Example:\n",
    "\n",
    "  * $H₀: \\mu = 50$ (mean = 50)\n",
    "  * $H₁: \\mu > 50$ (mean is greater than 50)\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Choose the Significance Level (α)**\n",
    "\n",
    "* Common choices: **0.05 (5%)** or **0.01 (1%)**.\n",
    "* This is the probability of making a **Type I error** (rejecting H₀ when it’s true).\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Select the Test Statistic**\n",
    "\n",
    "* Depends on data type, distribution, and sample size:\n",
    "\n",
    "  * **Z-test** → large samples, known population σ.\n",
    "  * **t-test** → small samples, σ unknown.\n",
    "  * **Chi-square test** → categorical data.\n",
    "  * **ANOVA** → comparing more than two group means.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Compute the Test Statistic from Sample Data**\n",
    "\n",
    "* Formula:\n",
    "\n",
    "  $$\n",
    "  Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\n",
    "  $$\n",
    "\n",
    "  (for mean with known σ).\n",
    "\n",
    "* You’ll calculate either:\n",
    "\n",
    "  * A **test statistic** (Z, t, χ², F, etc.)\n",
    "  * Or a **p-value** (probability of observing data this extreme if H₀ is true).\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 5: Define the Decision Rule**\n",
    "\n",
    "* Compare test statistic with **critical value** from the distribution table, OR use the **p-value method**:\n",
    "\n",
    "  * If **p ≤ α** → Reject H₀.\n",
    "  * If **p > α** → Fail to reject H₀.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 6: Make a Decision and Interpret**\n",
    "\n",
    "* Reject H₀ → Evidence supports the alternative hypothesis.\n",
    "* Fail to reject H₀ → No strong evidence against H₀.\n",
    "\n",
    "---\n",
    "\n",
    "#  Quick Example\n",
    "\n",
    "A sample of 36 phones has mean battery = 9.5 hours, σ = 1.8.\n",
    "Company claims mean = 10. Test at α = 0.05.\n",
    "\n",
    "1. $H₀: \\mu = 10,\\; H₁: \\mu \\neq 10$.\n",
    "2. α = 0.05.\n",
    "3. Z-test.\n",
    "4. $Z = \\frac{9.5 - 10}{1.8/\\sqrt{36}} = -1.67$.\n",
    "5. Critical Z = ±1.96.\n",
    "6. Since -1.67 is inside the range, **Fail to reject H₀** → no significant difference.\n",
    "\n",
    "---\n",
    "\n",
    "**Mnemonic:**\n",
    "**“Hypothesis → Alpha → Test → Compute → Compare → Conclude.”**\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286949e7-64cd-4374-8937-c12ec1175c5d",
   "metadata": {},
   "source": [
    "> # `performing a Z-test`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7248d6e-294a-4186-92dc-ec86f25af024",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Z-Test**\n",
    "\n",
    "## **1. When to Use Z-Test**\n",
    "\n",
    "* Population standard deviation (σ) is known.\n",
    "* Sample size is large (**n ≥ 30**) → CLT applies.\n",
    "* Data is approximately normally distributed.\n",
    "\n",
    "Common uses:\n",
    "\n",
    "* Test a population **mean**.\n",
    "* Test a population **proportion**.\n",
    "* Compare **two population means** (large n).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Formula for Z-Test (One Sample Mean)**\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\bar{X} - \\mu_0}{\\sigma / \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\bar{X}$ = sample mean\n",
    "* $\\mu_0$ = hypothesized population mean (from H₀)\n",
    "* $\\sigma$ = population standard deviation\n",
    "* $n$ = sample size\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Steps**\n",
    "\n",
    "1. **State Hypotheses**\n",
    "   Example: A company claims battery life = 10 hours.\n",
    "\n",
    "   * $H₀: \\mu = 10$\n",
    "   * $H₁: \\mu \\neq 10$ (two-tailed)\n",
    "\n",
    "2. **Set α (significance level)**\n",
    "\n",
    "   * Example: α = 0.05 → critical Z = ±1.96.\n",
    "\n",
    "3. **Calculate Test Statistic**\n",
    "   Suppose:\n",
    "\n",
    "   * $\\bar{X} = 9.5$, σ = 1.8, n = 36.\n",
    "\n",
    "   $$\n",
    "   Z = \\frac{9.5 - 10}{1.8/\\sqrt{36}} \n",
    "   = \\frac{-0.5}{0.3} \n",
    "   = -1.67\n",
    "   $$\n",
    "\n",
    "4. **Decision Rule**\n",
    "\n",
    "   * If $|Z| > 1.96$, reject H₀.\n",
    "   * Here, $|-1.67| < 1.96$.\n",
    "\n",
    "5. **Conclusion**\n",
    "\n",
    "   * Fail to reject H₀ → no significant evidence battery life is different from 10 hours.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Z-Test for Proportion (bonus)**\n",
    "\n",
    "If testing population proportion $p$:\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\hat{p} - p_0}{\\sqrt{p_0 (1 - p_0) / n}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**In short:** Z-test compares your sample mean (or proportion) with the hypothesized population value, using the standard error to scale differences.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d3d466-2fa7-412e-a1b0-91def861dd01",
   "metadata": {},
   "source": [
    "> # `Rejection Region Approach`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae549107-8ed8-4771-ba00-4a90f9cffb6d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "# Rejection Region Approach\n",
    "\n",
    "## **1. Idea**\n",
    "\n",
    "* Instead of calculating a p-value, we decide by comparing the **test statistic** (Z, t, χ², etc.) to a **critical value**.\n",
    "* The **rejection region** is the set of values for which we reject $H₀$.\n",
    "* It depends on:\n",
    "\n",
    "  * The **significance level (α)**.\n",
    "  * Whether the test is **one-tailed** or **two-tailed**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Steps**\n",
    "\n",
    "1. **State Hypotheses**\n",
    "   Example: $H₀: \\mu = 50,\\; H₁: \\mu > 50$.\n",
    "\n",
    "2. **Choose α (say 0.05)**.\n",
    "\n",
    "3. **Determine the Critical Value(s)**\n",
    "\n",
    "   * Look up the Z or t distribution.\n",
    "   * For a **one-tailed test** (α = 0.05): critical Z = 1.645.\n",
    "   * For a **two-tailed test** (α = 0.05): critical Z = ±1.96.\n",
    "\n",
    "4. **Compute the Test Statistic**\n",
    "\n",
    "   * Formula:\n",
    "\n",
    "     $$\n",
    "     Z = \\frac{\\bar{X} - \\mu_0}{\\sigma / \\sqrt{n}}\n",
    "     $$\n",
    "\n",
    "5. **Decision Rule**\n",
    "\n",
    "   * If the test statistic **falls in the rejection region**, reject $H₀$.\n",
    "   * If not, fail to reject $H₀$.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Example (Two-Tailed Z-Test)**\n",
    "\n",
    "Claim: Population mean = 100.\n",
    "Sample: $\\bar{X} = 104,\\; \\sigma = 12,\\; n = 36$.\n",
    "Test at α = 0.05.\n",
    "\n",
    "1. $H₀: \\mu = 100,\\; H₁: \\mu \\neq 100$.\n",
    "2. α = 0.05 → critical Z = ±1.96.\n",
    "3. Compute:\n",
    "\n",
    "   $$\n",
    "   Z = \\frac{104 - 100}{12/\\sqrt{36}} \n",
    "   = \\frac{4}{2} \n",
    "   = 2.0\n",
    "   $$\n",
    "4. Decision: Since $Z = 2.0 > 1.96$, reject $H₀$.\n",
    "5. Conclusion: Mean is significantly different from 100.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Visualization (Mental Picture)**\n",
    "\n",
    "* Imagine the normal bell curve.\n",
    "* Shade α = 0.05 at the tails → these are the **rejection regions**.\n",
    "* If your Z lands inside the shaded area, reject $H₀$.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Difference from p-value method:**\n",
    "\n",
    "* **Rejection region:** Compare test statistic to critical value.\n",
    "* **p-value method:** Compare p-value to α.\n",
    "* Both give the same conclusion, just different perspectives.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203586b7-4451-4f52-9c1a-cca6f45c5359",
   "metadata": {},
   "source": [
    "> # `Type 1 Vs Type 2 Errors`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b65d1a1-2f3a-43e3-b1bc-3e06219a7474",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "# **Type I vs Type II Errors**\n",
    "\n",
    "## **1. The Setup**\n",
    "\n",
    "In hypothesis testing, we make a decision about the **null hypothesis (H₀)**:\n",
    "\n",
    "* **Reject H₀**\n",
    "* **Fail to reject H₀**\n",
    "\n",
    "But mistakes can happen depending on the **truth in the population**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. The Two Types of Errors**\n",
    "\n",
    "###  **Type I Error (α)**\n",
    "\n",
    "* **Definition:** Rejecting $H₀$ when it is actually true.\n",
    "* Analogy: Convicting an innocent person.\n",
    "* Probability of Type I Error = **α** (the significance level).\n",
    "* Example: Claiming a new drug works when in fact it doesn’t.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Type II Error (β)**\n",
    "\n",
    "* **Definition:** Failing to reject $H₀$ when it is actually false.\n",
    "* Analogy: Letting a guilty person go free.\n",
    "* Probability of Type II Error = **β**.\n",
    "* Example: Missing the fact that a new drug actually works (concluding it doesn’t).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Power of a Test**\n",
    "\n",
    "* **Power = 1 – β**\n",
    "* Probability of correctly rejecting a false $H₀$.\n",
    "* A powerful test = low chance of Type II Error.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Summary Table**\n",
    "\n",
    "| Reality ↓ / Decision → | Fail to Reject H₀ | Reject H₀      |\n",
    "| ---------------------- | ----------------- | -------------- |\n",
    "| H₀ True                | ✅ Correct         | ❌ Type I Error |\n",
    "| H₀ False               | ❌ Type II Error   | ✅ Correct      |\n",
    "\n",
    "---\n",
    "\n",
    "## **5. In Machine Learning**\n",
    "\n",
    "* **Type I Error (False Positive):** Model predicts spam when the email is not spam.\n",
    "* **Type II Error (False Negative):** Model misses spam (predicts not spam when it is spam).\n",
    "* Choosing α balances the trade-off between the two.\n",
    "\n",
    "---\n",
    "\n",
    "**Mnemonic:**\n",
    "\n",
    "* **Type I = False Alarm** (crying wolf when there is no wolf).\n",
    "* **Type II = Missed Detection** (not crying wolf when there is one).\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aec6e3-cb74-4790-a24f-770388133b98",
   "metadata": {},
   "source": [
    "> # `One Sided vs 2 sided tests`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6893b81-b788-45ba-a5e1-47ad365d6f73",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **One-Sided vs Two-Sided Tests**\n",
    "\n",
    "## **1. Two-Sided (Two-Tailed) Test**\n",
    "\n",
    "* **Hypotheses:**\n",
    "\n",
    "  * $H_0: \\mu = \\mu_0$\n",
    "  * $H_1: \\mu \\neq \\mu_0$\n",
    "* We test for **any difference** (greater or smaller).\n",
    "* Rejection regions: both **tails** of the distribution.\n",
    "* Example: A company claims average battery life = 10 hrs. You want to test if it’s **different from 10** (could be less OR more).\n",
    "\n",
    "Critical Z values (α = 0.05): ±1.96.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. One-Sided (One-Tailed) Test**\n",
    "\n",
    "* **Hypotheses:**\n",
    "\n",
    "  * Right-tailed:\n",
    "\n",
    "    * $H_0: \\mu \\leq \\mu_0$\n",
    "    * $H_1: \\mu > \\mu_0$\n",
    "  * Left-tailed:\n",
    "\n",
    "    * $H_0: \\mu \\geq \\mu_0$\n",
    "    * $H_1: \\mu < \\mu_0$\n",
    "* Tests for a **specific direction** (greater than OR less than, not both).\n",
    "* Rejection region: only **one tail**.\n",
    "* Example: Testing if a new medicine **increases survival rate** compared to standard. You only care if it’s better, not worse.\n",
    "\n",
    "Critical Z value (α = 0.05): 1.645 (right tail) or –1.645 (left tail).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Key Differences**\n",
    "\n",
    "| Feature                                  | One-Sided Test                          | Two-Sided Test     |\n",
    "| ---------------------------------------- | --------------------------------------- | ------------------ |\n",
    "| Direction                                | Specific (>, <)                         | Any difference (≠) |\n",
    "| Rejection region                         | One tail                                | Both tails         |\n",
    "| Power (for true effect in one direction) | More powerful                           | Less powerful      |\n",
    "| Risk                                     | Might miss effect in opposite direction | More conservative  |\n",
    "\n",
    "---\n",
    "\n",
    "## **4. In Machine Learning**\n",
    "\n",
    "* One-sided: Testing if **model A’s accuracy > model B’s accuracy**.\n",
    "* Two-sided: Testing if **model A’s accuracy ≠ model B’s accuracy** (could be better OR worse).\n",
    "\n",
    "---\n",
    "\n",
    "**Rule of thumb:**\n",
    "\n",
    "* Use **two-sided** unless you have a strong prior reason to expect an effect only in one direction.\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f1f4f-fa4a-4ce6-b03c-6cf21e5894cc",
   "metadata": {},
   "source": [
    "> # `Statistical Power`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c071324a-81a2-4369-8b9e-d52a87f08289",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "###  What is Statistical Power?\n",
    "\n",
    "* **Definition:** The probability of correctly rejecting the null hypothesis (**H₀**) when the alternative hypothesis (**H₁**) is true.\n",
    "* In short: it tells us **how good a test is at detecting a real effect**.\n",
    "\n",
    "Formula (conceptually):\n",
    "\n",
    "$$\n",
    "\\text{Power} = 1 - \\beta\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* **β (Type II Error):** Probability of failing to reject H₀ when H₁ is actually true.\n",
    "* So, **higher power = lower risk of missing a real effect**.\n",
    "\n",
    "---\n",
    "\n",
    "###  Why is Power Important?\n",
    "\n",
    "* A test with **low power** might miss real effects → false negatives.\n",
    "* Researchers usually aim for **80% power** (0.8) → means if the effect is real, we’ll catch it 8 times out of 10.\n",
    "\n",
    "---\n",
    "\n",
    "###  Factors Affecting Statistical Power\n",
    "\n",
    "1. **Sample Size (n):** Larger samples = higher power.\n",
    "2. **Effect Size:** Bigger effect = easier to detect → higher power.\n",
    "3. **Significance Level (α):** Larger α (e.g., 0.10 instead of 0.05) increases power but also increases chance of Type I error.\n",
    "4. **Variability (σ²):** Less noise = higher power.\n",
    "\n",
    "---\n",
    "\n",
    "###  Simple Example\n",
    "\n",
    "Suppose we want to test if a new medicine lowers blood pressure:\n",
    "\n",
    "* **H₀:** No difference (medicine = placebo).\n",
    "\n",
    "* **H₁:** Medicine lowers BP.\n",
    "\n",
    "* If the medicine truly works, a **powerful test** will detect it.\n",
    "\n",
    "* A **low-power test** might miss it and wrongly conclude the medicine doesn’t work.\n",
    "\n",
    "---\n",
    "\n",
    "**Memory Trick:**\n",
    "\n",
    "* **Type I error (α):** False alarm.\n",
    "* **Type II error (β):** Missed detection.\n",
    "* **Power = 1 - β:** Ability to catch the signal when it’s really there.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6e1a85-328b-4965-9b91-be23b66e127b",
   "metadata": {},
   "source": [
    "> # `P-Value`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a03708-fcf9-4c9a-9e39-d7e360337ea5",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **P-Value**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "The **p-value** is the **probability of observing the sample data (or something more extreme) assuming the null hypothesis $H_0$ is true**.\n",
    "\n",
    "In simple words:\n",
    "\n",
    "* It measures how **compatible your data** is with the null hypothesis.\n",
    "* Smaller p-value → less compatible → stronger evidence against $H_0$.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Interpreting the P-Value**\n",
    "\n",
    "* **p ≤ α:** Reject $H_0$ (data is unlikely under H₀)\n",
    "* **p > α:** Fail to reject $H_0$ (data is consistent with H₀)\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Relationship to Significance Level**\n",
    "\n",
    "* α = significance level (common: 0.05, 0.01)\n",
    "* p-value is **compared to α**:\n",
    "\n",
    "  * If **p < 0.05**, result is statistically significant.\n",
    "  * If **p ≥ 0.05**, result is not significant.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Example**\n",
    "\n",
    "A sample of 36 phones has mean battery = 9.5, population mean = 10, σ = 1.8.\n",
    "\n",
    "* Compute Z = -1.67 (from previous Z-test example).\n",
    "* **Two-tailed p-value**:\n",
    "\n",
    "$$\n",
    "p = 2 \\cdot P(Z \\le -1.67) \\approx 2 \\cdot 0.0475 = 0.095\n",
    "$$\n",
    "\n",
    "* Compare to α = 0.05 → **p > 0.05**, fail to reject $H_0$.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Misconceptions**\n",
    "\n",
    "* ❌ P-value is **not** the probability that $H_0$ is true.\n",
    "* ❌ P-value is **not** the probability that results happened by chance.\n",
    "* ✅ It’s the probability of seeing data as extreme (or more extreme) if H₀ is true.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. In Machine Learning**\n",
    "\n",
    "* Test if a feature **significantly correlates with target**.\n",
    "* Compare **model performance metrics** between two models.\n",
    "* Evaluate **A/B testing** results for algorithm changes.\n",
    "\n",
    "---\n",
    "\n",
    "**Mnemonic:**\n",
    "**“p-value = How surprising is my data if H₀ were true?”**\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b9282f-ea56-40f6-82a9-9d1582c0f39e",
   "metadata": {},
   "source": [
    "> # `How to interpret P-values`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb26459-71a5-4664-9e6d-a5e9d4a1b363",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Interpreting P-Values**\n",
    "\n",
    "## **1. Compare P-Value to Significance Level (α)**\n",
    "\n",
    "* **Step 1:** Choose a significance level α (common choices: 0.05 or 0.01).\n",
    "* **Step 2:** Look at your p-value.\n",
    "\n",
    "  * **p ≤ α → Reject H₀** (evidence suggests an effect exists)\n",
    "  * **p > α → Fail to reject H₀** (insufficient evidence to claim an effect)\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Understanding the Magnitude**\n",
    "\n",
    "* **Very small p-value (e.g., < 0.01)** → Strong evidence **against H₀**.\n",
    "* **Moderate p-value (e.g., 0.01 – 0.05)** → Moderate evidence **against H₀**.\n",
    "* **Large p-value (e.g., > 0.05)** → Weak or no evidence **against H₀**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Examples**\n",
    "\n",
    "| P-value | Interpretation                              |\n",
    "| ------- | ------------------------------------------- |\n",
    "| 0.001   | Very strong evidence against H₀ → reject H₀ |\n",
    "| 0.03    | Strong evidence against H₀ → reject H₀      |\n",
    "| 0.07    | Weak evidence → fail to reject H₀           |\n",
    "| 0.5     | No evidence → fail to reject H₀             |\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Common Misinterpretations**\n",
    "\n",
    "* ❌ A p-value is **not** the probability that H₀ is true.\n",
    "* ❌ A p-value is **not** the probability that your data happened by chance.\n",
    "* ✅ Correct view: **P-value = probability of observing your data (or more extreme) if H₀ were true.**\n",
    "\n",
    "---\n",
    "\n",
    "## **5. P-Values in Machine Learning**\n",
    "\n",
    "* Determine whether a **feature is statistically significant** for prediction.\n",
    "* Test whether **model improvements** are meaningful.\n",
    "* Evaluate **A/B tests** for algorithm changes in production.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick tip:**\n",
    "\n",
    "* **Small p-value → reject H₀** → effect likely exists.\n",
    "* **Large p-value → fail to reject H₀** → effect not supported.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79093dc1-13d4-4180-b6e0-adedeb571809",
   "metadata": {},
   "source": [
    "> # `Types of Hypothesis Tests`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35f93c-0053-4bb0-b088-61963ae7046b",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Types of Hypothesis Tests**\n",
    "\n",
    "## **1. Z-Test**\n",
    "\n",
    "* **Purpose:** Test a population mean (or proportion) when **σ is known** or **large sample size (n ≥ 30)**.\n",
    "* **Types:**\n",
    "\n",
    "  * **One-sample Z-test** → Compare sample mean to population mean.\n",
    "  * **Two-sample Z-test** → Compare means of two independent samples.\n",
    "  * **Proportion Z-test** → Test population proportion.\n",
    "* **Example:** Is the average battery life of phones = 10 hours?\n",
    "\n",
    "---\n",
    "\n",
    "## **2. T-Test**\n",
    "\n",
    "* **Purpose:** Test means when **population σ unknown** and/or **small sample size (n < 30)**.\n",
    "* **Types:**\n",
    "\n",
    "  1. **One-sample t-test** → Compare sample mean to hypothesized mean.\n",
    "  2. **Independent two-sample t-test** → Compare means of two independent groups.\n",
    "  3. **Paired t-test** → Compare means of **related samples** (before-after studies).\n",
    "* **Example:** Does a new teaching method increase student scores compared to old method?\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Chi-Square Test (χ²)**\n",
    "\n",
    "* **Purpose:** Test relationships between **categorical variables**.\n",
    "* **Types:**\n",
    "\n",
    "  1. **Chi-square goodness-of-fit** → Does observed data fit a specific distribution?\n",
    "  2. **Chi-square test of independence** → Are two categorical variables independent?\n",
    "* **Example:** Is gender independent of preference for a product?\n",
    "\n",
    "---\n",
    "\n",
    "## **4. ANOVA (Analysis of Variance)**\n",
    "\n",
    "* **Purpose:** Compare **means of 3 or more groups**.\n",
    "* **One-way ANOVA:** One factor, multiple groups.\n",
    "* **Two-way ANOVA:** Two factors.\n",
    "* **Example:** Do exam scores differ across three teaching methods?\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Non-Parametric Tests**\n",
    "\n",
    "* Used when **data doesn’t meet normality assumptions**.\n",
    "* Examples:\n",
    "\n",
    "  * **Mann-Whitney U Test** → Compare two independent samples.\n",
    "  * **Wilcoxon Signed-Rank Test** → Paired samples.\n",
    "  * **Kruskal-Wallis Test** → Compare more than two groups.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Other Specialized Tests**\n",
    "\n",
    "* **F-Test:** Compare variances of two populations.\n",
    "* **Proportion Test:** Compare population proportions (one-sample or two-sample).\n",
    "* **Correlation Tests:** Test if correlation ≠ 0 (e.g., Pearson correlation).\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Summary:**\n",
    "\n",
    "| Test Type      | Data Type             | Purpose                              |\n",
    "| -------------- | --------------------- | ------------------------------------ |\n",
    "| Z-test         | Continuous            | Known σ, test mean or proportion     |\n",
    "| T-test         | Continuous            | Unknown σ, small sample              |\n",
    "| Chi-square     | Categorical           | Test independence or goodness-of-fit |\n",
    "| ANOVA          | Continuous            | Compare 3+ group means               |\n",
    "| Non-parametric | Continuous or Ordinal | Data doesn’t fit normality           |\n",
    "\n",
    "---\n",
    "\n",
    "**ML Connection:**\n",
    "\n",
    "* **T-tests & ANOVA:** Compare model metrics across groups.\n",
    "* **Chi-square:** Feature selection for categorical variables.\n",
    "* **Non-parametric tests:** Useful when data is skewed or ordinal.\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c947e742-a1e7-42e2-a689-1a6d66274521",
   "metadata": {},
   "source": [
    "> # `Z-Test`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f01a21-3f9f-4dfe-891e-0541b0e11725",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Z-Test**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "A **Z-test** is a statistical test used to determine if there is a **significant difference** between a sample mean (or proportion) and a population mean (or proportion), **when the population standard deviation (σ) is known** or the sample size is large (n ≥ 30).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Types of Z-Tests**\n",
    "\n",
    "1. **One-Sample Z-Test**\n",
    "\n",
    "   * Compare a **sample mean** to a **known population mean**.\n",
    "   * Example: Is the average battery life of 36 phones different from 10 hours?\n",
    "\n",
    "2. **Two-Sample Z-Test**\n",
    "\n",
    "   * Compare the means of **two independent samples**.\n",
    "   * Example: Compare average exam scores of students in Class A vs Class B.\n",
    "\n",
    "3. **Z-Test for Proportions**\n",
    "\n",
    "   * Compare a sample proportion with a population proportion or compare **two proportions**.\n",
    "   * Example: Is the proportion of students passing a test different from 0.8?\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Formula**\n",
    "\n",
    "### **One-Sample Z-Test (Mean)**\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\bar{X} - \\mu_0}{\\sigma / \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\bar{X}$ = sample mean\n",
    "* $\\mu_0$ = population mean (H₀)\n",
    "* σ = population standard deviation\n",
    "* n = sample size\n",
    "\n",
    "---\n",
    "\n",
    "### **Two-Sample Z-Test (Mean)**\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Z-Test for Proportion**\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\hat{p} - p_0}{\\sqrt{p_0(1-p_0)/n}}\n",
    "$$\n",
    "\n",
    "* $\\hat{p}$ = sample proportion\n",
    "* $p_0$ = population proportion\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Steps to Perform Z-Test**\n",
    "\n",
    "1. **State Hypotheses**\n",
    "\n",
    "   * Example: H₀: μ = 10, H₁: μ ≠ 10\n",
    "\n",
    "2. **Choose α (significance level)**\n",
    "\n",
    "   * Usually 0.05 → Z critical = ±1.96 for two-tailed test\n",
    "\n",
    "3. **Compute Z statistic** using formula\n",
    "\n",
    "4. **Decision Rule**\n",
    "\n",
    "   * If |Z| > Z critical → reject H₀\n",
    "   * If |Z| ≤ Z critical → fail to reject H₀\n",
    "\n",
    "5. **Conclusion**\n",
    "\n",
    "   * Interpret in context of the problem\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Example (One-Sample Z-Test)**\n",
    "\n",
    "* Sample: n = 36 phones, mean battery life = 9.5 hrs\n",
    "* Population mean: μ₀ = 10 hrs, σ = 1.8\n",
    "\n",
    "$$\n",
    "Z = \\frac{9.5 - 10}{1.8 / \\sqrt{36}} = \\frac{-0.5}{0.3} = -1.67\n",
    "$$\n",
    "\n",
    "* Critical Z = ±1.96 (α = 0.05, two-tailed)\n",
    "* |–1.67| < 1.96 → **Fail to reject H₀**\n",
    "* Conclusion: No significant difference in battery life.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. When to Use Z-Test**\n",
    "\n",
    "* Large sample size (n ≥ 30)\n",
    "* Known population σ\n",
    "* Data roughly normally distributed\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Machine Learning Connection**\n",
    "\n",
    "* Compare model accuracies to a benchmark.\n",
    "* Compare conversion rates in A/B tests.\n",
    "* Feature significance testing for continuous variables.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Memory Trick:**\n",
    "**Z-Test = “How many standard errors away is my sample mean from the population mean?”**\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d71833-32db-4d48-b736-4f0b58d4d224",
   "metadata": {},
   "source": [
    "> # `T-Test`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1882171e-14a2-4e11-87f0-01a0c7f3d62e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **T-Test**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "A **t-test** is a statistical test used to compare **means** when:\n",
    "\n",
    "* The **population standard deviation (σ) is unknown**\n",
    "* The **sample size is small (n < 30)**\n",
    "\n",
    "It uses the **t-distribution**, which is similar to the normal distribution but has **fatter tails** to account for more variability in small samples.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Types of T-Tests**\n",
    "\n",
    "### **a) One-Sample T-Test**\n",
    "\n",
    "* Compare a **sample mean** to a **known or hypothesized population mean**.\n",
    "* Example: Does the average test score of 15 students differ from 75?\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\bar{X}$ = sample mean\n",
    "* $s$ = sample standard deviation\n",
    "* n = sample size\n",
    "* $\\mu_0$ = hypothesized population mean\n",
    "\n",
    "---\n",
    "\n",
    "### **b) Independent Two-Sample T-Test**\n",
    "\n",
    "* Compare **means of two independent groups**.\n",
    "* Example: Compare exam scores of Class A vs Class B.\n",
    "\n",
    "**Formula (assuming equal variances):**\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n",
    "$$\n",
    "\n",
    "Where $s_p$ = pooled standard deviation:\n",
    "\n",
    "$$\n",
    "s_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **c) Paired Sample T-Test**\n",
    "\n",
    "* Compare **means of two related samples** (before-after, matched pairs).\n",
    "* Example: Student scores **before and after** a new teaching method.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{d}}{s_d / \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\bar{d}$ = mean of differences\n",
    "* $s_d$ = standard deviation of differences\n",
    "* n = number of pairs\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Steps to Perform a T-Test**\n",
    "\n",
    "1. **State Hypotheses**\n",
    "\n",
    "   * Example: H₀: μ = 75, H₁: μ ≠ 75\n",
    "\n",
    "2. **Choose α (significance level)**, usually 0.05\n",
    "\n",
    "3. **Compute t statistic** using the formula\n",
    "\n",
    "4. **Compare with Critical t value** (from t-table, depends on df = n–1) or use **p-value**\n",
    "\n",
    "5. **Decision**\n",
    "\n",
    "   * |t| > t critical → reject H₀\n",
    "   * |t| ≤ t critical → fail to reject H₀\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Example (One-Sample T-Test)**\n",
    "\n",
    "* Sample: n = 10 students, mean = 78, sample sd = 5\n",
    "* Population mean: μ₀ = 75\n",
    "\n",
    "$$\n",
    "t = \\frac{78 - 75}{5 / \\sqrt{10}} = \\frac{3}{1.58} \\approx 1.90\n",
    "$$\n",
    "\n",
    "* df = 10–1 = 9\n",
    "* α = 0.05 → two-tailed t critical ≈ ±2.262\n",
    "* |1.90| < 2.262 → **Fail to reject H₀**\n",
    "\n",
    "---\n",
    "\n",
    "## **5. When to Use T-Test**\n",
    "\n",
    "* **Unknown σ**\n",
    "* **Small sample (n < 30)**\n",
    "* Data roughly **normally distributed**\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Machine Learning Applications**\n",
    "\n",
    "* Compare **model performance metrics** for small datasets.\n",
    "* Test whether a **feature significantly affects target**.\n",
    "* Compare **before-after effect of algorithm changes**.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Memory Trick:**\n",
    "\n",
    "* **Z-test:** σ known or large n\n",
    "* **T-test:** σ unknown, small n\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abedd13f-7c00-4a22-a3f0-d5f80a323563",
   "metadata": {},
   "source": [
    "> # `Chi-square Test`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f88d093-d6b0-49e9-b93e-034db926e3ad",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "#  **Chi-Square (χ²) Test**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "The **Chi-Square test** is a **non-parametric statistical test** used to examine whether there is a significant association between **categorical variables** or whether an observed frequency distribution matches an expected distribution.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Types of Chi-Square Tests**\n",
    "\n",
    "### **a) Chi-Square Goodness-of-Fit Test**\n",
    "\n",
    "* **Purpose:** Test if a **single categorical variable** follows a specific distribution.\n",
    "* **Example:** Are dice rolls uniform across 1–6?\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $O_i$ = observed frequency\n",
    "* $E_i$ = expected frequency\n",
    "\n",
    "---\n",
    "\n",
    "### **b) Chi-Square Test of Independence**\n",
    "\n",
    "* **Purpose:** Test if **two categorical variables are independent**.\n",
    "* **Example:** Is gender independent of choosing a computer course?\n",
    "\n",
    "**Formula (same as above):**\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $O_{ij}$ = observed frequency in cell i,j\n",
    "* $E_{ij} = \\frac{(\\text{row total} \\cdot \\text{column total})}{\\text{grand total}}$\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Steps to Perform Chi-Square Test**\n",
    "\n",
    "1. **State Hypotheses**\n",
    "\n",
    "   * Goodness-of-fit: H₀ = observed frequencies match expected\n",
    "   * Independence: H₀ = variables are independent\n",
    "\n",
    "2. **Set significance level α** (common: 0.05)\n",
    "\n",
    "3. **Calculate χ² statistic** using observed and expected frequencies\n",
    "\n",
    "4. **Find critical χ² value** from χ² table with appropriate **degrees of freedom (df)**:\n",
    "\n",
    "   * Goodness-of-fit: df = number of categories – 1\n",
    "   * Independence: df = (rows–1) × (columns–1)\n",
    "\n",
    "5. **Decision**\n",
    "\n",
    "   * χ² > χ² critical → reject H₀\n",
    "   * χ² ≤ χ² critical → fail to reject H₀\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Example (Test of Independence)**\n",
    "\n",
    "Survey of 100 students:\n",
    "\n",
    "* **Gender:** Male/Female\n",
    "* **Course Preference:** Data Science / AI\n",
    "\n",
    "|        | DS | AI | Total |\n",
    "| ------ | -- | -- | ----- |\n",
    "| Male   | 20 | 30 | 50    |\n",
    "| Female | 25 | 25 | 50    |\n",
    "| Total  | 45 | 55 | 100   |\n",
    "\n",
    "**Expected frequencies:**\n",
    "\n",
    "* Male & DS = (50 × 45)/100 = 22.5\n",
    "* Male & AI = (50 × 55)/100 = 27.5\n",
    "* Female & DS = 22.5, Female & AI = 27.5\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\frac{(20-22.5)^2}{22.5} + \\frac{(30-27.5)^2}{27.5} + \\frac{(25-22.5)^2}{22.5} + \\frac{(25-27.5)^2}{27.5} \\approx 1.36\n",
    "$$\n",
    "\n",
    "* df = (2–1) × (2–1) = 1\n",
    "* χ² critical at α = 0.05 → 3.841\n",
    "* 1.36 < 3.841 → **Fail to reject H₀** → Gender and course preference are independent\n",
    "\n",
    "---\n",
    "\n",
    "## **5. When to Use**\n",
    "\n",
    "* Data is **categorical**\n",
    "* Observations are **independent**\n",
    "* Expected frequency in each cell ≥ 5 (rule of thumb)\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Machine Learning Applications**\n",
    "\n",
    "* Feature selection: test if categorical features are **dependent on target**\n",
    "* Market research: test if user preferences differ by demographics\n",
    "* A/B testing for categorical outcomes\n",
    "\n",
    "---\n",
    "\n",
    "**Mnemonic:**\n",
    "\n",
    "* **Goodness-of-fit → single variable**\n",
    "* **Independence → two variables**\n",
    "* χ² measures **difference between observed & expected frequencies**\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec06f9e-4a51-42fc-8abc-138a8b36a222",
   "metadata": {},
   "source": [
    "> # `ANOVA (Analysis of Variance)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3e58a0-8321-4993-be40-e8aa5b25314e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "# **ANOVA (Analysis of Variance)**\n",
    "\n",
    "## **1. Definition**\n",
    "\n",
    "ANOVA is a statistical test used to determine if there are **significant differences between the means of 3 or more groups**.\n",
    "\n",
    "* Instead of doing multiple t-tests (which increases error risk), ANOVA compares all group means **in one test**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Idea Behind ANOVA**\n",
    "\n",
    "It looks at **variability** in data:\n",
    "\n",
    "* **Between-group variability**: how much the group means differ from each other.\n",
    "* **Within-group variability**: how much individuals differ within each group.\n",
    "\n",
    "**If between > within → groups are significantly different.**\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Hypotheses**\n",
    "\n",
    "* **Null hypothesis (H₀):** All group means are equal.\n",
    "* **Alternative hypothesis (H₁):** At least one mean is different.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Types of ANOVA**\n",
    "\n",
    "1. **One-way ANOVA**\n",
    "\n",
    "   * One factor (independent variable), 3+ groups.\n",
    "   * Example: Do exam scores differ across three teaching methods?\n",
    "\n",
    "2. **Two-way ANOVA**\n",
    "\n",
    "   * Two factors (e.g., teaching method **and** gender).\n",
    "   * Tests main effects + interaction effects.\n",
    "\n",
    "3. **Repeated Measures ANOVA**\n",
    "\n",
    "   * Same subjects measured under different conditions.\n",
    "   * Example: Blood pressure measured before, during, and after treatment.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Test Statistic (F-ratio)**\n",
    "\n",
    "$$\n",
    "F = \\frac{\\text{Between-group variance}}{\\text{Within-group variance}}\n",
    "$$\n",
    "\n",
    "* If **F is large**, groups differ significantly.\n",
    "* Compare with **F-critical** value from F-distribution (df between, df within).\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Steps in One-Way ANOVA**\n",
    "\n",
    "1. **State hypotheses** (H₀: μ₁ = μ₂ = μ₃ …).\n",
    "2. **Set significance level (α = 0.05)**.\n",
    "3. **Calculate F-statistic** (ANOVA table).\n",
    "4. **Compare F with critical F** or check **p-value**.\n",
    "\n",
    "   * If p < α → reject H₀.\n",
    "5. If significant → do **post-hoc tests** (like Tukey’s HSD) to see **which groups differ**.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Example (One-Way ANOVA)**\n",
    "\n",
    "Suppose exam scores of students taught by 3 methods:\n",
    "\n",
    "* Method A: [85, 90, 88]\n",
    "* Method B: [78, 74, 80]\n",
    "* Method C: [92, 95, 91]\n",
    "\n",
    "ANOVA compares:\n",
    "\n",
    "* Between-group variance (differences in averages).\n",
    "* Within-group variance (spread inside each method).\n",
    "\n",
    "If F = 12.5 and p < 0.05 → reject H₀ → teaching methods differ.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Applications in Machine Learning**\n",
    "\n",
    "* Model comparison: Compare accuracy across 3+ ML models.\n",
    "* Feature testing: Compare outcomes across multiple categories of a feature.\n",
    "* A/B/n testing: Test if multiple experimental groups differ significantly.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Limitations**\n",
    "\n",
    "* Assumes **normality** and **equal variances** across groups.\n",
    "* If violated → use **non-parametric alternatives** (Kruskal-Wallis test).\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Mnemonic:**\n",
    "\n",
    "* **T-test** = compare 2 means\n",
    "* **ANOVA** = compare 3+ means\n",
    "* **F-test** inside ANOVA tells us if differences are real\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
