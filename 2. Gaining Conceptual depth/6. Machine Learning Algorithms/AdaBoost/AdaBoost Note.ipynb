{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae5af62-6ff0-4942-a5bf-889191177033",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1 style=\"color:#2E86C1;\">AdaBoost: A Boosting Algorithm Note | <a href=\"https://github.com/AdilShamim8/50-Days-of-Machine-Learning/tree/main/Day%2043%20AdaBoost\">Link</a></h1> \n",
    "    <p>\n",
    "      In this note, we will explain the <strong>AdaBoost</strong> algorithm step by step using HTML formatting within a Jupyter Notebook Markdown cell.\n",
    "      We will also include mathematical formulas (rendered with LaTeX) and a Python code example.\n",
    "    </p>\n",
    "    <h2 style=\"color:#117A65;\">Step 1: Introduction</h2>\n",
    "    <p>\n",
    "      AdaBoost (Adaptive Boosting) is an <em>ensemble learning</em> method that combines multiple weak classifiers to form a strong classifier.\n",
    "      It works by iteratively training weak learners (often simple decision stumps) and updating the weights of the training examples \n",
    "      so that the next classifier focuses more on the difficult (misclassified) examples.\n",
    "    </p>\n",
    "    <h2 style=\"color:#117A65;\">Step 2: Mathematical Formulation</h2>\n",
    "    <p>\n",
    "      At each iteration <em>t</em>, a weak classifier \\( h_t(x) \\) is trained and its error is computed with respect to the weighted dataset.\n",
    "      The weight (or importance) for this classifier is calculated as:\n",
    "    </p>\n",
    "    <p style=\"font-size:16px;\">\n",
    "      \\( \\alpha_t = \\frac{1}{2}\\ln\\left(\\frac{1-\\epsilon_t}{\\epsilon_t}\\right) \\)\n",
    "    </p> \n",
    "    <p>\n",
    "      Here, \\( \\epsilon_t \\) is the weighted error rate of the weak learner at iteration <em>t</em>. The training weights for each example are updated as:\n",
    "    </p>\n",
    "    <p style=\"font-size:16px;\">\n",
    "      \\( w_{i}^{(t+1)} = w_{i}^{(t)} \\cdot e^{-\\alpha_t y_i h_t(x_i)} \\)\n",
    "    </p>   \n",
    "    <p>\n",
    "      Finally, the strong (final) classifier is a weighted combination of all weak classifiers:\n",
    "    </p>   \n",
    "    <p style=\"font-size:16px;\">\n",
    "      \\( H(x) = \\operatorname{sign}\\left(\\sum_{t=1}^{T} \\alpha_t h_t(x)\\right) \\)\n",
    "    </p>   \n",
    "    <h2 style=\"color:#117A65;\">Step 3: Python Implementation</h2>\n",
    "    <p>\n",
    "      The following Python code demonstrates a simple AdaBoost classifier using scikit-learn.\n",
    "    </p>    \n",
    "    <pre style=\"background-color:#F4F6F7; padding:10px; border-radius:4px;\"><code class=\"python\">\n",
    "# Import necessary libraries\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# For binary classification, select only two classes (e.g., class 0 and 1)\n",
    "mask = y != 2\n",
    "X, y = X[mask], y[mask]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize AdaBoost with decision stumps as weak learners\n",
    "ada = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=50,\n",
    "    learning_rate=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the AdaBoost model\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ada.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "    </code></pre>    \n",
    "    <h2 style=\"color:#117A65;\">Step 4: Conclusion</h2>\n",
    "    <p>\n",
    "      In this note, we introduced AdaBoost with a clear step-by-step explanation that includes:\n",
    "    </p>\n",
    "    <ul>\n",
    "      <li>HTML formatting within a Markdown cell</li>\n",
    "      <li>LaTeX formulas for mathematical expressions</li>\n",
    "      <li>A practical Python code example using scikit-learn</li>\n",
    "    </ul>    \n",
    "  </body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56ca7a-31c3-4333-be70-6411c4c8bc65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
