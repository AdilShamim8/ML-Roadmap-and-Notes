{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d30882c-55d1-4860-b974-62aa6b00f041",
   "metadata": {},
   "source": [
    "# Binning and Binarization in Feature Transformation | [Link](https://github.com/AdilShamim8/50-Days-of-Machine-Learning/tree/main/Day%2016%20Binning%20and%20Binarization)\n",
    "\n",
    "When working with continuous data, it’s often useful to convert it into discrete intervals (bins) or binary values. This process is known as **binning** (or discretization) and **binarization**, respectively. These techniques can help reduce noise, handle outliers, and simplify models.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Binning and Binarization\n",
    "\n",
    "### Binarization\n",
    "\n",
    "**Binarization** converts a continuous feature into binary (0/1) values based on a threshold \\( t \\). The transformation is given by:  \n",
    "\n",
    "$$  \n",
    "f(x) =   \n",
    "\\begin{cases}  \n",
    "1 & \\text{if } x > t, \\\\\n",
    "0 & \\text{if } x \\leq t.  \n",
    "\\end{cases}  \n",
    "$$  \n",
    "\n",
    "### Python Code: Binarization Example\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "data = {'Feature': [0.2, 0.5, 1.5, 2.0, 3.5, 4.0, 5.2]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set threshold value\n",
    "threshold = 2.0\n",
    "\n",
    "# Binarize the feature based on the threshold\n",
    "df['Binarized'] = (df['Feature'] > threshold).astype(int)\n",
    "\n",
    "print(\"Binarization Example:\")\n",
    "print(df)\n",
    "\n",
    "# Plot original and binarized data\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(df['Feature'], 'o-', label='Original Feature')\n",
    "plt.step(range(len(df)), df['Binarized'], where='mid', label='Binarized', color='red')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.title(\"Binarization of Feature\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Discretization\n",
    "\n",
    "<p><strong>Discretization</strong> (or binning) converts a continuous feature into categorical bins. For a feature <i>x</i> and a set of bin boundaries <i>{b<sub>0</sub>, b<sub>1</sub>, &hellip;, b<sub>k</sub>}</i>, the bin index <i>i</i> is defined as:</p>  \n",
    "\n",
    "$$  \n",
    "\\text{bin}(x) = i \\quad \\text{if} \\quad b_i \\leq x < b_{i+1}  \n",
    "$$  \n",
    "\n",
    "### Python Code: Discretization using Fixed Bins\n",
    "\n",
    "```python\n",
    "# Define bin edges\n",
    "bins = [0, 1, 2, 4, 6]\n",
    "labels = ['Very Low', 'Low', 'Medium', 'High']\n",
    "\n",
    "# Use pd.cut to discretize the feature\n",
    "df['Discretized'] = pd.cut(df['Feature'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "print(\"\\nDiscretization (Fixed Bins) Example:\")\n",
    "print(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Quantile Binning\n",
    "\n",
    "**Quantile Binning** divides the data into bins such that each bin has (approximately) the same number of observations. The bin boundaries are defined by the quantiles of the feature’s distribution.\n",
    "\n",
    "For a dataset of size \\( n \\) divided into \\( k \\) bins, the boundaries are given by the quantiles at \\( \\frac{100}{k} \\) percentile increments.  \n",
    "For example, if using 4 bins (quartiles), the boundaries are the 25th, 50th, and 75th percentiles.\n",
    "\n",
    "### Python Code: Quantile Binning\n",
    "\n",
    "```python\n",
    "# Use pd.qcut to perform quantile binning\n",
    "df['Quantile_Bin'] = pd.qcut(df['Feature'], q=4, labels=False)\n",
    "\n",
    "print(\"\\nQuantile Binning Example:\")\n",
    "print(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. KMeans Binning\n",
    "\n",
    "**KMeans Binning** uses clustering to group similar values together. The idea is to apply KMeans clustering to the one-dimensional feature and then use the cluster labels as bin indices.\n",
    "\n",
    "### Steps:\n",
    "1. Reshape the feature into a 2D array.\n",
    "2. Fit KMeans with the desired number of bins \\( k \\).\n",
    "3. Use the cluster labels as the bin assignment.\n",
    "\n",
    "### Python Code: KMeans Binning\n",
    "\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Reshape the feature to a 2D array (required by KMeans)\n",
    "X = df['Feature'].values.reshape(-1, 1)\n",
    "\n",
    "# Set the desired number of bins (clusters)\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "df['KMeans_Bin'] = kmeans.fit_predict(X)\n",
    "\n",
    "print(\"\\nKMeans Binning Example:\")\n",
    "print(df)\n",
    "\n",
    "# Plot the clusters (bins)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(range(len(df)), df['Feature'], c=df['KMeans_Bin'], cmap='viridis', s=100)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Feature Value')\n",
    "plt.title(\"KMeans Binning of Feature\")\n",
    "plt.colorbar(label='Cluster Label (Bin)')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "- **Binarization** converts a continuous variable into a binary value based on a threshold.\n",
    "- **Discretization** groups continuous data into predefined bins using fixed boundaries.\n",
    "- **Quantile Binning** ensures equal frequency in each bin by setting boundaries at data quantiles.\n",
    "- **KMeans Binning** applies clustering to determine bin assignments based on natural groupings in the data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
