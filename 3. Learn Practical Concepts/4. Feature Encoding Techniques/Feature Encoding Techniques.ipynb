{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953ea419-89e7-4c79-9928-139130e55a9d",
   "metadata": {},
   "source": [
    "## Overview of Feature Encoding\n",
    "\n",
    "In machine learning, many algorithms require numerical input data. **Feature encoding** transforms categorical data into a numerical format so that models can process it. The most common encoding techniques include:\n",
    "\n",
    "- **Ordinal Encoding:** For categorical features that have a natural order.\n",
    "- **Label Encoding:** For mapping categories to integer values (often used for target variables).\n",
    "- **One-Hot Encoding:** For representing each category as a binary vector, especially when no ordinal relationship exists.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Ordinal Encoding  | [Link](https://github.com/AdilShamim8/50-Days-of-Machine-Learning/tree/main/Day%2010%20Ordinal%20Encoding)\n",
    "\n",
    "**Concept:**  \n",
    "Ordinal Encoding is used when your categorical feature has an intrinsic order (e.g., *Low*, *Medium*, *High*). The technique assigns an integer value to each category while preserving the order.\n",
    "\n",
    "**Mathematical Representation:**  \n",
    "\n",
    "<p>  \n",
    "    If you have an ordered set of categories <code>{c<sub>1</sub>, c<sub>2</sub>, &hellip;, c<sub>k</sub>}</code> (e.g., <code>Low &lt; Medium &lt; High</code>), then the encoding function can be written as:  \n",
    "</p>  \n",
    "\n",
    "$$\n",
    "f(c_i) = i \\quad \\text{for } i = 1, 2, \\dots, k.\n",
    "$$\n",
    "\n",
    "For example,  \n",
    "- Low → 1  \n",
    "- Medium → 2  \n",
    "- High → 3  \n",
    "\n",
    "**Python Code Example:**\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Example data with ordered categories\n",
    "data = np.array([[\"Low\"], [\"Medium\"], [\"High\"]])\n",
    "\n",
    "# Specify the order of categories explicitly\n",
    "encoder = OrdinalEncoder(categories=[[\"Low\", \"Medium\", \"High\"]])\n",
    "encoded = encoder.fit_transform(data)\n",
    "\n",
    "print(\"Ordinal Encoding:\\n\", encoded)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Label Encoding\n",
    "\n",
    "**Concept:**  \n",
    "Label Encoding assigns a unique integer to each category without implying any order. This method is commonly used for the target variable in classification tasks but can also be used for features when order is not important.\n",
    "\n",
    "**Mathematical Representation:**  \n",
    "\n",
    "<p>  \n",
    "    For a set of categories <code>{c<sub>1</sub>, c<sub>2</sub>, &hellip;, c<sub>k</sub>}</code>, label encoding maps each category to an integer value:  \n",
    "</p>  \n",
    "\n",
    "$$\n",
    "\\text{Label}(c_i) = i \\quad \\text{for each } c_i.\n",
    "$$\n",
    "\n",
    "**Python Code Example:**\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Example categorical data\n",
    "data = [\"red\", \"green\", \"blue\", \"green\", \"red\"]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoded = encoder.fit_transform(data)\n",
    "\n",
    "print(\"Label Encoding:\\n\", encoded)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. One-Hot Encoding  | [Link](https://github.com/AdilShamim8/50-Days-of-Machine-Learning/tree/main/Day%2011%20One-Hot%20Encoding)\n",
    "\n",
    "**Concept:**  \n",
    "One-Hot Encoding converts each categorical value into a binary vector of length equal to the number of unique categories. Only one element in the vector is 1 (indicating the presence of the category) and all others are 0. This method is ideal when there is no ordinal relationship between categories.\n",
    "\n",
    "**Mathematical Representation:**  \n",
    "\n",
    "<p>  \n",
    "    For a category <code>c</code> from a set of <code>k</code> categories, the one-hot encoded vector <strong>y</strong> is defined as:  \n",
    "</p>  \n",
    "\n",
    "$$\n",
    "y_j =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } j = c, \\\\\n",
    "0 & \\text{otherwise,}\n",
    "\\end{cases}\n",
    "\\quad \\text{for } j = 1, 2, \\dots, k.\n",
    "$$\n",
    "\n",
    "**Python Code Example (Using Pandas):**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame with categorical data\n",
    "data = pd.DataFrame({'color': ['red', 'green', 'blue', 'green', 'red']})\n",
    "\n",
    "# Generate one-hot encoding\n",
    "one_hot = pd.get_dummies(data['color'])\n",
    "print(\"One-Hot Encoding using pandas:\\n\", one_hot)\n",
    "```\n",
    "\n",
    "**Python Code Example (Using Scikit-Learn):**\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "data = np.array([[\"red\"], [\"green\"], [\"blue\"], [\"green\"], [\"red\"]])\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded = encoder.fit_transform(data)\n",
    "\n",
    "print(\"One-Hot Encoding using scikit-learn:\\n\", encoded)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "- **Ordinal Encoding** is ideal for ordered categories. It maps each category to an integer in a way that preserves the order.  \n",
    "- **Label Encoding** simply assigns a unique integer to each category and is most useful for target variables or non-ordinal features.\n",
    "- **One-Hot Encoding** creates binary vectors for each category, ensuring no ordinal relationship is imposed on the data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
