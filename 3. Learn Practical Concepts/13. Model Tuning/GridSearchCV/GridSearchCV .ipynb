{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9089042d-d50c-4243-86e1-16a38e62bfeb",
   "metadata": {},
   "source": [
    "# Model Tuning with GridSearchCV\n",
    "\n",
    "GridSearchCV is an automated tool in scikit‚Äëlearn used for hyperparameter tuning. It performs an exhaustive search over a specified parameter grid while using cross-validation to evaluate model performance. This note provides an overview of its theory, relevant formulas, and practical code examples.\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Model tuning** aims to find the optimal combination of hyperparameters to maximize (or minimize) a model‚Äôs performance metric. Hyperparameters are external configurations (e.g., regularization strength, kernel parameters) set before training. In contrast, model parameters are learned during training.\n",
    "\n",
    "GridSearchCV automates this process by:\n",
    "- Defining a **grid** of hyperparameter values.\n",
    "- Training the model for each combination.\n",
    "- Evaluating performance via cross-validation.\n",
    "- Returning the best hyperparameter set.\n",
    "\n",
    "## Mathematical Formulation\n",
    "\n",
    "Suppose your model has \\( k \\) hyperparameters, and you choose a set of possible values for each:\n",
    "\n",
    "<ul style=\"list-style-type: none;\">  \n",
    "    <li><span style=\"font-family: 'Courier New', Courier, monospace;\">p<sub>1</sub> &in; {p<sub>1</sub><sup>(1)</sup>, p<sub>1</sub><sup>(2)</sup>,...., p<sub>1</sub><sup>(n<sub>1</sub>)</sup>}</span></li>  \n",
    "    <li><span style=\"font-family: 'Courier New', Courier, monospace;\">p<sub>2</sub> &in; {p<sub>2</sub><sup>(1)</sup>, p<sub>2</sub><sup>(2)</sup>, ...., p<sub>2</sub><sup>(n<sub>2</sub>)</sup>}</span></li>  \n",
    "    <li>&#x2026;</li>  \n",
    "    <li><span style=\"font-family: 'Courier New', Courier, monospace;\">p<sub>k</sub> &in; {p<sub>k</sub><sup>(1)</sup>, p<sub>k</sub><sup>(2)</sup>,...., p<sub>k</sub><sup>(n<sub>k</sub>)</sup>}</span></li>  \n",
    "</ul>  \n",
    "  \n",
    "The grid is the Cartesian product:\n",
    "\n",
    "$$\n",
    "\\mathcal{P} = \\{ (p_1, p_2, \\dots, p_k) \\mid p_1 \\in P_1,\\, p_2 \\in P_2,\\, \\dots,\\, p_k \\in P_k \\}\n",
    "$$\n",
    "\n",
    "<p>For each combination <span style=\"font-family: 'Courier New', Courier, monospace;\">ùëù</span> &in; <span style=\"font-family: 'Courier New', Courier, monospace;\">ùìü</span>, the model is trained and evaluated using cross-validation. If using <span style=\"font-family: 'Courier New', Courier, monospace;\">k</span>-fold CV, the score for hyperparameters <span style=\"font-family: 'Courier New', Courier, monospace;\">ùëù</span> is estimated as:</p>  \n",
    "\n",
    "$$\n",
    "\\text{CV Score}(\\mathbf{p}) = \\frac{1}{k} \\sum_{i=1}^{k} \\text{score}_i(\\mathbf{p})\n",
    "$$\n",
    "\n",
    "<p>GridSearchCV then selects the combination <span style=\"font-family: 'Courier New', Courier, monospace;\">ùëù<sup>*</sup></span> with the best (e.g., maximum) CV score:</p>  \n",
    "\n",
    "$$\n",
    "\\mathbf{p}^* = \\arg\\max_{\\mathbf{p} \\in \\mathcal{P}} \\text{CV Score}(\\mathbf{p})\n",
    "$$\n",
    "\n",
    "## How GridSearchCV Works\n",
    "\n",
    "1. **Parameter Grid Definition**: Create a dictionary of hyperparameters and their possible values.\n",
    "2. **Model Training**: For each parameter combination in the grid, the estimator is trained using cross-validation.\n",
    "3. **Score Aggregation**: Compute the average performance (e.g., accuracy, AUC) over the CV folds.\n",
    "4. **Selection**: The hyperparameter combination with the best average score is selected.\n",
    "5. **Refitting**: Optionally, the estimator is refit on the entire training dataset using the best parameters.\n",
    "\n",
    "## Python Code Example\n",
    "\n",
    "Below is an example using a Support Vector Machine (SVM) classifier to tune the regularization parameter \\( C \\) and the kernel coefficient \\(\\gamma\\):\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load a sample dataset (Iris)\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf']  # Using only the 'rbf' kernel for this example\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with 5-fold cross-validation\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best CV Accuracy: {:.2f}%\".format(grid.best_score_ * 100))\n",
    "\n",
    "# Evaluate the best estimator on the test set\n",
    "y_pred = grid.predict(X_test)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "```\n",
    "\n",
    "### Explanation\n",
    "\n",
    "- **Data Preparation**: We load the Iris dataset and split it.\n",
    "- **Parameter Grid**: A grid is defined for \\( C \\) and \\(\\gamma\\) for the RBF kernel.\n",
    "- **GridSearchCV Object**: With 5-fold cross-validation, all combinations are tried in parallel (using all available cores via `n_jobs=-1`).\n",
    "- **Evaluation**: The best parameters and their CV accuracy are printed. Finally, the best model is evaluated on the test set.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "GridSearchCV is a powerful and widely used tool in machine learning for automating hyperparameter tuning. By exhaustively searching over a predefined grid of parameter values and leveraging cross-validation, it helps identify the best model configuration to maximize performance. This note has provided both theoretical insights and practical code examples to help you get started with model tuning using GridSearchCV.\n",
    "\n",
    "---\n",
    "\n",
    "*References:*\n",
    "- [scikit‚Äëlearn documentation on GridSearchCV.](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "- [Analytics Vidhya's guide on GridSearchCV.](https://www.analyticsvidhya.com/blog/2021/06/tune-hyperparameters-with-gridsearchcv/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
