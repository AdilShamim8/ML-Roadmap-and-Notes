{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d45c932-4a98-4d75-9cd2-8c38d1837cbf",
   "metadata": {},
   "source": [
    "# Column Transformer | [Link](https://github.com/AdilShamim8/50-Days-of-Machine-Learning/tree/main/Day%2012%20Column%20Transformer)\n",
    "\n",
    "When preprocessing data for machine learning, it is common to apply different transformations to different types of features (e.g., numerical vs. categorical). The **ColumnTransformer** in scikit-learn helps manage this by allowing you to specify different preprocessing pipelines for subsets of features.\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "A **Pipeline** is used to chain multiple steps together (e.g., preprocessing and model training), ensuring that all steps are applied in sequence during both training and prediction. The **ColumnTransformer** extends this idea by allowing different transformations on specified columns of your dataset.\n",
    "\n",
    "### Why Use ColumnTransformer?\n",
    "\n",
    "- **Selective Preprocessing:** Apply different transformers (e.g., scaling, encoding) to different columns.\n",
    "- **Simplified Workflow:** Combine multiple transformations in a single object that fits into a broader pipeline.\n",
    "- **Cleaner Code:** Manage complex preprocessing logic in an organized, reproducible manner.\n",
    "\n",
    "---\n",
    "\n",
    "## Mathematical Formulas in Preprocessing\n",
    "\n",
    "Many transformations use well-known mathematical formulas. For example:\n",
    "\n",
    "### Standard Scaling\n",
    "\n",
    "To standardize a numerical feature, the **StandardScaler** transforms data by removing the mean and scaling to unit variance:\n",
    "\n",
    "$$\n",
    "x_{\\text{scaled}} = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- μ is the mean of the feature.\n",
    "- σ is the standard deviation.\n",
    "\n",
    "### Min-Max Scaling\n",
    "\n",
    "Alternatively, the **MinMaxScaler** scales features to a given range, usually \\([0, 1]\\):\n",
    "\n",
    "$$\n",
    "x_{\\text{norm}} = \\frac{x - x_{\\text{min}}}{x_{\\text{max}} - x_{\\text{min}}}\n",
    "$$\n",
    "\n",
    "These formulas are applied individually to each feature column selected by the ColumnTransformer.\n",
    "\n",
    "---\n",
    "\n",
    "## Using ColumnTransformer in Python\n",
    "\n",
    "Below is a Python code example that demonstrates how to create a preprocessing pipeline using ColumnTransformer. In this example, numerical features are imputed and standardized, while categorical features are imputed and one-hot encoded.\n",
    "\n",
    "```python\n",
    "# Import necessary modules\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample feature lists\n",
    "numeric_features = ['age', 'salary']\n",
    "categorical_features = ['gender', 'country']\n",
    "\n",
    "# Pipeline for numerical features: impute missing values and scale\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for categorical features: impute missing values and encode\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create the ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combine the preprocessor with an estimator in a full pipeline\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Example usage with train/test split (replace X, y with your data)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# clf.fit(X_train, y_train)\n",
    "# score = clf.score(X_test, y_test)\n",
    "# print(\"Model accuracy:\", score)\n",
    "```\n",
    "\n",
    "### Key Points in the Code\n",
    "\n",
    "- **Numeric Pipeline:**  \n",
    "  - **SimpleImputer:** Fills in missing values using the median.\n",
    "  - **StandardScaler:** Standardizes features using the formula:\n",
    "    $$\n",
    "    x_{\\text{scaled}} = \\frac{x - \\mu}{\\sigma}\n",
    "    $$\n",
    "\n",
    "- **Categorical Pipeline:**  \n",
    "  - **SimpleImputer:** Fills in missing values with a constant value (`'missing'`).\n",
    "  - **OneHotEncoder:** Converts categorical variables into a binary matrix.\n",
    "\n",
    "- **Combining Pipelines:**  \n",
    "  The `ColumnTransformer` applies these pipelines to the respective columns, and the overall `Pipeline` chains preprocessing with model training.\n",
    "\n",
    "---\n",
    "\n",
    "## Benefits and Best Practices\n",
    "\n",
    "- **Modularity:**  \n",
    "  Each transformer (or pipeline) is modular. This means you can easily swap or update individual preprocessing steps.\n",
    "\n",
    "- **Reproducibility:**  \n",
    "  Pipelines ensure that the same transformations are applied during training and prediction, minimizing data leakage.\n",
    "\n",
    "- **Extensibility:**  \n",
    "  You can add more transformers or estimators to the pipeline as needed. For example, you might include feature selection or additional scaling.\n",
    "\n",
    "- **Debugging:**  \n",
    "  Breaking down your preprocessing steps into modular pipelines makes it easier to track down errors or unexpected behavior in your data processing.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The ColumnTransformer is a powerful tool in the scikit-learn ecosystem that streamlines the preprocessing of heterogeneous datasets. By applying different transformations to specific subsets of features, it helps create robust and maintainable machine learning pipelines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
