{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "533c9377-67b8-48b7-87ae-949bc0e6d343",
   "metadata": {},
   "source": [
    "## KNN Imputer for Missing Data | [Link](https://github.com/AdilShamim8/50-Days-of-Machine-Learning/tree/main/Day%2023%20KNN%20Imputer)\n",
    "\n",
    "### Overview\n",
    "\n",
    "**KNN Imputer** is an imputation technique that leverages the concept of k-nearest neighbors (KNN) to fill in missing values. Rather than simply replacing missing values with a fixed statistic (like the mean or median), KNN Imputer identifies the k most similar observations (neighbors) based on the other feature values and then imputes the missing value using an aggregate (typically the mean) of the neighbors’ values.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. **Distance Calculation:**  \n",
    "   For each sample with missing values, the algorithm calculates the distance (usually Euclidean) to all other samples using only the features that are present in both samples.\n",
    "   \n",
    "2. **Neighbor Selection:**  \n",
    "   It then selects the k-nearest neighbors that have non-missing values in the target feature.\n",
    "\n",
    "3. **Aggregation:**  \n",
    "   The missing value is imputed by aggregating (typically averaging) the corresponding values from the k-nearest neighbors.\n",
    "\n",
    "### Benefits\n",
    "\n",
    "- **Data-Driven:** Imputation is based on the actual observed data distribution rather than a global statistic.\n",
    "- **Preserves Relationships:** By considering neighbors, the method tends to preserve local data patterns and relationships.\n",
    "- **Flexibility:** The number of neighbors (k) can be tuned based on the dataset’s characteristics.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- **Computationally Intensive:** For large datasets, calculating distances for each missing entry can be resource-intensive.\n",
    "- **Assumes Similarity:** The method assumes that similar samples (neighbors) provide a good estimate, which may not hold in all cases.\n",
    "- **Sensitive to Feature Scaling:** It is important to standardize or normalize features before applying KNN Imputer to ensure fair distance comparisons.\n",
    "\n",
    "### Python Code Example\n",
    "\n",
    "Below is an example using scikit-learn's `KNNImputer`:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sample DataFrame with missing numerical values\n",
    "data = {\n",
    "    'Feature1': [1.0, 2.0, np.nan, 4.0, 5.0],\n",
    "    'Feature2': [2.0, np.nan, 3.0, 4.0, 5.0],\n",
    "    'Feature3': [np.nan, 1.0, 2.0, 3.0, 4.0]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Optional: Scale features to standardize before imputation (important for KNN)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Create and apply KNN Imputer\n",
    "# n_neighbors defines the number of neighbors to use for imputation (default is 5)\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "df_imputed_scaled = imputer.fit_transform(df_scaled)\n",
    "\n",
    "# Inverse transform to get back original scale\n",
    "df_imputed = pd.DataFrame(scaler.inverse_transform(df_imputed_scaled), columns=df.columns)\n",
    "print(\"\\nDataFrame after KNN Imputation:\")\n",
    "print(df_imputed)\n",
    "```\n",
    "\n",
    "#### Explanation:\n",
    "- **Data Creation:** We create a DataFrame with missing values in three features.\n",
    "- **Scaling:** Standardization is applied using `StandardScaler` to ensure features contribute equally to the Euclidean distance calculation.\n",
    "- **KNNImputer:** We initialize `KNNImputer` with `n_neighbors=3` (you can adjust k as needed) and apply it to the scaled DataFrame.\n",
    "- **Inverse Transform:** The imputed scaled data is transformed back to the original scale for interpretation.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "KNN Imputer provides a more tailored approach to missing data imputation by using local information from similar samples. This method is especially useful when the data has local structure that simple global imputation strategies (like mean or median imputation) might overlook. Always remember to scale your features when using KNN-based methods to ensure fair distance calculations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
