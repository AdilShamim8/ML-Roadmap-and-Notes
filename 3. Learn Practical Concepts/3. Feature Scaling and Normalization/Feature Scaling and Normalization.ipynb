{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e35d826-ba0b-45b1-808c-9406a35d2e02",
   "metadata": {},
   "source": [
    "\n",
    "# Standardization and Normalization\n",
    "\n",
    "This note covers two important data scaling techniques: **Standardization** and **Normalization**. These methods are used to adjust the range and distribution of data features, which is crucial for many machine learning algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "- **Standardization** rescales data to have a mean of 0 and a standard deviation of 1. It is especially useful when data is approximately normally distributed.\n",
    "- **Normalization** scales data to a fixed range, usually [0, 1]. It is often used when the distribution is unknown or not Gaussian.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Standardization | [Link](https://github.com/AdilShamim8/50-Days-of-Machine-Learning/tree/main/Day%2008%20Standardization)\n",
    "\n",
    "### 2.1. What is Standardization?\n",
    "\n",
    "Standardization (or Z-score normalization) transforms your data so that it has:\n",
    "- A mean (μ) of 0\n",
    "- A standard deviation (σ) of 1\n",
    "\n",
    "This process ensures that each feature contributes equally to the model.\n",
    "\n",
    "### 2.2. Step-by-Step Process for Standardization\n",
    "\n",
    "**Step 1:** **Calculate the Mean**  \n",
    "Compute the mean of the dataset:\n",
    "$$\n",
    "\\mu = \\frac{1}{n}\\sum_{i=1}^{n} x_i\n",
    "$$\n",
    "\n",
    "**Step 2:** **Calculate the Standard Deviation**  \n",
    "Determine the standard deviation:\n",
    "$$\n",
    "\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\mu)^2}\n",
    "$$\n",
    "\n",
    "**Step 3:** **Transform the Data**  \n",
    "Standardize each data point using:\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "### 2.3. Python Example with NumPy\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "# Step 1: Calculate mean\n",
    "mean = np.mean(data)\n",
    "print(\"Mean:\", mean)\n",
    "\n",
    "# Step 2: Calculate standard deviation\n",
    "std = np.std(data)\n",
    "print(\"Standard Deviation:\", std)\n",
    "\n",
    "# Step 3: Standardize the data\n",
    "standardized_data = (data - mean) / std\n",
    "print(\"Standardized Data:\", standardized_data)\n",
    "```\n",
    "\n",
    "### 2.4. Using Scikit-Learn's StandardScaler\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Data needs to be a 2D array (e.g., one feature per column)\n",
    "data = np.array([[10], [20], [30], [40], [50]])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(data)\n",
    "print(\"Standardized Data using StandardScaler:\")\n",
    "print(standardized_data)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Normalization | [Link](https://github.com/AdilShamim8/50-Days-of-Machine-Learning/tree/main/Day%2009%20Normalization)\n",
    "\n",
    "### 3.1. What is Normalization?\n",
    "\n",
    "Normalization rescales the data to a fixed range, most commonly [0, 1]. This is useful when your data does not follow a Gaussian distribution or when you want to bound all features within the same range.\n",
    "\n",
    "### 3.2. Step-by-Step Process for Normalization\n",
    "\n",
    "**Step 1:** **Identify the Minimum and Maximum Values**  \n",
    "Find the minimum and maximum values in the dataset:\n",
    "$$\n",
    "x_{\\min} = \\min(x_i), \\quad x_{\\max} = \\max(x_i)\n",
    "$$\n",
    "\n",
    "**Step 2:** **Rescale the Data**  \n",
    "Normalize each data point with:\n",
    "$$\n",
    "x' = \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}}\n",
    "$$\n",
    "\n",
    "### 3.3. Python Example with NumPy\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "# Step 1: Calculate minimum and maximum\n",
    "data_min = np.min(data)\n",
    "data_max = np.max(data)\n",
    "print(\"Minimum:\", data_min)\n",
    "print(\"Maximum:\", data_max)\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "normalized_data = (data - data_min) / (data_max - data_min)\n",
    "print(\"Normalized Data:\", normalized_data)\n",
    "```\n",
    "\n",
    "### 3.4. Using Scikit-Learn's MinMaxScaler\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Data needs to be a 2D array\n",
    "data = np.array([[10], [20], [30], [40], [50]])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(data)\n",
    "print(\"Normalized Data using MinMaxScaler:\")\n",
    "print(normalized_data)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. When to Use Each Method\n",
    "\n",
    "- **Standardization** is ideal when:\n",
    "  - Data follows a Gaussian (normal) distribution.\n",
    "  - Algorithms assume features are centered around zero (e.g., PCA, logistic regression).\n",
    "\n",
    "- **Normalization** is preferred when:\n",
    "  - You need to bound the data within a specific range.\n",
    "  - The data does not follow a normal distribution (e.g., neural networks often perform better with normalized data).\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Practical Considerations\n",
    "\n",
    "- **Training vs. Testing:** Always compute scaling parameters (mean, standard deviation, min, max) on the training set and apply the same transformation to the test set.\n",
    "- **Feature-wise Scaling:** When working with multi-dimensional data, apply scaling to each feature independently.\n",
    "- **Impact on Models:** Proper scaling can improve the performance of many machine learning algorithms by ensuring that each feature contributes equally.\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "\n",
    "This detailed note should help you understand the processes behind standardization and normalization while providing clear, step-by-step instructions and code examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
